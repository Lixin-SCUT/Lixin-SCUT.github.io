<html>
  <head>
    <meta charset="utf-8" />
<meta name="description" content="" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>多线程日志 | Lixin-SCUT</title>
<link rel="shortcut icon" href="https://lixin-scut.github.io//favicon.ico?v=1589901544459">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css" integrity="sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
<link rel="stylesheet" href="https://lixin-scut.github.io//styles/main.css">

<script src="https://cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>
<script src="https://cdn.bootcss.com/moment.js/2.23.0/moment.min.js"></script>



  </head>
  <body>
    <div class="main">
      <div class="main-content">
        <div class="site-header">
  <a href="https://lixin-scut.github.io/">
  <img class="avatar" src="https://lixin-scut.github.io//images/avatar.png?v=1589901544459" alt="">
  </a>
  <h1 class="site-title">
    Lixin-SCUT
  </h1>
  <p class="site-description">
    千里之行，始于足下。不积跬步，无以至千里。
  </p>
  <div class="menu-container">
    
      
        <a href="/" class="menu">
          首页
        </a>
      
    
      
        <a href="/archives" class="menu">
          时间轴
        </a>
      
    
      
        <a href="/tags" class="menu">
          分类/标签
        </a>
      
    
      
        <a href="/post/about" class="menu">
          关于
        </a>
      
    
  </div>
  <div class="social-container">
    
      
    
      
    
      
    
      
    
      
    
  </div>
</div>


        <div class="post-detail">
          <article class="post">
            <h2 class="post-title">
              多线程日志
            </h2>
            <div class="post-info">
              <time class="post-time">
                · 2020-03-02 ·
              </time>
              
                <a href="https://lixin-scut.github.io//tag/FkuF879Gw" class="post-tag">
                  # Network-Library
                </a>
              
            </div>
            
            <div class="post-content">
              <p>故障诊断和追踪<br>
日志库是单例模式<br>
muduo日志库是C++ stream风格，但没用iostream，而是自己写了logstream class<br>
日志需要有设置级别的功能<br>
日志的目的地只有本地，不要往网络传日志<br>
日志应该有rolling功能，主要由文件大小和时间来区分<br>
日志文件名：进程名+时间+机器名+进程id+后缀.log<br>
防止程序崩溃1.定期flush 2.在内存中的日志消息都有cookie，值为某个函数地址<br>
日志消息格式是固定的，不需要通过运行时配置<br>
要点 1.每条日志只占1行 2.时间戳精确到微妙 gettimeofday 3.保证同一时区 4.打印线程id 5.打印日志级别 6.打印源文件名和行号<br>
每行日志的前四个字段的宽度是固定的以空格分隔便于分析，避免出现正则表达式的元字符</p>
<p>优化：<br>
1.日期和时间都是缓存的<br>
2.前四个字段是定长的，避免运行时求长度<br>
3.线程id预先格式化为字符串 4.源文件名部分采用编译器计算<br>
多线程异步日志：使用一个背景线程来收集日志信息，其他业务线程往这个线程发送日志消息<br>
双缓冲技术 使用两个buffer 分为前段接收和后端写入<br>
实际上有四个缓冲区</p>
<p>日志通常用于故障诊断 和追踪(trace) ,也可用于性能分析。</p>
<p>日志通常要记录</p>
<ol>
<li>收到的每条内部消息的id (还可以包括关键字段、长度、hash等);</li>
<li>收到的每条外部消息的全文；</li>
<li>发出的每条消息的全文，每条消息都有全局唯一的id；</li>
<li>关键内部状态的变更。</li>
</ol>
<p>每条日志都有时间戳</p>
<p>一个日志库大体可分为前端(frontend)和后端(backend)两部分。前端是供应用程序使用的接口(API),并生成日志消息(log message)；后端则负责把日志 消息写到目的地(destination)。这两部分的接口有可能简单到只有一个回调函数：<br>
void output(const char* message, int len);<br>
其中的message字符串是一条完整的日志消息，包含日志级别、时间戳、源文件位 置、线程id等基本字段，以及程序输出的具体消息内容。<br>
在多线程程序中，前端和后端都与单线程程序无甚区别，无非是每个线程有自己 的前端，整个程序共用一个后端。但难点在于将日志数据从多个前端高效地传输到后 端尢这是一个典型的多生产者-单消费者问题，对生产者(前端)而言，要尽量做 到低延迟、低CPU开销、无阻塞；对消费者(后端)而言，要做到足够大的吞吐量,，并占用较少资源。</p>
<p>常见的日志功能：</p>
<ol>
<li>日志消息有多种级别（level）,如 TRACE. DEBUG、INFO、WARN、ERROR. FATAL 等。</li>
<li>日志消息可能有多个目的地（appender）,如文件、socket、SMTP等。</li>
<li>日志消息的格式可配置（layout）,例如 org. apache. Iog4 j . PatternLayouto</li>
<li>可以设置运行时过滤器（filter）,控制不同组件的日志消息的级别和目的地。<br>
在上面这几项中，除了第一项之外，其余三项都是非必需的功能。</li>
</ol>
<p>日志的输出级别在运行时可调，这样同一个可执行文件可以分别在测试环境的时候输出DEBUG级别的日志，在生产环境输出INFO级别的日志。在必要的时候也可以临时在线调整日志的输出级别。例如某台机器的消息量过大、日志文件太多、磁 盘空间紧张，那么可以临时调整为WARNING级别输出，减少日志数目。又比如某个新上线的进程的行为略显古怪，则可以临时调整为DEBUG级别输出，打印更细节的日志消息以便分析查错。调整日志的输出级别不需要重新编译，也不需要重启进程，只要调用 Logger::setLogLevel（）就能即时生效。<br>
对于分布式系统中的服务进程而言，日志的目的地（destination ）只有一个：本 地文件。往网络写日志消息是不靠谱的，因为诊断日志的功能之一正是诊断网络故 障，往网络写日志消息的另一个坏处是增加网络带宽消耗。同理应 该避免往网络文件系统（例如NFS）上写日志，<br>
以本地文件为日志的destination,那么日志文件的滚动（rolling ）是必需的，这样可以简化日志归档（archive）的实现。rolling的条件通常有两个：文件大小（例 如每写满1GB就换下一个文件）和时间（例如每天零点新建一个日志文件，不论前 一个文件有没有写满）。日志库的LogFile会自动根据文件大小和时间来主动 滚动日志文件。既然能主动rolling, 也就不必支持SIGUSR1，毕竟多线程程序 处理signal很麻烦<br>
一个典型的日志文件的文件名如下：<br>
logfile_test.2012060-144022.hostname.3605.log<br>
文件名由以下几部分组成：<br>
•第1部分logfile.test是进程的名字。通常是main函数参数中argv[0]的 basename,这样容易区分究竟是哪个服务程序的日志。必要时还可以把程序 版本加进去。<br>
•第2部分是文件的创建时间（GMT时区）。这样很容易通过文件名来选择某一时间范围内的日志，例如用通配符*.20120603-14 * 表示2012年6月3日下午2 点（GMT）左右的日志文件（s）<br>
•第3部分是机器名称。这样即便把日志文件拷贝到别的机器上也能追溯其来源。<br>
•第4部分是进程id。如果一个程序一秒之内反复重启，那么每次都会生成不同的日志文件。<br>
•第5部分是统一的后缀名.logo同样是为了便于周边配套脚本的编写。<br>
muduo的日志文件滚动没有采用文件改名的办法，即dmesg.log是最新日志, dmesg.log.l是前一个口志，dmesg.Log.2.gz是更早的口志等。这种做法的一个好处是dmesglog始终是最新日志，便于编写某些及时解析日志的脚本。将来可以增加一个功能，每次滚动日志文件之后立刻创建（更新）一个symlink, logMe.test.log始终指向当前最新的日志文件，这样达到相同的效果。<br>
往文件写日志的一个常见问题是，万一程序崩溃，那么最后若干条日志往往就丢失了，因为日志库不能每条消息都flush硬盘，更不能每条日志都open/close文 件，这样性能开销太大。muduo日志库用两个办法来应对这一点，其一是定期（默认3秒）将缓冲区内的日志消息flush到硬盘；其二是每条内存中的日志消息都带有 cookie （或者叫哨兵值/sentry）,其值为某个函数的地址，这样通过在core dump文件中查找cookie就能找到尚未来得及写入磁盘的消息。<br>
日志消息的格式是固定的，不需要运行时配置，这样可节省每条日志解析格式字符串的开销。我认为日志的格式在项目的整个生命周期几乎不会改变，因为我们经常 会为不同目的编写parse 日志的脚本，既要解析最近几天的日志文件，也要和几个月之前，甚至一年之前的日志文件的同类数据做对比。如果在此期间日志格式变了，势必会增加很多无谓的工作量。如果真的需要调整消息格式，直接修改代码并重新编译<br>
日志消息格式有几个要点:<br>
•尽量每条日志占一行。这样很容易用awk、sed、grep等命令行工具来快速联机 分析日<br>
•时间戳精确到微秒。每条消息都通过gettimeofday（2）获得当前时间，这么做 不会有什么性能损失。因为在x86-64 Linux ,gettimeofday（2）不是系统调 用，不会陷入内核<br>
•始终使用GMT时区（Z）。对于跨洲的分布式系统而言，可省去本地时区转换的麻烦（别忘了主要西方国家大多实行夏令时），更易于追杳事件的顺序。<br>
•打印线程id。便于分析多线程程序的时序，也可以检测死锁，这里的线程id 是指调用LOG_INFO 的线程。<br>
•打印日志级别。在线查错的时候先看看有无ERROR日志，通常可加速定位问题。<br>
•打印源文件名和行号。修复bug的时候不至于搞错对象。<br>
每行日志的前4个字段的宽度是固定的，以空格分隔，便于用脚本解析。另外，应该避免在日志格式（特别是消息id）中出现正则表达式的元字符（meta character）,等等，这样在用less查看日志文件的时候查找字符 串更加便捷。</p>
<p>性能需求<br>
编写Linux服务端程序的时候，我们需要一个高效的日志库。只有日志库足够高 效，程序员才敢在代码中输出足够多的诊断信息，减小运维难度，提升效率。高效性 体现在几方面：<br>
•每秒写成上万条日志的时候没有明显的性能损失。<br>
•能应对一个进程产生大量日志数据的场景<br>
•不阻塞正常的执行流程。<br>
•在多线程程序中，不造成争用（contention ）</p>
<p>为了实现这样的性能指标，muduo日志库的实现有几点优化措施值得一提：<br>
•时间戳字符串中的日期和时间两部分是缓存的，一秒之内的多条日志只需重新 格式化微秒部分雹，每条日志只需要格式化微秒部分(“.125770Z”)。<br>
•日志消息的前4个字段是定长的，因此可以避免在运行期求字符串长度(不会 反复调用strlen)。因为编译器认识memcpy()函数，对于定长的内存复制, 会在编译期把它inline展开为高效的目标代码。<br>
•线程id是预先格式化为字符串，在输出日志消息时只需简单拷贝几个字节。见 CurrentThread::tidString()。<br>
•每行日志消息的源文件名部分采用了编译期计算来获得basename,避免运行期strrchr(3)开销。见SourceFile class,这里利用了 gcc的内置函数。</p>
<p>多线程异步日志<br>
多线程程序对日志库提出了新的需求：线程安全，即多个线程可以并发写日志, 两个线程的日志消息不会出现交织。线程安全不难办到，简单的办法是用一个全局 mutex保护IO,或者每个线程单独写一个日志文件，但这两种做法的高效性就堪忧了。前者会造成全部线程抢一个锁，后者有可能让业务线程阻塞在写磁盘操作上。<br>
解决办法不难想到，用一个背景线程负责收集日志消息，并写入日志文件, 其他业务线程只管往这个“日志线程”发送日志消息，这称为“异步日志”。<br>
在多线程服务程序中，异步日志（叫“非阻塞日志”似乎更准确）是必需的，因 为如果在网络IO线程或业务线程中直接往磁盘写数据的话，写操作偶尔能阻塞长达数秒之久</p>
<p>我们需要一个“队列”来将日志前端的数据传送到后端（日志线程），但这个 “队列”不必是现成的BlockingQueue<a href="std::string">std::string</a>,因为不用每次产生一条日志消息都通知（notify）接收方。<br>
muduo日志库采用的是双缓冲（double buffering ）技术，基本思路是准备两块buffer： A和B,前端负责往buffer A填数据（日志消息）,后端负责将buffer B 的数据写入文件。当buffer A写满之后，交换A和B,让后端将buffer A的数据写 入文件，而前端则往buffer B填入新的日志消息，如此往复。用两个buffer的好处是 在新建日志消息的时候不必等待磁盘文件操作，也避免每条新日志消息都触发（唤 醒）后端日志线程。换言之，前端不是将一条条日志消息分别传送给后端，而是将多条日志消息拼成一个大的buffer传送给后端，相当于批处理，减少了线程唤醒的频度，降低开销。另外，为了及时将日志消息写入文件，即便buffer A未满，日志库也 会每3秒执行一次上述交换写入操作。</p>
<p>关键代码<br>
实际实现采用了四个缓冲区，这样可以进一步减少或避免日志前端的等待。数据 结构如下(muduo/base/AsyncLogging.h )：</p>
<pre><code>typedef boost::ptr_vector&lt;LargeBuffer&gt;
typedef BufferVector::auto_type
</code></pre>
<p>其中，LargeBuffer 类型是 FixedBuffer class template 的一份具体实现(instantiation ),其大小为4MB,可以存至少1000条日志消息<code>boost::ptr_vector&lt;T&gt;::auto_type</code> 类型类似C++11中的std: :unique_ptr,具备移动语义(move semantics ),而且能自动管理对象生命期。mutex.用于保护后面的四个数据成员。buffers.存放的是供后端写入的buffer</p>
<p>前端在生成一条日志消息的时候会调用AsyncLogging::append()。在这个函数中, 如果当前缓冲(currentBuffer,)剩余的空间足够大,则会直接把日志消息拷贝(追加)到当前缓冲中,这是最常见的情况。这里拷贝一条日志消息并不会带来多大开销。前后端代码的其余部分都没有拷贝，而是简单的指针交换。</p>
<p>否则，说明当前缓冲已经写满，就把它送入(移入)buffers,并试图把预备好的另一块缓冲(nextBuffer_ )移用(move)为当前缓冲,然后追加日志消息并通知(唤醒)后端开始写入日志数据。以上两种情况在临界区之内都没有耗时的操作，运行时间为常数。<br>
如果前端写入速度太快，一下子把两块缓冲都用完了，那么只好分配一块新的 buffer,作为当前缓冲,这是极少发生的情况。</p>
<p>首先准备好两块空闲的buffer,以备在临界区内交换。在临界区内， 等待条件触发,这里的条件有两个：其一是超时，其二是前端写满了一 个或多个buffer。注意这里是非常规的condition variable用法，它没有使用while循环，而且等待时间有上限。<br>
一开始先分配好四个缓冲区A、 B、C、D,前端和后端各持有其中两个。前端和后端各有一个缓冲区数组，初始时都 是空的。<br>
万一前端陷入死循环，拼命发送日志消息，超过后端的处理（输出）能力，会导致什么后果？对于同步日志来说，这不是问题，因为阻塞IO自然就限制了前端的写 入速度，起到了节流阀的作用。但是对于异步日志来说，这就是典型的生产速度高于消费速度问题，会造成数据在内存中堆积，严重时引发性能问题（可用 内存不足）或程序崩溃（分配内存失败）<br>
muduo 日志库处理日志堆积的方法很简单：直接丢掉多余的日志buffer,以腾出内存。这样可以防止日志库本身引起程序故障，是一种自我保护措施。</p>

            </div>
          </article>
        </div>

        
          <div class="next-post">
            <div class="next">下一篇</div>
            <a href="https://lixin-scut.github.io//post/xian-cheng-chi-yu-nei-cun-chi">
              <h3 class="post-title">
                线程池与内存池
              </h3>
            </a>
          </div>
        

        
          
            <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
<script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>

<div id="gitalk-container"></div>

<script>

  var gitalk = new Gitalk({
    clientID: '253c8689f3b11b51dcf1',
    clientSecret: '64df7c097665e7dd6f416ecfaba36581a91bdb63',
    repo: 'Lixin-SCUT.github.io',
    owner: 'Lixin-SCUT',
    admin: ['Lixin-SCUT'],
    id: (location.pathname).substring(0, 49),      // Ensure uniqueness and length less than 50
    distractionFreeMode: false  // Facebook-like distraction free mode
  })

  gitalk.render('gitalk-container')

</script>

          

          
        

        <div class="site-footer">
  Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a> | 
  <a class="rss" href="https://lixin-scut.github.io//atom.xml" target="_blank">RSS</a>
</div>

<script>
  hljs.initHighlightingOnLoad()
</script>

      </div>
    </div>
  </body>
</html>

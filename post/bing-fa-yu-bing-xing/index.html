<html>
  <head>
    <meta charset="utf-8" />
<meta name="description" content="" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>并发与并行、多核与多线程 | Lixin-SCUT</title>
<link rel="shortcut icon" href="https://lixin-scut.github.io//favicon.ico?v=1584193930523">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css" integrity="sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
<link rel="stylesheet" href="https://lixin-scut.github.io//styles/main.css">

<script src="https://cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>
<script src="https://cdn.bootcss.com/moment.js/2.23.0/moment.min.js"></script>



  </head>
  <body>
    <div class="main">
      <div class="main-content">
        <div class="site-header">
  <a href="https://lixin-scut.github.io/">
  <img class="avatar" src="https://lixin-scut.github.io//images/avatar.png?v=1584193930523" alt="">
  </a>
  <h1 class="site-title">
    Lixin-SCUT
  </h1>
  <p class="site-description">
    In the darkest night,rising like a spire.
  </p>
  <div class="menu-container">
    
      
        <a href="/" class="menu">
          首页
        </a>
      
    
      
        <a href="/archives" class="menu">
          时间轴
        </a>
      
    
      
        <a href="/tags" class="menu">
          分类/标签
        </a>
      
    
      
        <a href="/post/about" class="menu">
          关于
        </a>
      
    
  </div>
  <div class="social-container">
    
      
    
      
    
      
    
      
    
      
    
  </div>
</div>


        <div class="post-detail">
          <article class="post">
            <h2 class="post-title">
              并发与并行、多核与多线程
            </h2>
            <div class="post-info">
              <time class="post-time">
                · 2019-12-30 ·
              </time>
              
                <a href="https://lixin-scut.github.io//tag/caA4UQ2wC" class="post-tag">
                  # 操作系统/Linux
                </a>
              
                <a href="https://lixin-scut.github.io//tag/FaScKSk5i" class="post-tag">
                  # 读书笔记
                </a>
              
            </div>
            
            <div class="post-content">
              <p>今天早上在看muduo的方案介绍事产生了一点疑惑<br>
书中的描述：</p>
<blockquote>
<p>方案5：这间小银行有一个旋转门、一个柜台，每次只允许一名客户办理业务。而且当有人在办理业务时，旋转门是锁住的（计算和IO 在同一线程）。为了维持工作效率，银行要求客户应该尽快办理业务，最好不要在取款的时候打电话去问家里人密码，也不要在通过旋转门的时候停下来系鞋带，这都会阻塞其他堵在门外的客户。如果客户很少，这是很经济且高效的方案；但是如果场地较大（多核），则这种布局就浪费了不少资源，只能并发（concurrent）不能并行（parallel）。如果确实一次办不完，应该离开柜台，到门外等着，等银行通知再来继续办理（分阶段回调）</p>
</blockquote>
<p>我的疑惑就在于：但是如果场地较大（多核），则这种布局就浪费了不少资源，只能<strong>并发(concurrent)</strong> 不能<strong>并行（parallel）</strong>。如果确实一次办不完，应该离开柜台，到门外等着，等银行通知再来继续办理（分阶段回调）</p>
<p>一瞬间我发现我对并发和并行的定义有点模糊了，因为我记得并发不是一个进程分为多个部分或者多个进程或多个线程交替执行吗？但是Reactor执行不是顺序执行的吗？</p>
<p>于是我去查了一下<br>
参考<a href="https://www.zhihu.com/question/33515481">并发与并行的区别？</a></p>
<blockquote>
<p>如果某个系统支持两个或者多个动作（Action）同时存在，那么这个系统就是一个<strong>并发系统</strong>。<br>
如果某个系统支持两个或者多个动作同时执行，那么这个系统就是一个<strong>并行系统</strong>。并发系统与并行系统这两个定义之间的关键差异在于“存在”这个词。<br>
并发和并行都可以是很多个线程，就看这些线程能不能同时被（多个）cpu执行，如果可以就说明是并行，而并发是多个线程被（一个）cpu 轮流切换着执行。<br>
并发就是指代码<strong>逻辑上可以并行</strong>，有并行的潜力，但是<strong>不一定当前是真的</strong>以物理并行的方式运行<br>
并发指的是代码的性质，并行指的是<strong>物理运行状态</strong></p>
</blockquote>
<p>然后是翻查CSAPP中的解释：</p>
<blockquote>
<p>一个逻辑流的执行在时间上与另一个流重叠，称为<strong>并发流（concurrent flow）</strong>，这两个流并发地运行<br>
多个流并发地执行的一般现象称为并发（concurrency）。一个进程和其他进程轮流运行的概念称为多任务（multitasking）。一个进程执行它的控制流的一部分的每一时间段叫做时间片（time slice），因此多任务也叫作时间分片（time slicing）；<br>
并发流的思想与流运行的处理器核数或者计算机数无关。如果两个流在时间上重叠，那么它们就是并发的，它是并发流的一个真子集。如果两个流并发地运行在不同的处理器核或者计算机上，那么我们称它们为<strong>并行流（parallel flow）</strong>，它们并行地运行（running in parallel），且并行地执行。<br>
并行流是并发流的真子集，并行流一定是并发流，并发流不一定是并行流。</p>
</blockquote>
<p>看来我对并发和并行的理解并没有错误啊<br>
那就是对Reactor的理解出现了偏差</p>
<p>然后我回去看了方案6和方案7的描述，发现一个问题</p>
<blockquote>
<p>它为每个请求（而不是每个连接）创建了一个新线程（方案6）<br>
每个连接创建一个计算线程，每个连接上的请求固定发给同一个线程去算（方案7）</p>
</blockquote>
<p>注意 连接-请求-线程 这三者！！！特别是一个连接下可以有多个请求！！！而不是必须一个连接一个请求！！！</p>
<p>那么回到方案5的描述 我们可以看到</p>
<blockquote>
<p>如果确实一次办不完，应该离开柜台，到门外等着，等银行通知再来继续办理（分阶段回调）</p>
</blockquote>
<p>这里就是请求的问题了，注意是等待通知而不是重新排队，相当于在并发运行，所以方案5只能并发不能并行就是这么来的</p>
<p>然后另外一个疑惑就是</p>
<blockquote>
<p>方案7 与方案6 的另外一个区别是单个client 的最大CPU 占用率。在方案6 中，一个TCP 连接上发来的一长串突发请求（burst requests）可以占满全部8 个core；而在方案7 中，由于每个连接上的请求固定由同一个线程处理，那么它最多占用12.5%的CPU 资源。</p>
</blockquote>
<p>这里就确实是我的认知出现了偏差，把 一个cpu当前只能运行一个进程+进程是资源分配的最小单位，线程是CPU调度的最小单位 误理解为 一个进程只能在一个cpu上运行（以为它的多线程也只能分配到这个cpu上）（错误的）<br>
这个明显是错误的，一个进程可以在多个cpu上运行，比如一个进程的多个线程可以在多个cpu上运行，这也就是方案6收到突发性爆炸请求占满cpu和方案7只开了8个线程（注意这里假设8个core）每个只占12.5%的由来<br>
但注意！一个线程是只能在一个cpu上跑的，无法切割开来</p>
<p>参考资料<br>
<img src="https://lixin-scut.github.io//post-images/1577669961214.png" alt=""><br>
方案2 这是传统的Java 网络编程方案thread-per-connection，在Java 1.4 引入NIO 之前，Java 网络服务多采用这种方案。它的初始化开销比方案1 要小很多，但与求解Sudoku 的用时差不多，仍然不适合短连接服务。这种方案的伸缩性受到线程数的限制，一两百个还行，几千个的话对操作系统的scheduler 恐怕是个不小的负担。<br>
方案5 基本的单线程Reactor 方案。这种方案的优点是由网络库搞定数据收发，程序只关心业务逻辑；缺点：适合IO 密集的应用，不太适合CPU 密集的应用，因为较难发挥多核的威力。另外，与方案2 相比，方案5 处理网络消息的延迟可能要略大一些，因为方案2 直接一次read(2) 系统调用就能拿到请求数据，而方案5 要先poll(2) 再read(2)，多了一次系统调用。</p>
<p>方案6 这是一个过渡方案，收到Sudoku 请求之后，不在Reactor 线程计算，而是创建一个新线程去计算，以充分利用多核CPU。这是非常初级的多线程应用，因为它为每个请求（而不是每个连接）创建了一个新线程。这个开销可以用线程池来避免，即方案8。这个方案还有一个特点是out-of-order，即同时创建多个线程去计算同一个连接上收到的多个请求，那么算出结果的次序是不确定的，可能第2 个Sudoku 比较简单，比第1 个先算出结果。这也是我们在一开始设计协议的时候使用了id 的原因，以便客户端区分response 对应的是哪个request。</p>
<p>方案7 为了让返回结果的顺序确定，我们可以为每个连接创建一个计算线程，每个连接上的请求固定发给同一个线程去算，先到先得。这也是一个过渡方案，因为并发连接数受限于线程数目，这个方案或许还不如直接使用阻塞IO 的thread-per-connection 方案2。</p>
<p>方案7 与方案6 的另外一个区别是单个client 的最大CPU 占用率。在方案6 中，一个TCP 连接上发来的一长串突发请求（burst requests）可以占满全部8 个core；而在方案7 中，由于每个连接上的请求固定由同一个线程处理，那么它最多占用12.5%的CPU 资源。这两种方案各有优劣，取决于应用场景的需要（到底是公平性重要还是突发性能重要）。这个区别在方案8 和方案9 中同样存在，需要根据应用来取舍。</p>
<p>方案8 为了弥补方案6 中为每个请求创建线程的缺陷，我们使用固定大小线程池，程序结构如图6-12 所示。全部的IO 工作都在一个Reactor 线程完成，而计算任务交给thread pool。如果计算任务彼此独立，而且IO 的压力不大，那么这种方案是非常适用的。</p>
<p>方案9 这是muduo 内置的多线程方案，也是Netty 内置的多线程方案。这种方案的特点是one loop per thread，有一个main Reactor 负责accept(2) 连接，然后把连接挂在某个sub Reactor 中（muduo 采用round-robin 的方式来选择sub Reactor），这样该连接的所有操作都在那个sub Reactor 所处的线程中完成。多个连接可能被分派到多个线程中，以充分利用CPU。</p>
<p>muduo 采用的是固定大小的Reactor pool，池子的大小通常根据CPU 数目确定，也就是说线程数是固定的，这样程序的总体处理能力不会随连接数增加而下降。另外，由于一个连接完全由一个线程管理，那么请求的顺序性有保证，突发请求也不会占满全部8 个核（如果需要优化突发请求，可以考虑方案11）。这种方案把IO 分派给多个线程，防止出现一个Reactor 的处理能力饱和。</p>
<p>与方案8 的线程池相比，方案9 减少了进出thread pool 的两次上下文切换，在把多个连接分散到多个Reactor 线程之后，小规模计算可以在当前IO 线程完成并发回结果，从而降低响应的延迟。我认为这是一个适应性很强的多线程IO 模型，因此把它作为muduo 的默认线程模型（见图6-13）。</p>

            </div>
          </article>
        </div>

        
          <div class="next-post">
            <div class="next">下一篇</div>
            <a href="https://lixin-scut.github.io//post/linux-ji-chu-wen-jian-quan-xian-yu-mu-lu-pei-zhi-niao-ge-linux-di-wu-zhang">
              <h3 class="post-title">
                [Linux基础] 文件权限与目录配置（鸟哥Linux第五章）
              </h3>
            </a>
          </div>
        

        
          
            <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
<script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>

<div id="gitalk-container"></div>

<script>

  var gitalk = new Gitalk({
    clientID: '253c8689f3b11b51dcf1',
    clientSecret: '64df7c097665e7dd6f416ecfaba36581a91bdb63',
    repo: 'Lixin-SCUT.github.io',
    owner: 'Lixin-SCUT',
    admin: ['Lixin-SCUT'],
    id: (location.pathname).substring(0, 49),      // Ensure uniqueness and length less than 50
    distractionFreeMode: false  // Facebook-like distraction free mode
  })

  gitalk.render('gitalk-container')

</script>

          

          
        

        <div class="site-footer">
  Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a> | 
  <a class="rss" href="https://lixin-scut.github.io//atom.xml" target="_blank">RSS</a>
</div>

<script>
  hljs.initHighlightingOnLoad()
</script>

      </div>
    </div>
  </body>
</html>

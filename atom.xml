<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://lixin-scut.github.io/</id>
    <title>Lixin-SCUT</title>
    <updated>2020-03-19T14:48:27.574Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://lixin-scut.github.io/"/>
    <link rel="self" href="https://lixin-scut.github.io//atom.xml"/>
    <subtitle>千里之行，始于足下。不积跬步，无以至千里。</subtitle>
    <logo>https://lixin-scut.github.io//images/avatar.png</logo>
    <icon>https://lixin-scut.github.io//favicon.ico</icon>
    <rights>All rights reserved 2020, Lixin-SCUT</rights>
    <entry>
        <title type="html"><![CDATA[makefile 与 CMakeList]]></title>
        <id>https://lixin-scut.github.io//post/makefile-yu-cmakelist</id>
        <link href="https://lixin-scut.github.io//post/makefile-yu-cmakelist">
        </link>
        <updated>2020-03-19T13:00:54.000Z</updated>
        <content type="html"><![CDATA[<p>这两者可以说是大名鼎鼎了，今天就来认识一下</p>
<h3 id="makefile-与-cmakelist">makefile 与 CMakeList</h3>
<p>  .gcc是GNU Compiler Collection（就是GNU编译器套件），也可以简单认为是编译器，它可以编译很多种编程语言（括C、C++、Objective-C、Fortran、Java等等）。<br>
  当你的程序只有一个源文件时，直接就可以用gcc命令编译它。但是当你的程序包含很多个源文件时，用gcc命令逐个去编译时，你就很容易混乱而且工作量大。<br>
  所以出现了make工具，make工具可以看成是一个智能的批处理工具，它本身并没有编译和链接的功能，而是用类似于批处理的方式—通过调用makefile文件中用户指定的命令来进行编译和链接的。make工具就根据makefile中的命令进行编译和链接的。<br>
  makefile命令中就包含了调用gcc（也可以是别的编译器）去编译某个源文件的命令。makefile在一些简单的工程完全可以人工手写，但是当工程非常大的时候，手写makefile也是非常麻烦的，如果换了个平台makefile又要重新修改。</p>
<p>  这时候就出现了Cmake这个工具，cmake就可以更加简单的生成makefile文件给上面那个make用。当然cmake还有其他功能，就是可以跨平台生成对应平台能用的makefile，你不用再自己去修改了。<br>
  可是cmake根据什么生成makefile呢？它又要根据一个叫CMakeLists.txt文件（学名：组态档）去生成makefile。<br>
  最后CMakeLists.txt文件必须自己手写或者由IDE生成的</p>
<p>  make 是用来执行Makefile的，Makefile是类unix环境下(比如Linux)的类似于批处理的&quot;脚本&quot;文件。其基本语法是: 目标+依赖+命令，只有在目标文件不存在，或目标比依赖的文件更旧，命令才会被执行。<br>
  由此可见，Makefile和make可适用于任意工作，不限于编程。比如，可以用来管理latex。<br>
  Makefile+make可理解为类unix环境下的项目管理工具，但它太基础了，抽象程度不高，而且在windows下不太友好(针对visual studio用户)，于是就有了跨平台项目管理工具cmake，cmake是跨平台项目管理工具，它用更抽象的语法来组织项目。虽然，仍然是目标，依赖之类的东西，但更为抽象和友好，<br>
<img src="https://lixin-scut.github.io//post-images/1584623168910.png" alt=""><br>
<img src="https://lixin-scut.github.io//post-images/1584629291049.png" alt=""></p>
<h3 id="makefile">makefile</h3>
<p>  makefile带来的好处就是“自动化编译”，makefile中会定义一系列的规 则，指定哪些文件需要先编译，哪些文件需要后编译，哪些文件<strong>需要重新编译</strong>，甚至于进行更复杂的功能操作。<br>
<img src="https://lixin-scut.github.io//post-images/1584624719171.png" alt=""><br>
<img src="https://lixin-scut.github.io//post-images/1584624705759.png" alt=""><br>
一个makefile主要含有一系列的规则，如下所示：</p>
<pre><code>A: B
(tab)&lt;command&gt;
(tab)&lt;command&gt;
</code></pre>
<p>每个命令行前都必须有tab符号<br>
  当用户键入&quot;make clean*'命令时，会删除*.o和helloworld文件。写好makefile文件, 在命令行中直接键入make命令，就会执行makefile中的内容了</p>
<p><img src="https://lixin-scut.github.io//post-images/1584626076108.png" alt=""><br>
  这里应用到了变量。要设定一个变量，只要在一行的前端写下这个变量的名字，后面跟一个“=”号，后面跟要设定的这个变量的值即可。以后要引用这个变量，只写一个“$” 符号，后面是在括号里的变量名即可。<br>
  CFLAGS = -Wall -O -g：配置编译器设置，并把它赋值给CFLAGS变量，其中每个部分含义为：①-Wall：输出所有的警告信息；②-O：编译时进行优化；③-g：表示编译debug版本。</p>
<p><img src="https://lixin-scut.github.io//post-images/1584626123870.png" alt=""><br>
  在makefile规则中，通配符会被自动展开。但在变量的定义和函数引用时，通配符将失效。这种情况下如果需要通配符有效，就需要使用函数wildcard,它的用法是：<br>
<code>$(wildcard PATTERN...)</code><br>
  在makefile中，它被展开为已经存在的、使用空格分开的、匹配此模式的所有文件列表。<br>
  如果不存在任何符合此模式的文件，函数会忽略模式字符并返回空。需要注意的是：这种情况下的规则中通配符的展开和上面匹配通配符是有区别的。 下面这一行表示产生一个所有以.c、 .cpp结尾的文件的列表，然后存入变量SOURCES里。<br>
<code>SOURCES = $(wildcard *.c *.cpp)</code><br>
  patsubst函数，'用于匹配替换，有3个参数。第一个是一个需要匹配的式样，第二个表示用什么来替换它，第三个是一个需要被处理的由空格分隔的列表，比如：<br>
<code>$(patsubst %.c,%.o,$(dir))</code><br>
  是指用patsubst把$(击「)中的变量符合后缀是.c的全部替换成.O。<br>
  而下面这一行代码，则 表示把文件列表中所有的.c、.cpp字符变成.o,形成一个新的文件列表，然后存入0BJS变量中。<br>
<code>OBJS = $(patsubst %.c , %.o , $(patsubst %.cpp , %.o , $(SOURCES)))</code><br>
这几句命令表示把所有的.C、.cpp文件编译成.0文件。</p>
<pre><code>% .o ：% . c
			$(CC) $(CFLAGS) -c $&lt; -O $@
%.o : %.cpp
			$(XX) $(CFLAGS) -c $&lt; -O $@
</code></pre>
<p>这里有3个比较有用的内部变量：<br>
①<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">@</mi><mi mathvariant="normal">扩</mi><mi mathvariant="normal">展</mi><mi mathvariant="normal">成</mi><mi mathvariant="normal">当</mi><mi mathvariant="normal">前</mi><mi mathvariant="normal">规</mi><mi mathvariant="normal">则</mi><mi mathvariant="normal">的</mi><mi mathvariant="normal">目</mi><mi mathvariant="normal">的</mi><mi mathvariant="normal">文</mi><mi mathvariant="normal">件</mi><mi mathvariant="normal">名</mi><mi mathvariant="normal">；</mi><mi mathvariant="normal">②</mi></mrow><annotation encoding="application/x-tex">@ 扩展成当前规则的目的文件名；
②</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">@</span><span class="mord cjk_fallback">扩</span><span class="mord cjk_fallback">展</span><span class="mord cjk_fallback">成</span><span class="mord cjk_fallback">当</span><span class="mord cjk_fallback">前</span><span class="mord cjk_fallback">规</span><span class="mord cjk_fallback">则</span><span class="mord cjk_fallback">的</span><span class="mord cjk_fallback">目</span><span class="mord cjk_fallback">的</span><span class="mord cjk_fallback">文</span><span class="mord cjk_fallback">件</span><span class="mord cjk_fallback">名</span><span class="mord cjk_fallback">；</span><span class="mord">②</span></span></span></span>&lt;扩展成依靠列表中的第一个依靠文件；<br>
③而$^扩展成整个依靠的列表(除掉了里面所有重复的文件名)。</p>
<h3 id="cmakelist">CMakeList</h3>
<p>一、Cmake 简介<br>
  cmake 是一个跨平台、开源的构建系统。它是一个集软件构建、测试、打包于一身的软件。它使用与平台和编译器独立的配置文件来对软件编译过程进行控制</p>
<p>二、常用命令</p>
<ol>
<li>
<p>指定 cmake 的最小版本<br>
<code>cmake_minimum_required(VERSION 3.4.1)</code><br>
  这行命令是可选的，我们可以不写这句话，但在有些情况下，如果 CMakeLists.txt 文件中使用了一些高版本 cmake 特有的一些命令的时候，就需要加上这样一行，提醒用户升级到该版本之后再执行 cmake。</p>
</li>
<li>
<p>设置项目名称<br>
<code>project(demo)</code><br>
  这个命令不是强制性的，但最好都加上。它会引入两个变量 demo_BINARY_DIR 和 demo_SOURCE_DIR，同时，cmake 自动定义了两个等价的变量 PROJECT_BINARY_DIR 和 PROJECT_SOURCE_DIR。</p>
</li>
<li>
<p>设置编译类型</p>
</li>
</ol>
<pre><code>add_executable(demo demo.cpp) # 生成可执行文件
add_library(common STATIC util.cpp) # 生成静态库
add_library(common SHARED util.cpp) # 生成动态库或共享库
</code></pre>
<p>  add_library 默认生成是静态库，通过以上命令生成文件名字</p>
<ul>
<li>在 Linux 下是：<br>
demo<br>
libcommon.a<br>
libcommon.so</li>
<li>在 Windows 下是：<br>
demo.exe<br>
common.lib<br>
common.dll</li>
</ul>
<ol start="4">
<li>指定编译包含的源文件<br>
<strong>明确指定包含哪些源文件</strong><br>
<code>add_library(demo demo.cpp test.cpp util.cpp)</code></li>
</ol>
<p><strong>搜索所有的 cpp 文件</strong><br>
  aux_source_directory(dir VAR) 发现一个目录下所有的源代码文件并将列表存储在一个变量中。</p>
<pre><code>aux_source_directory(. SRC_LIST) # 搜索当前目录下的所有.cpp文件
add_library(demo ${SRC_LIST})
</code></pre>
<p><strong>自定义搜索规则</strong></p>
<pre><code>file(GLOB SRC_LIST &quot;*.cpp&quot; &quot;protocol/*.cpp&quot;)
add_library(demo ${SRC_LIST})
# 或者
file(GLOB SRC_LIST &quot;*.cpp&quot;)
file(GLOB SRC_PROTOCOL_LIST &quot;protocol/*.cpp&quot;)
add_library(demo ${SRC_LIST} ${SRC_PROTOCOL_LIST})
# 或者
aux_source_directory(. SRC_LIST)
aux_source_directory(protocol SRC_PROTOCOL_LIST)
add_library(demo ${SRC_LIST} ${SRC_PROTOCOL_LIST})
</code></pre>
<ol start="5">
<li>查找指定的库文件<br>
  find_library(VAR name path)查找到指定的预编译库，并将它的路径存储在变量中。<br>
  默认的搜索路径为 cmake 包含的系统库，因此如果是 NDK 的公共库只需要指定库的 name 即可。</li>
</ol>
<pre><code>find_library( # Sets the name of the path variable.
              log-lib
 
              # Specifies the name of the NDK library that
              # you want CMake to locate.
              log )
</code></pre>
<p>  类似的命令还有 find_file()、find_path()、find_program()、find_package()。</p>
<ol start="6">
<li>设置包含的目录</li>
</ol>
<pre><code>include_directories(
    ${CMAKE_CURRENT_SOURCE_DIR}
    ${CMAKE_CURRENT_BINARY_DIR}
    ${CMAKE_CURRENT_SOURCE_DIR}/include
)
</code></pre>
<p>  Linux 下还可以通过如下方式设置包含的目录<br>
<code>set(CMAKE_CXX_FLAGS &quot;${CMAKE_CXX_FLAGS} -L${CMAKE_CURRENT_SOURCE_DIR}&quot;)</code></p>
<ol start="7">
<li>设置链接库搜索目录</li>
</ol>
<pre><code>link_directories(
    ${CMAKE_CURRENT_SOURCE_DIR}/libs
)
</code></pre>
<p>  Linux 下还可以通过如下方式设置包含的目录</p>
<pre><code>set(CMAKE_CXX_FLAGS &quot;${CMAKE_CXX_FLAGS} -L${CMAKE_CURRENT_SOURCE_DIR}/libs&quot;)
</code></pre>
<ol start="8">
<li>设置 target 需要链接的库</li>
</ol>
<pre><code>target_link_libraries( # 目标库
                       demo
 
                       # 目标库需要链接的库
                       # log-lib 是上面 find_library 指定的变量名
                       ${log-lib} )
</code></pre>
<p>  在 Windows 下，系统会根据链接库目录，搜索xxx.lib 文件，Linux 下会搜索 xxx.so 或者 xxx.a 文件，如果都存在会优先链接动态库（so 后缀）。</p>
<p><strong>指定链接动态库或静态库</strong></p>
<pre><code>target_link_libraries(demo libface.a) # 链接libface.a
target_link_libraries(demo libface.so) # 链接libface.so
</code></pre>
<p>  指定全路径</p>
<pre><code>target_link_libraries(demo ${CMAKE_CURRENT_SOURCE_DIR}/libs/libface.a)
target_link_libraries(demo ${CMAKE_CURRENT_SOURCE_DIR}/libs/libface.so)
</code></pre>
<p>  指定链接多个库</p>
<pre><code>target_link_libraries(demo
    ${CMAKE_CURRENT_SOURCE_DIR}/libs/libface.a
    boost_system.a
    boost_thread
    pthread)
</code></pre>
<ol start="9">
<li>设置变量<br>
<strong>set 直接设置变量的值</strong></li>
</ol>
<pre><code>set(SRC_LIST main.cpp test.cpp)
add_executable(demo ${SRC_LIST})
</code></pre>
<p><strong>set 追加设置变量的值</strong></p>
<pre><code>set(SRC_LIST main.cpp)
set(SRC_LIST ${SRC_LIST} test.cpp)
add_executable(demo ${SRC_LIST})
</code></pre>
<p><strong>list 追加或者删除变量的值</strong></p>
<pre><code>set(SRC_LIST main.cpp)
list(APPEND SRC_LIST test.cpp)
list(REMOVE_ITEM SRC_LIST main.cpp)
add_executable(demo ${SRC_LIST})
</code></pre>
<ol start="10">
<li>条件控制<br>
<strong>if…elseif…else…endif</strong></li>
</ol>
<p><strong>逻辑判断和比较：</strong><br>
if (expression)：expression 不为空（0,N,NO,OFF,FALSE,NOTFOUND）时为真<br>
if (not exp)：与上面相反<br>
if (var1 AND var2)<br>
if (var1 OR var2)<br>
if (COMMAND cmd)：如果 cmd 确实是命令并可调用为真<br>
if (EXISTS dir) if (EXISTS file)：如果目录或文件存在为真<br>
if (file1 IS_NEWER_THAN file2)：当 file1 比 file2 新，或 file1/file2 中有一个不存在时为真，文件名需使用全路径<br>
if (IS_DIRECTORY dir)：当 dir 是目录时为真<br>
if (DEFINED var)：如果变量被定义为真<br>
if (var MATCHES regex)：给定的变量或者字符串能够匹配正则表达式 regex 时为真，此处 var 可以用 var 名，也可以用 ${var}<br>
if (string MATCHES regex)</p>
<p><strong>数字比较：</strong><br>
if (variable LESS number)：LESS 小于<br>
if (string LESS number)<br>
if (variable GREATER number)：GREATER 大于<br>
if (string GREATER number)<br>
if (variable EQUAL number)：EQUAL 等于<br>
if (string EQUAL number)</p>
<p><strong>字母表顺序比较：</strong><br>
if (variable STRLESS string)<br>
if (string STRLESS string)<br>
if (variable STRGREATER string)<br>
if (string STRGREATER string)<br>
if (variable STREQUAL string)<br>
if (string STREQUAL string)</p>
<p>示例：</p>
<pre><code>if(MSVC)
    set(LINK_LIBS common)
else()
    set(boost_thread boost_log.a boost_system.a)
endif()
target_link_libraries(demo ${LINK_LIBS})

# 或者
if(UNIX)
    set(CMAKE_CXX_FLAGS &quot;${CMAKE_CXX_FLAGS} -std=c++11 -fpermissive -g&quot;)
else()
    add_definitions(-D_SCL_SECURE_NO_WARNINGS
    D_CRT_SECURE_NO_WARNINGS
    -D_WIN32_WINNT=0x601
    -D_WINSOCK_DEPRECATED_NO_WARNINGS)
endif()
 
if(${CMAKE_BUILD_TYPE} MATCHES &quot;debug&quot;)
    ...
else()
    ...
endif()
</code></pre>
<p><strong>while…endwhile</strong></p>
<pre><code>while(condition)
    ...
endwhile()
</code></pre>
<p><strong>foreach…endforeach</strong></p>
<pre><code>foreach(loop_var RANGE start stop [step])
    ...
endforeach(loop_var)
</code></pre>
<p>  start 表示起始数，stop 表示终止数，step 表示步长，示例：</p>
<pre><code>foreach(i RANGE 1 9 2)
    message(${i})
endforeach(i)

# 输出：13579
</code></pre>
<ol start="11">
<li>打印信息</li>
</ol>
<pre><code>message(${PROJECT_SOURCE_DIR})
message(&quot;build with debug mode&quot;)
message(WARNING &quot;this is warnning message&quot;)
message(FATAL_ERROR &quot;this build has many error&quot;) # FATAL_ERROR 会导致编译失败
</code></pre>
<ol start="12">
<li>包含其它 cmake 文件</li>
</ol>
<pre><code>include(./common.cmake) # 指定包含文件的全路径
include(def) # 在搜索路径中搜索def.cmake文件
set(CMAKE_MODULE_PATH ${CMAKE_CURRENT_SOURCE_DIR}/cmake) # 设置include的搜索路径
</code></pre>
<p>三、常用变量</p>
<ol>
<li>
<p>预定义变量<br>
PROJECT_SOURCE_DIR：工程的根目录<br>
PROJECT_BINARY_DIR：运行 cmake 命令的目录，通常是 ${PROJECT_SOURCE_DIR}/build<br>
PROJECT_NAME：返回通过 project 命令定义的项目名称<br>
CMAKE_CURRENT_SOURCE_DIR：当前处理的 CMakeLists.txt 所在的路径<br>
CMAKE_CURRENT_BINARY_DIR：target 编译目录<br>
CMAKE_CURRENT_LIST_DIR：CMakeLists.txt 的完整路径<br>
CMAKE_CURRENT_LIST_LINE：当前所在的行<br>
CMAKE_MODULE_PATH：定义自己的 cmake 模块所在的路径，SET(CMAKE_MODULE_PATH ${PROJECT_SOURCE_DIR}/cmake)，然后可以用INCLUDE命令来调用自己的模块<br>
EXECUTABLE_OUTPUT_PATH：重新定义目标二进制可执行文件的存放位置<br>
LIBRARY_OUTPUT_PATH：重新定义目标链接库文件的存放位置</p>
</li>
<li>
<p>环境变量<br>
使用环境变量<br>
<code>$ENV{Name}</code><br>
写入环境变量<br>
<code>set(ENV{Name} value) # 这里没有“$”符号</code></p>
</li>
<li>
<p>系统信息<br>
CMAKE_MAJOR_VERSION：cmake 主版本号，比如 3.4.1 中的 3<br>
CMAKE_MINOR_VERSION：cmake 次版本号，比如 3.4.1 中的 4<br>
CMAKE_PATCH_VERSION：cmake 补丁等级，比如 3.4.1 中的 1<br>
CMAKE_SYSTEM：系统名称，比如 Linux-2.6.22<br>
CMAKE_SYSTEM_NAME：不包含版本的系统名，比如 Linux<br>
CMAKE_SYSTEM_VERSION：系统版本，比如 2.6.22<br>
CMAKE_SYSTEM_PROCESSOR：处理器名称，比如 i686<br>
UNIX：在所有的类 UNIX 平台下该值为 TRUE，包括 OS X 和 cygwin<br>
WIN32：在所有的 win32 平台下该值为 TRUE，包括 cygwin</p>
</li>
<li>
<p>主要开关选项<br>
BUILD_SHARED_LIBS：这个开关用来控制默认的库编译方式，如果不进行设置，使用 add_library 又没有指定库类型的情况下，默认编译生成的库都是静态库。如果 set(BUILD_SHARED_LIBS ON) 后，默认生成的为动态库<br>
CMAKE_C_FLAGS：设置 C 编译选项，也可以通过指令 add_definitions() 添加<br>
CMAKE_CXX_FLAGS：设置 C++ 编译选项，也可以通过指令 add_definitions() 添加<br>
<code>add_definitions(-DENABLE_DEBUG -DABC) # 参数之间用空格分隔</code></p>
</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[上下文切换]]></title>
        <id>https://lixin-scut.github.io//post/shang-xia-wen-qie-huan</id>
        <link href="https://lixin-scut.github.io//post/shang-xia-wen-qie-huan">
        </link>
        <updated>2020-03-19T08:50:57.000Z</updated>
        <content type="html"><![CDATA[<h3 id="linux进程控制">Linux进程控制</h3>
<ul>
<li>进程地址空间（地址空间）<br>
  虚拟内存机制为每个进程提供了独占系统地址空间的假象。尽管每个进程地址空间内容不尽相同，但是他们的都有相似的结构。Linux进程的地址空间底部是保留给用户程序的，包括文本、数据、堆、栈等，其中文本区和数据区是通过存储器映射方式将磁盘中可执行文件的相应段映射至虚拟存储器地址空间中。<br>
  有一些&quot;敏感&quot;的地址需要注意下，从0xC0000000开始到0xFFFFFFFF是内核地址空间，通常情况下代码运行在用户态（使用0x00000000 ~ 0xC00000000的用户地址空间，对于32位进程来说，代码段从0x08048000开始），当发生系统调用、进程切换等操作时CPU控制寄存器设置模式位，进入内核模式，在该状态下进程可以访问全部存储器位置和执行全部指令。也就说32位进程的地址空间都是4G，但用户态下只能访问低3G的地址空间，若要访问3G ~ 4G的地址空间则只有进入内核态。</li>
<li>进程控制块（处理机）<br>
  进程的调度实际就是内核选择相应的进程控制块，被选择的进程控制块中包含了一个进程基本的信息。</li>
<li>上下文切换<br>
  内核管理所有进程控制块，而进程控制块记录了进程全部状态信息。每一次进程调度就是一次上下文切换，所谓的上下文本质上就是当前运行状态，主要包括通用寄存器、浮点寄存器、状态寄存器、程序计数器、用户栈和内核数据结构（页表、进程表、文件表）等。进程执行时刻，内核可以决定抢占当前进程并开始新的进程，这个过程由内核调度器完成，当调度器选择了某个进程时称为该进程被调度，该过程通过上下文切换来改变当前状态。一次完整的上下文切换通常是进程原先运行于用户态，之后因系统调用或时间片到切换到内核态执行内核指令，完成上下文切换后回到用户态，此时已经切换到进程B。</li>
</ul>
<h3 id="线程与进程">线程与进程</h3>
<p>  操作系统管理很多进程的执行。有些进程是来自各种程序、系统和应用程序的单独进程，而某些进程来自被分解为很多进程的应用或程序。当一个进程从内核中移出，另一个进程成为活动的，这些进程之间便发生了上下文切换。操作系统必须记录重启进程和启动新进程使之活动所需要的所有信息。这些信息被称作上下文，它描述了进程的现有状态。当进程成为活动的，它可以继续从被抢占的位置开始执行。<br>
进程的上下文信息包括：</p>
<ul>
<li>进程id</li>
<li>指向可执行文件的指针</li>
<li>栈</li>
<li>静态和动态分配的变量的内存</li>
<li>处理器寄存器<br>
等等</li>
</ul>
<p>  进程的上下文的多数信息都与地址空间的描述有关。进程的上下文使用很多系统资源，而且会花费一些时间来从一个进程的上下文切换到另一个进程的上下文。</p>
<p>  线程也有上下文。当线程被抢占时，就会发生线程之间的上下文切换。如果线程属于相同的进程，它们共享相同的地址空间，因为线程包含在它们所属于的进程的地址空间内。这样，进程需要恢复的多数信息对于线程而言是不需要的。尽管进程和它的线程共享了很多内容，但最为重要的是其地址空间和资源，有些信息对于线程而言是本地且唯一的，而线程的其他方面包含在进程的各个段的内部。</p>
<table>
<thead>
<tr>
<th style="text-align:center">上下文内容</th>
<th style="text-align:center">进    程</th>
<th style="text-align:center">线    程</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">指向可执行文件的指针</td>
<td style="text-align:center">●</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">栈</td>
<td style="text-align:center">●</td>
<td style="text-align:center">●</td>
</tr>
<tr>
<td style="text-align:center">内存(数据段和堆)</td>
<td style="text-align:center">●</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">状态</td>
<td style="text-align:center">●</td>
<td style="text-align:center">●</td>
</tr>
<tr>
<td style="text-align:center">优先级</td>
<td style="text-align:center">●</td>
<td style="text-align:center">●</td>
</tr>
<tr>
<td style="text-align:center">程序I/O的状态</td>
<td style="text-align:center">●</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">授予权限</td>
<td style="text-align:center">●</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">调度信息</td>
<td style="text-align:center">●</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">审计信息</td>
<td style="text-align:center">●</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">有关资源的信息-文件描述符-读/写指针</td>
<td style="text-align:center">●</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">有关事件和信号的信息</td>
<td style="text-align:center">●</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">寄存器组 -栈指针 -指令计数器 -诸如此类</td>
<td style="text-align:center">●</td>
<td style="text-align:center">●</td>
</tr>
</tbody>
</table>
<p>  对线程唯一或本地的信息包括线程id、处理器寄存器(当线程执行时寄存器的状态，包括程序计数器和栈指针)、线程状态及优先级、线程特定数据(thread-specific data，TSD)。线程id是在创建线程时指定的。线程能够访问它所属进程的数据段，因此线程可以读写它所属进程的全局声明数据。进程中一个线程做出的任何改动都可以被进程中的所有线程以及主线程获得。在多数情况下，这要求某种类型的同步以防止无意的更新。线程的局部声明变量不应当被任何对等线程访问。它们被放置到线程栈中，而且当线程完成时，它们便会被从栈中移走。</p>
<p>  TSD是一种结构体，包含线程私有的数据和信息。TSD可以包含进程全局数据的私有副本，还可以包含线程的信号掩码。信号掩码用来识别特定类型的信号，这些信号在发送给进程时不会被该线程接收。否则，如果操作系统给进程发送一个信号，进程的地址空间中的所有线程也会接收到那个信号。线程会接收所有没有被掩码遮蔽的信号。</p>
<p>  线程与它所属的进程共享代码段和栈段。它的指令指针指向进程的代码段的某个位置，是下一条可执行的线程指令，而且栈指针指向进程栈中线程的栈的顶部位置。线程还可以访问任何环境变量。进程的所有资源(例如文件描述符)都将与线程共享。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[pthread_once()]]></title>
        <id>https://lixin-scut.github.io//post/pthread_once</id>
        <link href="https://lixin-scut.github.io//post/pthread_once">
        </link>
        <updated>2020-03-19T01:24:52.000Z</updated>
        <content type="html"><![CDATA[<p>  在多线程环境中，有些事仅需要执行一次。通常当初始化应用程序时，可以比较容易地将其放在main函数中。但当写一个库时，就不能在main里面初始化了，此时可以用静态初始化，但使用一次初始化（pthread_once）会比较容易些。</p>
<pre><code>pthread_once_t once_control = PTHREAD_ONCE_INIT;
int pthread_once(pthread_once_t *once_control, void (*init_routine) (void))；
</code></pre>
<p><strong>功能：</strong><br>
  本函数使用初值为PTHREAD_ONCE_INIT的once_control变量保证init_routine()函数在本进程执行序列中仅执行一次。<br>
  在多线程编程环境下，尽管pthread_once()调用会出现在多个线程中，init_routine()函数仅执行一次，究竟在哪个线程中执行是不定的，是由内核调度来决定。</p>
<p><strong>底层：</strong><br>
  Linux Threads使用互斥锁和条件变量保证由pthread_once()指定的函数执行且仅执行一次，而once_control表示是否执行过。<br>
  如果once_control的初值不是PTHREAD_ONCE_INIT（Linux Threads定义为0），pthread_once() 的行为就会不正常。<br>
  在LinuxThreads中，实际&quot;一次性函数&quot;的执行状态有三种：NEVER（0）、IN_PROGRESS（1）、DONE （2），如果once初值设为1，则由于所有pthread_once()都必须等待其中一个激发&quot;已执行一次&quot;信号，因此所有pthread_once()都会陷入永久的等待中；如果设为2，则表示该函数已执行过一次，从而所有pthread_once()都会立即返回0。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[调度]]></title>
        <id>https://lixin-scut.github.io//post/diao-du</id>
        <link href="https://lixin-scut.github.io//post/diao-du">
        </link>
        <updated>2020-03-18T09:32:53.000Z</updated>
        <content type="html"><![CDATA[<p>  当计算机系统是多道程序设计系统时，通常就会有多个进程或线程同时竞争CPU。只要有两个或更多的进程处于就绪状态，如果只有一个CPU可用，那么就必须选择下一个要运行的进程。在操作系统中，完成选择工作的这一部分称为调度程序（scheduler）,该程序使用的算法称为调 度算法（scheduling algorithm）。</p>
<p>  进程切换的代价是比较高的。<br>
  首先用户态必须切换到内核态，然后要保存当前进程的状态，包括在进程表中存储寄存器值以便以 后重新装载。在许多系统中，内存映像（例如，页表内的内存访问位）也必须保存，<br>
  接着，通过运行调 度算法选定一个新进程之后，应该将新进程的内存映像重新装入MMU,最后新进程开始运行。<br>
  除此 之外，进程切换还要使整个内存高速缓存失效，强迫缓存从内存中动态重新装入两次（进入内核一次， 离开内核一次）。<br>
  总之，如果每秒钟切换进程的次数太多，会耗费大量CPU时间，所以有必要提醒注意。</p>
<p><strong>进程行为</strong><br>
  某些进程花费了绝大多数时间在计算上，而 其他进程则在等待I/O上花费了绝大多数时间。前者称为计算密集型（compute-bound）, 后者称为I/O密集型（I/O-bound）。<br>
  典型的计算密集型进程具有较长时间的CPU集中使用和较小频度的 I/O等待。 I/O密集型进程具有较短时间的CPU集中使用和频繁的I/O等待。它是I/O类的，因为这种进程 在I/O请求之间较少进行计算，并不是因为它们有转别长的I/O请求。在I/O开始后无论处理数据是多还是少，它们都花费同样的时间提出硬件请求读取磁盘块。</p>
<p><strong>何时调度</strong><br>
  第一，在创建一个新进程之后，需要决定是运行父进程还是运行子进程。由于这两种进程都处于就绪状态，所以这是一 种正常的调度决策，可以任意决定，也就是说，调度程序可以合法选择先运行父进程还是先运行子进程。<br>
  第二，在一个进程退出时必须做出调度决策。一个进程不再运行（因为它不再存在），所以必须从 就绪进程集中选择另外某个进程。如果没有就绪的进程，通常会运行一个系统提供的空闲进程。<br>
  第三，当一个进程阻塞在I/O和信号最上或由于其他原因阻塞时，必须选择另一个进程运行。<br>
  第四，在一个I/O中断发生时，必须做出调度决策。如果中断来自I/O设备，而该设备现在完成了工作，某些被阻塞的等待该I/O的进程就成为可运行的就绪进程。是否让新就绪的进程运行，这取决于 调度程序的决定，或者让中断发生时运行的进程继续运行，或者应该让某个其他进程运行。</p>
<p><strong>调度算法分类</strong><br>
根据如何处理时钟中断，可以把调度算法分为两类。<br>
  非抢占式调度算法挑选一个进 程，然后让该进程运行直至被阻塞（阻塞在I/O上或等待另一个进程），或者直到该进程自动释放CPU。 即使该进程运行了若干个小时，它也不会被强迫挂起。这样做的结果是，在时钟中断发生时不会进行调 度。在处理完时钟中断后，如果没有更高优先级的进程等待到时，则被中断的进程会继续执行。<br>
  相反，抢占式调度算法挑选一个进程，并且让该进程运行某个固定时段的最大值。如果在该时段结 束时，该进程仍在运行，它就被挂起，而调度程序挑选另一个进程运行（如果存在一个就绪进程）。进 行抢占式调度处理，需要在时间间隔的末端发生时钟中断，以便把CPU控制返回给调度程序。如果没有 可用的时钟，那么非抢占式调度就是惟一的选择了。</p>
<p><strong>调度算法分类</strong><br>
在不同的系统中，调度程序的优化是不同的。这里有必要 划分出三种环境：<br>
1）	批处理。<br>
2）	交互式。<br>
3）	实时。</p>
<p><strong>调度算法的目标</strong><br>
<img src="https://lixin-scut.github.io//post-images/1584525112161.png" alt=""></p>
<p><strong>策略和机制</strong><br>
  将调度机制（scheduling mechanism）与调度策略（scheduling policy）分离，也就是将调度算法以某种形式参数化，而参数可以由用户进程填写。</p>
<p><strong>线程调度</strong><br>
  当若干进程都有多个线程时，就存在两个层次的并行：进程和线程。在这样的系统中调度处理有本 质差别，这取决于所支持的是用户级线程还是内核级线程（或两者都支持）。<br>
  首先考虑用户级线程。由于内核并不知道有线程存在，所以内核还是和以前一样地操作，选取一个进程，并给予时间片控制。进程中的线程调度程序决定哪个线程运行。由于多 道线程并不存在时钟中断，所以这个线程可以按其意愿任意运行多长时间。如果该线程用完了进程的全 部时间片，内核就会选择另一个进程运行。<br>
  在进程终于又一次运行时，线程会接着运行。该线程会继续耗费进程的所有时间片，直到它完成工作。不过，该线程的这种不合群的行为不会影响到其他的进程。其他进程会得到调度程序所分配的 合适份额，不会考虑进程内部所发生的事。<br>
<img src="https://lixin-scut.github.io//post-images/1584525832250.png" alt=""><br>
  现在考虑使用内核级线程的情形。内核选择一个特定的线程运行。它不用考虑该线程属于哪个进程， 不过如果有必要的话，它可以这样做。对被选择的线程赋予一个时间片，而旦如果超过了时间片，就会 强制挂起该线程。</p>
<p><strong>内核线程与用户线程调度的区别</strong><br>
用户级线程和内核级线程之间的差别在于性能。用户级线程的线程切换需要少量的机器指令，而内核级线程需要完整的上下文切换，修改内存映像，使高速缓存失效，这导致了若干数量级的延退。<br>
  从进程A的一个线程切换到进程B的一个线程，其代价高于运行进程A的第2个线程（因为必须修改 内存映像，清除内存高速缓存的内容），内核对此是了解的，并可运用这些信息做出决定。例如，给定两个在其他方面同等重要的线程，其中一个线程与刚好阻塞的线程属于同一个进程，而另一个线程属于 其他的进程，那么应该倾向前者。<br>
  另一个重要因素是用户级线程可以使用专为应用程序定制的线程调度程序。由于运行系统了解所有线程的作用，所以会直接选择分派线程接着运行，这样分派线程就会启动另一个工作线程运行。在一个工作线程经常阻塞在磁盘I/O上的环境中，这个策略将并行度最大化。 而在内核级线程中，内核从来不了解每个线程的作用（虽然它们被赋予了不同的优先级）。不过，一般而言，应用定制的线程调度程序能够比内核更好地满足应用的需要。</p>
<p><strong>批处理系统中的调度</strong></p>
<ol>
<li>先来先服务<br>
  最简单的是非抢占式的先来先服务(first-come first-severd)算法。使用该算 法，进程按照它们请求CPU的顺序使用CPU。基本上，有一个就绪进程的单一队列。</li>
<li>最短作业优先<br>
  适用于运行时间可以预知的另一个非抢占式的批处理调度算法。</li>
<li>最短剩余时间优先<br>
  最短作业优先的抢占式版本是景短剩余时间优先(shortest remaining time next)算法。使用这个算 法，调度程序总是选择剩余运行时间最短的那个进程运行。再次提醒，有关的运行时间必须提前掌握。 当一个新的作业到达时，其整个时间同当前进程的剩余时间做比较。如果新的进程比当前运行进程需要 更少的时间，当前进程就被挂起，而运行新的进程。</li>
</ol>
<p><strong>交互式系统中的调度</strong><br>
  现在考察用于交互式系统中的一些调度算法，它们在个人计算机、服务器和其他类系统中都是常用的。</p>
<ol>
<li>轮转调度<br>
  一种最古老、最简单、最公平且使用最广的算法是轮转调度(round robin)。每个进程被分配一个 时间段，称为时间片(quantum),即允许该进程在该时间段中运行。如果在时间片结束时该进程还在运 行，则将剥夺CPU并分配给另一个进程。如果该进程在时间片结束前阻塞或结束，则CPU立即进行切换。当一 个进程用完它的时间片后，就被移到队列的末尾<br>
  时间片轮转调度中惟一有趣的一点是时间片的长度。CPU时间的20%浪费在管理开 销上。<br>
  时间片设得太短会导致过多的进程切换，降低了CPU效率，而设得太长又可能 引起对短的交互请求的响应时间变长。将时间片设为20ms~50 ms通常是一个比较合理的折中。</li>
<li>优先级调度<br>
  轮转调度做了一个隐含的假设，即所有的进程同等重要，但外部因素考虑在内的需要就导致了优先级调度。其基本思想很清楚：每个进程被赋予一个优先级，允许优先级最高的可运行进程先运行。<br>
  为了防止高优先级进程无休止地运行下去，调度程序可以在每个时钟滴答(即每个时钟中断)降低 当前进程的优先级。如果这个动作导致该进程的优先级低于次高优先级的进程，则进行进程切换。一个可采用的方法是，每个进程可以被赋予一个允许运行的最大时间片，当这个时间片用完时，下一个次高 优先级的进程获得机会运行。<br>
  优先级可以是静态赋予或动态赋予。如果不偶尔对优先级进行调整，则低优先级 进程很可能会产生饥饿现象。</li>
<li>多级队列<br>
  如前所述，长时间片的进程又会影响到响应时间，其解决办法是设立优先级类。属于最高优先级类的进程运行一个时间片，属于次高优先级类的进程运行2个时间片，再次一级运行4个时间片，以此类推。当一个进程用完分配的时间片后，它被移到下一类。</li>
<li>最短进程优先</li>
<li>保证调度</li>
<li>彩票调度</li>
<li>公平分享调度</li>
</ol>
<p><strong>实时系统中的调度</strong><br>
  实时系统通常可以分为硬实时（hard real time）和软实时（soft real time）,前者的含义是必须满足绝对的截止时间，后者的含义是虽然不希望偶尔错失截止时间，但是可以容忍。<br>
  实时系统中的事件可以按照响应方式进一步分类为周期性（以规则的时间间隔发生）事件或非周期 性（发生时间不可预知）事件。<br>
  实时系统使用的调度算法可以是上面介绍的算法中的任意一种。从实用考虑，轮转调度和优先级调度更为常用。惟一的局限是，缺乏一个时钟将运行过长的线程加以中断。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[用户态和内核态]]></title>
        <id>https://lixin-scut.github.io//post/yong-hu-tai-he-nei-he-tai</id>
        <link href="https://lixin-scut.github.io//post/yong-hu-tai-he-nei-he-tai">
        </link>
        <updated>2020-03-18T08:35:09.000Z</updated>
        <content type="html"><![CDATA[<h3 id="用户态和内核态">用户态和内核态</h3>
<p>  当一个任务（进程）执行系统调用而陷入内核代码中执行时，我们就称进程处于内核运行态（或简称为内核态）。此时处理器处于特权级最高的（0级）内核代码中执行。<br>
  当进程处于内核态时，执行的内核代码会使用当前进程的内核栈。每个进程都有自己的内核栈。当进程在执行用户自己的代码时，则称其处于用户运行态（用 户态）。即此时处理器在特权级最低的（3级）用户代码中运行。<br>
  用户运行一个程序，该程序所创建的进程开始是运行在用户态的，如果要执行文件操作，网络数据发送等操作，必须通过write，send等系统调用，这些系统调用会调用内核中的代码来完成操作，这时，必须切换到Ring0，然后进入3GB-4GB中的内核地址空间去执行这些代码完成操作，完成后，切换回Ring3，回到用户态。这样，用户态的程序就不能 随意操作内核地址空间，具有一定的安全保护作用。</p>
<h3 id="区分内核态和用户态的原因">区分内核态和用户态的原因</h3>
<p>  在CPU中运行的操作系统程序和用户程序对应的机器指令集是不同的。操作系统程序使用所有指令，但用户程序只能使用部分指令。从资源管理和程序控制执行的角度出发，将指令系统分为两大部分：特权指令和非特权指令。在程序执行时，根据执行程序对资源和机器指令的使用权限，把机器设置为两个状态：内核态和用户态。<br>
  避免代码进行潜在危险的操作，以防止给操作系统带来安全隐患。系统调用与返回的情况下进行两种方式的转换。<br>
  用户态状态下，执行的代码被硬件限定，不能进行某些操作，比如写入其他进程的存储空间，以防止给操作系统带来安全隐患。内核禁止此状态下的代码进行潜在危险的操作，比如写入系统配置文件、杀掉其他用户的进程、重启系统等。</p>
<h3 id="用户态切换到内核态的3种方式">用户态切换到内核态的3种方式：</h3>
<ol>
<li>系统调用<br>
这是用户态进程主动要求切换到内核态的一种方式，用户态进程通过系统调用申请使用操作系统提供的服务程序完成工作，比如前例中fork()实际上就是执行了一个创建新进程的系统调用。而系统调用的机制其核心还是使用了操作系统为用户特别开放的一个中断来实现，例如Linux的int 80h中断。</li>
<li>异常<br>
当CPU在执行运行在用户态下的程序时，发生了某些事先不可知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关程序中，也就转到了内核态，比如缺页异常。</li>
<li>外围设备的中断<br>
当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序，如果先前执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了由用户态到内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[编译与链接]]></title>
        <id>https://lixin-scut.github.io//post/bian-yi-yu-lian-jie</id>
        <link href="https://lixin-scut.github.io//post/bian-yi-yu-lian-jie">
        </link>
        <updated>2020-03-18T07:55:50.000Z</updated>
        <content type="html"><![CDATA[<p>其实叫编译过程是不对的，因为编译与链接都只是C++文本文件到可执行文件的一环，但是似乎大家是是习惯了叫做编译，我也暂时没想到好的名称来代替，就暂时只用这个博文名吧。</p>
<p><strong>预处理</strong></p>
<ul>
<li>
<p>展开所有的宏定义，完成字符常量替换。</p>
</li>
<li>
<p>处理条件编译语句，通过是否具有某个宏来决定过滤掉哪些代码。</p>
</li>
<li>
<p>处理#include指令，将被包含的文件插入到该指令所在位置。</p>
</li>
<li>
<p>过滤掉所有注释语句。</p>
</li>
<li>
<p>添加行号和文件名标识。</p>
</li>
<li>
<p>保留所有#pragma编译器指令。</p>
</li>
</ul>
<p><strong>编译</strong></p>
<ul>
<li>
<p>词法分析。</p>
</li>
<li>
<p>语法分析。</p>
</li>
<li>
<p>语义分析。</p>
</li>
<li>
<p>中间语言生成。</p>
</li>
<li>
<p>目标代码生成与优化。</p>
</li>
</ul>
<p><strong>链接</strong></p>
<p>各个源代码模块独立的被编译，然后将他们组装起来成为一个整体，组装的过程就是链接。被链接的各个部分本本身就是二进制文件，所以在被链接时需要将所有目标文件的代码段拼接在一起，然后将所有对符号地址的引用加以修正。</p>
<ul>
<li>
<p>静态链接</p>
<p>静态链接最简单的情况就是在编译时和静态库链接在一起成为完整的可执行程序。这里所说的静态库就是对多个目标文件（.o）文件的打包，通常静态链接的包名为<code>lib****.a</code>，静态链接所有被用到的目标文件都会复制到最终生成的可执行目标文件中。这种方式的好处是在运行时，可执行目标文件已经完全装载完毕，只要按指令序执行即可，速度比较快，但缺点也有很多</p>
</li>
</ul>
<p>静态链接是对目标文件的打包，打包命令如下</p>
<pre><code>    gcc -c test1.c    // 生成test1.o
    gcc -c test2.c    // 生成test2.c
    ar cr libtest.a test1.o test2.o
</code></pre>
<p>首先编译得到test1.o和test2.o两个目标文件，之后通过ar命令将这两个文件打包为.a文件，文件名格式为lib + 静态库名 + .a后缀。在生成可执行文件需要使用到它的时候只需要在编译时加上即可。需要注意的是，使用静态库时加在最后的名字不是libtest.a，而是l + 静态库名。</p>
<pre><code>    gcc -o main main.c -ltest
</code></pre>
<ul>
<li>
<p>动态链接</p>
<p>静态链接发生于编译阶段，加载至内存前已经完整，但缺点是如果多个程序都需要使用某个静态库，则该静态库会在每个程序中都拷贝一份，非常浪费内存资源，所以出现了动态链接的方式来解决这个问题。</p>
<p>动态链接在形式上倒是和静态链接非常相似，首先也是需要打包，打包成动态库，不过文件名格式为lib + 动态库名 + .so后缀。不过动态库的打包不需要使用ar命令，gcc就可以完成，但要注意在编译时要加上-fPIC选项，打包时加上-shared选项。</p>
<pre><code>  gcc -fPIC -c test1.c 
  gcc -fPIC -c test2.c
  gcc -shared test1.o test2.o -o libtest.so
</code></pre>
<p>使用动态链接的用法也和静态链接相同。</p>
<pre><code>  gcc -o main main.c -ltest
</code></pre>
</li>
</ul>
<p>如果仅仅像上面的步骤是没有办法正常使用库的，我们可以通过加-Lpath指定搜索库文件的目录（-L.表示当前目录），默认情况下会到环境变量LD_LIBRARY_PATH指定的目录下搜索库文件，默认情况是/usr/lib，我们可以将库文件拷贝到那个目录下再链接。</p>
<p>二者的优缺点：</p>
<ul>
<li>
<p>动态库运行时会先检查内存中是否已经有该库的拷贝，若有则共享拷贝，否则重新加载动态库（C语言的标准库就是动态库）。静态库则是每次在编译阶段都将静态库文件打包进去，当某个库被多次引用到时，内存中会有多份副本，浪费资源。</p>
</li>
<li>
<p>动态库另一个有点就是更新很容易，当库发生变化时，如果接口没变只需要用新的动态库替换掉就可以了。但是如果是静态库的话就需要重新被编译。</p>
</li>
<li>
<p>不过静态库也有优点，主要就是静态库一次性完成了所有内容的绑定，运行时就不必再去考虑链接的问题了，执行效率会稍微高一些。</p>
</li>
</ul>
<p><strong>链接</strong></p>
<p>符号解析</p>
<ul>
<li>
<p>可重定位目标文件</p>
<p>对于独立编译的可重定位目标文件，其ELF文件格式包括ELF头（指定文件大小及字节序）、.text（代码段）、.rodata（只读数据区）、.data（已初始化数据区）、.bss（未初始化全局变量）、.symtab（符号表）等，其中链接时最需要关注的就是符号表。每个可重定位目标文件都有一张符号表，它包含该模块定义和引用的符号的信息，简而言之就是我们在每个模块中定义和引用的全局变量（包括定义在本模块的全局变量、静态全局变量和引用自定义在其他模块的全局变量）需要通过一张表来记录，在链接时通过查表将各个独立的目标文件合并成一个完整的可执行文件。</p>
</li>
<li>
<p>解析符号表</p>
<p>解析符号引用的目的是将每个引用与可重定位目标文件的符号表中的一个符号定义联系起来。</p>
</li>
</ul>
<p>重定位</p>
<ul>
<li>
<p>合并节</p>
<p>多个可重定位目标文件中相同的节合并成一个完整的聚合节，比如多个目标文件的.data节合并成可执行文件的.data节。链接器将运行时存储地址赋予每个节，完成这步每条指令和全局变量都有运行时地址了。</p>
</li>
<li>
<p>重定位符号引用</p>
<p>这步修改全部代码节和数据节对每个符号的符号引用，使其指向正确的运行时地址。局部变量可以通过进栈、出栈临时分配，但全局变量（&quot;符号&quot;）的位置则是在各个可重定位目标文件中预留好的。通过上一步合并节操作后，指令中所有涉及符号的引用都会通过一定的寻址方式来定位该符号，比如相对寻址、绝对寻址等。</p>
</li>
</ul>
<p>可执行目标文件</p>
<ul>
<li>
<p>ELF头部</p>
<p>描述文件总体格式，并且包括程序的入口点（entry point），也就是程序运行时执行的第一条指令地址。</p>
</li>
<li>
<p>段头部表</p>
<p>描述了可执行文件数据段、代码段等各段的大小、虚拟地址、段对齐、执行权限等。实际上通过段头部表描绘了虚拟存储器运行时存储映像，比如每个UNIX程序的代码段总是从虚拟地址Ox0804800开始的。</p>
</li>
<li>
<p>其他段</p>
<p>和可重定位目标文件各段基本相同，但完成了多个节的合并和重定位工作。</p>
</li>
</ul>
<p><strong>加载</strong></p>
<ul>
<li>
<p>克隆</p>
<p>新程序的执行首先需要通过父进程外壳通过fork得到一个子进程，该子进程除了pid等标识和父进程不同外其他基本均与父进程相同。</p>
</li>
<li>
<p>重新映射</p>
<p>当子进程执行execve系统调用时会先清空子进程现有的虚拟存储器段（简而言之就是不再映射到父进程的各个段），之后重新创建子进程虚拟存储器各段和可执行目标文件各段的映射。这个阶段我们可以理解为对复制来的父进程页表进程重写，映射到外存中可执行文件的各个段。</p>
</li>
<li>
<p>虚页调入</p>
<p>加载过程并没有实际将磁盘中可执行文件调入内存，所做的工作仅仅是复制父进程页表、清空旧页表、建立新页表映射工作。之后加载器跳转到入口地址_start开始执行程序，接下来的过程需要配合虚拟存储器来完成。CPU获得指令的虚拟地址后，若包含该指令或数据的页尚未调入内存则将其从外存中调入，调入内存后修改页表得到虚拟页号和物理页号的对应关系。之后重新取同一条指令或数据时因该页已经被调入内存，所以通过虚拟地址得到虚拟页号，虚拟页号通过查页表可以得到物理页号，通过物理页号 + 页内偏移得到具体的物理地址，此时可以通过物理地址取得想要的数据。</p>
</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[在main()函数之前执行代码]]></title>
        <id>https://lixin-scut.github.io//post/zai-mainhan-shu-zhi-qian-zhi-xing-dai-ma</id>
        <link href="https://lixin-scut.github.io//post/zai-mainhan-shu-zhi-qian-zhi-xing-dai-ma">
        </link>
        <updated>2020-03-18T07:22:16.000Z</updated>
        <content type="html"><![CDATA[<p>这个是一道面试题，挺有趣的，考察的也算是对已有知识的利用和知识面的广度。</p>
<p>1.利用全局对象和静态对象的性质<br>
在main函数之前声明一个类的全局的对象。那么其执行顺序，根据全局对象的生存期和作用域，肯定先于main函数。<br>
静态对象同理</p>
<p>2.attribute关键字<br>
gcc中可以使用attribute关键字，声明constructor和destructor函数</p>
<pre><code>__attribute__((constructor)) void before_main()  
{  
   printf(&quot;before main\n&quot;); 
}  
  
__attribute__((destructor)) void after_main()  
{  
   printf(&quot;after main\n&quot;);  
}
</code></pre>
<p>3.onexit函数<br>
microsoft的C++编译器支持onexit函数。原型如下：</p>
<pre><code>_onexit_t _onexit(
   _onexit_t function
);

_onexit_t_m _onexit_m(
   _onexit_t_m function
);
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[覆盖、重载和隐藏的区别]]></title>
        <id>https://lixin-scut.github.io//post/fu-gai-chong-zai-he-yin-cang-de-qu-bie</id>
        <link href="https://lixin-scut.github.io//post/fu-gai-chong-zai-he-yin-cang-de-qu-bie">
        </link>
        <updated>2020-03-18T07:13:28.000Z</updated>
        <content type="html"><![CDATA[<ul>
<li>覆盖（override）是派生类中重新定义的函数，其函数名、参数列表（个数、类型和顺序）、返回值类型和父类完全相同，只有函数体有区别。派生类虽然继承了基类的同名函数，但用派生类对象调用该函数时会根据对象类型调用相应的函数。覆盖<strong>只能发生在类的成员函数</strong>中（对于override来说，一般用在虚函数上）。</li>
<li>隐藏是指派生类函数屏蔽了与其同名的函数，这里仅要求基类和派生类函数的函数名相同即可。隐藏比覆盖涵盖的范围更宽泛，毕竟参数不加限定。</li>
<li>重载是具有相同函数名但参数列表不同（个数、类型或顺序）的两个函数（不关心返回值），当调用函数时根据传递的参数列表来确定具体调用哪个函数。重载<strong>可以是同一个类的成员函数也可以是类外函数</strong>。</li>
<li>注意隐藏和重载的重要区别在于是否可见和候选函数，如果被隐藏了，等于优先级降低，所以可能直接不可见，无法作为候选函数，只有当前作用域没有适合的候选函数时才会到外层作用域考虑被隐藏的同名函数</li>
</ul>
<p><strong>重载和函数模板的区别</strong></p>
<ol>
<li>重载需要多个函数，这些函数彼此之间函数名相同，但参数列表中参数数量和类型不同。在区分各个重载函数时我们并不关心函数体。</li>
<li>模板函数是一个通用函数，函数的类型和形参不直接指定而用虚拟类型来代表。但只适用于形参个数相同而类型不同的函数。</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[深拷贝与浅拷贝]]></title>
        <id>https://lixin-scut.github.io//post/shen-kao-bei-yu-qian-kao-bei</id>
        <link href="https://lixin-scut.github.io//post/shen-kao-bei-yu-qian-kao-bei">
        </link>
        <updated>2020-03-18T06:59:01.000Z</updated>
        <content type="html"><![CDATA[<ol>
<li>浅拷贝：浅拷贝仅仅是拷贝向被指向对象的内存地址，如果原地址中对象被改变了，那么浅拷贝指向的对象也会相应改变。所以指针和引用的拷贝都属于浅拷贝</li>
<li>深拷贝：开辟了一块新的内存地址用于存放实际指向的对象，最后会存在两份相同的数据。</li>
<li>所以当同一类的不同对象互相赋值时，需要注意含有指针或引用的成员。特别是指向动态内存中的对象，如果B中有一个成员变量指针已经申请了动态内存，那A中的那个成员变量也指向同一块内存。这就会出现问题：当B把内存释放了，这时A的指针就是空悬指针了</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[图 329. 矩阵中的最长递增路径[困难][未做出]]]></title>
        <id>https://lixin-scut.github.io//post/tu-329-ju-zhen-zhong-de-zui-chang-di-zeng-lu-jing-kun-nan-wei-zuo-chu</id>
        <link href="https://lixin-scut.github.io//post/tu-329-ju-zhen-zhong-de-zui-chang-di-zeng-lu-jing-kun-nan-wei-zuo-chu">
        </link>
        <updated>2020-03-18T04:55:39.000Z</updated>
        <content type="html"><![CDATA[<blockquote>
<p>给定一个整数矩阵，找出最长递增路径的长度。<br>
对于每个单元格，你可以往上，下，左，右四个方向移动。 你不能在对角线方向上移动或移动到边界外（即不允许环绕）。<br>
示例 1:<br>
输入: nums =<br>
[<br>
[9,9,4],<br>
[6,6,8],<br>
[2,1,1]<br>
]<br>
输出: 4<br>
解释: 最长递增路径为 [1, 2, 6, 9]。<br>
示例 2:<br>
输入: nums =<br>
[<br>
[3,4,5],<br>
[3,2,6],<br>
[2,2,1]<br>
]<br>
输出: 4<br>
解释: 最长递增路径是 [3, 4, 5, 6]。注意不允许在对角线方向上移动。<br>
来源：力扣（LeetCode）<br>
链接：https://leetcode-cn.com/problems/longest-increasing-path-in-a-matrix<br>
著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。</p>
</blockquote>
<p>【未做出】<br>
首先我想用的是动态规划，但是很明显单纯的动态规划是不够的，<br>
因为动态规划需要依赖于过去的状态和状态转移方程，而我们无法从后面的信息去更新现有的信息（右下角更新左上角）<br>
所以看了题解之后发现果然是必须利用存储信息的<br>
利用存储信息然后不断地更新旧信息，从而使得不需要更新的信息只需要O(1)的时间复杂度<br>
代码如下：<br>
注意diretion数组，用于上下左右四个位置的转移，减少循环和判断条件的复杂度</p>
<pre><code>class Solution {
public:
    int longestIncreasingPath(vector&lt;vector&lt;int&gt;&gt;&amp; matrix) {
        if(matrix.empty())
        {   return 0; }
        row = matrix.size(); 
        col = matrix[0].size();
        
        vector&lt;vector&lt;int&gt;&gt; cache(row,vector&lt;int&gt;(col,0));
        int res = 0;
        
        for(int r = 0; r &lt; row; ++r )
        {
            for(int c = 0; c &lt; col; ++c)
            {
                int temp = longestIncreasingPath(matrix, r, c, cache);
                res = res &gt; temp? res : temp;
            }
        }
        
        return res;
    }
    
    int longestIncreasingPath(vector&lt;vector&lt;int&gt;&gt;&amp; matrix, int r, int c, vector&lt;vector&lt;int&gt;&gt;&amp; cache)
    {
        if(cache[r][c] != 0)
        {   return cache[r][c]; }
        
        for(auto d : direction)
        {
            if(r+d[0] &gt;= 0 &amp;&amp; r+d[0] &lt; row 
               &amp;&amp; c+d[1] &gt;= 0 &amp;&amp; c+d[1] &lt; col 
               &amp;&amp; matrix[r+d[0]][c+d[1]] &gt; matrix[r][c])
            {
                cache[r][c] = max(cache[r][c],longestIncreasingPath(matrix, r+d[0], c+d[1], cache));
        
            }
        }
        
        return ++cache[r][c];
    }

private:
    int row, col;
    vector&lt;vector&lt;int&gt;&gt; direction  = { { 0 , 1 }, { 1 , 0 }, { 0 , -1 }, { -1 , 0 } };
};
</code></pre>
<p>官方题解：</p>
<blockquote>
<p>正文<br>
方法一：朴素的深度优先搜索 【超时】<br>
直觉<br>
深度优先搜索可以找到从任何单元格开始的最长递增路径。我们可以对全部单元格进行深度优先搜索。<br>
算法<br>
每个单元格可以看作图<br>
G 中的一个定点。若两相邻细胞的值满足a&lt;b，则存在有向边 (a,b)。问题转化成：<br>
寻找有向图 G 中的最长路径。<br>
很显然,我们可以使用深度优先搜索或广度优先搜索从根开始访问连接的所有细胞。在搜索期间更新路径的最大长度，并在搜索完成后得到答案。<br>
一般而言，在深度优先搜索或广度优先搜索中，我们可以使用集合visited 来避免重复访问。在下一节中我们将介绍基于此的更优算法。</p>
</blockquote>
<pre><code>// Naive DFS Solution
// Time Limit Exceeded
public class Solution {
  private static final int[][] dirs = {{0, 1}, {1, 0}, {0, -1}, {-1, 0}};
  private int m, n;

  public int longestIncreasingPath(int[][] matrix) {
      if (matrix.length == 0) return 0;
      m = matrix.length;
      n = matrix[0].length;
      int ans = 0;
      for (int i = 0; i &lt; m; ++i)
          for (int j = 0; j &lt; n; ++j)
              ans = Math.max(ans, dfs(matrix, i, j));
      return ans;
  }

  private int dfs(int[][] matrix, int i, int j) {
      int ans = 0;
      for (int[] d : dirs) {
          int x = i + d[0], y = j + d[1];
          if (0 &lt;= x &amp;&amp; x &lt; m &amp;&amp; 0 &lt;= y &amp;&amp; y &lt; n &amp;&amp; matrix[x][y] &gt; matrix[i][j])
              ans = Math.max(ans, dfs(matrix, x, y));
      }
      return ++ans;
  }
}
</code></pre>
<blockquote>
<p>复杂度分析<br>
时间复杂度 ：O(2^(m+n))。对每个有效递增路径均进行搜索。在最坏情况下，会有 O(2^(m+n)) 次调用。例如：<br>
空间复杂度 ： O(mn)。 对于每次深度优先搜索，系统栈需要 O(h) 空间，其中 h 为递归的最深深度。最坏情况下，O(h)=O(mn)。</p>
</blockquote>
<blockquote>
<p>解法二：记忆化深度优先搜索 【通过】<br>
直觉<br>
将递归的结果存储下来，这样每个子问题只需要计算一次。<br>
算法<br>
从上面的分析中，我们知道在淳朴的深度优先搜索方法中有许多重复的计算。<br>
一个优化途径是我们可以用一个集合来避免一次深度优先搜索中的重复访问。该优化可以将一次深度优先搜索的时间复杂度优化到 O(mn)<br>
O(mn)，总时间复杂度 O(m<sup>2*n</sup>2 )。<br>
下面介绍一个更有力的优化方法，记忆化。<br>
在计算中，记忆化是一种优化技术，它通过存储“昂贵”的函数调用的结果，在相同的输入再次出现时返回缓存的结果，以此加快程序的速度。<br>
在本问题中，我们多次递归调用 dfs(x, y) 。但是，如果我们已经知道四个相邻单元格的结果，就只需要常数时间。在搜索过程中，如果未计算过单元格的结果，我们会计算并将其缓存；否则，直接从缓存中获取之。<br>
Java</p>
</blockquote>
<pre><code>// DFS + Memoization Solution
// Accepted and Recommended
public class Solution {
    private static final int[][] dirs = {{0, 1}, {1, 0}, {0, -1}, {-1, 0}};
    private int m, n;

    public int longestIncreasingPath(int[][] matrix) {
        if (matrix.length == 0) return 0;
        m = matrix.length; n = matrix[0].length;
        int[][] cache = new int[m][n];
        int ans = 0;
        for (int i = 0; i &lt; m; ++i)
            for (int j = 0; j &lt; n; ++j)
                ans = Math.max(ans, dfs(matrix, i, j, cache));
        return ans;
    }

    private int dfs(int[][] matrix, int i, int j, int[][] cache) {
        if (cache[i][j] != 0) return cache[i][j];
        for (int[] d : dirs) {
            int x = i + d[0], y = j + d[1];
            if (0 &lt;= x &amp;&amp; x &lt; m &amp;&amp; 0 &lt;= y &amp;&amp; y &lt; n &amp;&amp; matrix[x][y] &gt; matrix[i][j])
                cache[i][j] = Math.max(cache[i][j], dfs(matrix, x, y, cache));
        }
        return ++cache[i][j];
    }
}

</code></pre>
<blockquote>
<p>复杂度分析<br>
时间复杂度 : O(mn)。 每个顶点/单元格均计算一次，且只被计算一次。每条边也均计算一次并只计算一次。总时间复杂度是 O(V+E)。V 是顶点总数，E 是边总数。本问题中，O(V)=O(mn)，O(E)=O(4V)=O(mn)。<br>
空间复杂度 : O(mn)。缓存决定了空间复杂度。</p>
</blockquote>
<blockquote>
<p>方法三：“剥洋葱”（动态规划） 【通过】<br>
直觉<br>
每个细胞的结果只与相邻的结果相关，能否使用动态规划？<br>
算法<br>
如果我们定义从单元格 (i,j) 开始的最长递增路径为函数f(i,j)<br>
则可以写出状态转移函数<br>
<code>f(i,j)=max{f(x,y)∣(x,y) is a nei∗∗∗or of(i,j) and matrix[x][y]&gt;matrix[i][j]}+1</code><br>
此公式与以前方法中使用的公式相同。有了状态转移函数，你可能会觉得可以使用动态规划来推导出所有结果，去他的深度优先搜索!<br>
这听起来很美好，可惜你忽略了一件事：我们没有依赖列表。<br>
想要让动态规划有效，如果问题 B 依赖于问题 A 的结果，就必须确保问题 A 比问题 B先计算。这样的依赖顺序对许多问题十分简单自然。如著名的斐波那契数列：<br>
F(0)=1,F(1)=1,F(n)=F(n−1)+F(n−2)<br>
子问题 F(n) 依赖于 F(n−1) 和 F(n−2)。因此，自然顺序就是正确的计算顺序。被依赖者总会先被计算。<br>
这种依赖顺序的术语是“拓扑顺序”或“拓扑排序”：<br>
对有向无环图的拓扑排序是顶点的一个线性排序，使得对于任何有向边 (u,v)，顶点 u 都在 顶点 v 的前面。<br>
在本问题中，拓扑顺序并不简单自然。没有矩阵的值，我们无法知道两个邻居 A 和 B 的依赖关系。作为预处理，我们必须显式执行拓扑排序。之后，我们可以按照存储的拓扑顺序使用状态转移函数动态地解决问题。<br>
有多种实现拓扑排序的方法。这里我们使用的是一种被称为“剥洋葱”的方法。其思路是在一个有向无环图中，会有一些不依赖于其他顶点的顶点，称为“叶子”。我们将这些叶子放在一个列表中（他们的内部排序不重要），然后将他们从图中移除。移除之后，会产生新的“叶子”。重复以上过程，就像一层一层一层地拨开洋葱的心。最后，列表中就会存储有效的拓扑排序。<br>
在本问题中，因为我们想要求出在整个图中最长的路径，也就是“洋葱”的层总数。因此，我们可以在“剥离”的期间计算层数，在不调用动态规划的情况下返回计数。</p>
</blockquote>
<pre><code>// Topological Sort Based Solution
// An Alternative Solution
public class Solution {
    private static final int[][] dir = {{0, 1}, {1, 0}, {0, -1}, {-1, 0}};
    private int m, n;
    public int longestIncreasingPath(int[][] grid) {
        int m = grid.length;
        if (m == 0) return 0;
        int n = grid[0].length;
        // padding the matrix with zero as boundaries
        // assuming all positive integer, otherwise use INT_MIN as boundaries
        int[][] matrix = new int[m + 2][n + 2];
        for (int i = 0; i &lt; m; ++i)
            System.arraycopy(grid[i], 0, matrix[i + 1], 1, n);

        // calculate outdegrees
        int[][] outdegree = new int[m + 2][n + 2];
        for (int i = 1; i &lt;= m; ++i)
            for (int j = 1; j &lt;= n; ++j)
                for (int[] d: dir)
                    if (matrix[i][j] &lt; matrix[i + d[0]][j + d[1]])
                        outdegree[i][j]++;

        // find leaves who have zero out degree as the initial level
        n += 2;
        m += 2;
        List&lt;int[]&gt; leaves = new ArrayList&lt;&gt;();
        for (int i = 1; i &lt; m - 1; ++i)
            for (int j = 1; j &lt; n - 1; ++j)
                if (outdegree[i][j] == 0) leaves.add(new int[]{i, j});

        // remove leaves level by level in topological order
        int height = 0;
        while (!leaves.isEmpty()) {
            height++;
            List&lt;int[]&gt; newLeaves = new ArrayList&lt;&gt;();
            for (int[] node : leaves) {
                for (int[] d:dir) {
                    int x = node[0] + d[0], y = node[1] + d[1];
                    if (matrix[node[0]][node[1]] &gt; matrix[x][y])
                        if (--outdegree[x][y] == 0)
                            newLeaves.add(new int[]{x, y});
                }
            }
            leaves = newLeaves;
        }
        return height;
    }
}
</code></pre>
<blockquote>
<p>复杂度分析<br>
时间复杂度 : O(mn)。拓扑排序的时间复杂度为 O(V+E)=O(mn)。V 是顶点总数，<br>
E 是边总数。本问题中，O(V)=O(mn)，O(E)=O(4V)=O(mn)。<br>
空间复杂度 : O(mn)。我们需要存储出度和每层的叶子。<br>
要点<br>
记忆化: 对于大量重复调用的问题，缓存其结果。<br>
动态规划要求按照拓扑顺序解决子问题。对于很多问题，拓扑顺序与自然秩序一致。而对于那些并非如此的问题，需要首先执行拓扑排序。因此,对于复杂拓扑问题（如本题），使用记忆化搜索通常是更容易更好的选择。</p>
</blockquote>
]]></content>
    </entry>
</feed>
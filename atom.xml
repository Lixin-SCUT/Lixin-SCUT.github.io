<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://lixin-scut.github.io/</id>
    <title>Lixin-SCUT</title>
    <updated>2020-03-19T07:26:04.960Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://lixin-scut.github.io/"/>
    <link rel="self" href="https://lixin-scut.github.io//atom.xml"/>
    <subtitle>千里之行，始于足下。不积跬步，无以至千里。</subtitle>
    <logo>https://lixin-scut.github.io//images/avatar.png</logo>
    <icon>https://lixin-scut.github.io//favicon.ico</icon>
    <rights>All rights reserved 2020, Lixin-SCUT</rights>
    <entry>
        <title type="html"><![CDATA[pthread_once()]]></title>
        <id>https://lixin-scut.github.io//post/pthread_once</id>
        <link href="https://lixin-scut.github.io//post/pthread_once">
        </link>
        <updated>2020-03-19T01:24:52.000Z</updated>
        <content type="html"><![CDATA[<p>  在多线程环境中，有些事仅需要执行一次。通常当初始化应用程序时，可以比较容易地将其放在main函数中。但当写一个库时，就不能在main里面初始化了，此时可以用静态初始化，但使用一次初始化（pthread_once）会比较容易些。</p>
<pre><code>pthread_once_t once_control = PTHREAD_ONCE_INIT;
int pthread_once(pthread_once_t *once_control, void (*init_routine) (void))；
</code></pre>
<p><strong>功能：</strong><br>
  本函数使用初值为PTHREAD_ONCE_INIT的once_control变量保证init_routine()函数在本进程执行序列中仅执行一次。<br>
  在多线程编程环境下，尽管pthread_once()调用会出现在多个线程中，init_routine()函数仅执行一次，究竟在哪个线程中执行是不定的，是由内核调度来决定。</p>
<p><strong>底层：</strong><br>
  Linux Threads使用互斥锁和条件变量保证由pthread_once()指定的函数执行且仅执行一次，而once_control表示是否执行过。<br>
  如果once_control的初值不是PTHREAD_ONCE_INIT（Linux Threads定义为0），pthread_once() 的行为就会不正常。<br>
  在LinuxThreads中，实际&quot;一次性函数&quot;的执行状态有三种：NEVER（0）、IN_PROGRESS（1）、DONE （2），如果once初值设为1，则由于所有pthread_once()都必须等待其中一个激发&quot;已执行一次&quot;信号，因此所有pthread_once()都会陷入永久的等待中；如果设为2，则表示该函数已执行过一次，从而所有pthread_once()都会立即返回0。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[调度]]></title>
        <id>https://lixin-scut.github.io//post/diao-du</id>
        <link href="https://lixin-scut.github.io//post/diao-du">
        </link>
        <updated>2020-03-18T09:32:53.000Z</updated>
        <content type="html"><![CDATA[<p>  当计算机系统是多道程序设计系统时，通常就会有多个进程或线程同时竞争CPU。只要有两个或更多的进程处于就绪状态，如果只有一个CPU可用，那么就必须选择下一个要运行的进程。在操作系统中，完成选择工作的这一部分称为调度程序（scheduler）,该程序使用的算法称为调 度算法（scheduling algorithm）。</p>
<p>  进程切换的代价是比较高的。<br>
  首先用户态必须切换到内核态，然后要保存当前进程的状态，包括在进程表中存储寄存器值以便以 后重新装载。在许多系统中，内存映像（例如，页表内的内存访问位）也必须保存，<br>
  接着，通过运行调 度算法选定一个新进程之后，应该将新进程的内存映像重新装入MMU,最后新进程开始运行。<br>
  除此 之外，进程切换还要使整个内存高速缓存失效，强迫缓存从内存中动态重新装入两次（进入内核一次， 离开内核一次）。<br>
  总之，如果每秒钟切换进程的次数太多，会耗费大量CPU时间，所以有必要提醒注意。</p>
<p><strong>进程行为</strong><br>
  某些进程花费了绝大多数时间在计算上，而 其他进程则在等待I/O上花费了绝大多数时间。前者称为计算密集型（compute-bound）, 后者称为I/O密集型（I/O-bound）。<br>
  典型的计算密集型进程具有较长时间的CPU集中使用和较小频度的 I/O等待。 I/O密集型进程具有较短时间的CPU集中使用和频繁的I/O等待。它是I/O类的，因为这种进程 在I/O请求之间较少进行计算，并不是因为它们有转别长的I/O请求。在I/O开始后无论处理数据是多还是少，它们都花费同样的时间提出硬件请求读取磁盘块。</p>
<p><strong>何时调度</strong><br>
  第一，在创建一个新进程之后，需要决定是运行父进程还是运行子进程。由于这两种进程都处于就绪状态，所以这是一 种正常的调度决策，可以任意决定，也就是说，调度程序可以合法选择先运行父进程还是先运行子进程。<br>
  第二，在一个进程退出时必须做出调度决策。一个进程不再运行（因为它不再存在），所以必须从 就绪进程集中选择另外某个进程。如果没有就绪的进程，通常会运行一个系统提供的空闲进程。<br>
  第三，当一个进程阻塞在I/O和信号最上或由于其他原因阻塞时，必须选择另一个进程运行。<br>
  第四，在一个I/O中断发生时，必须做出调度决策。如果中断来自I/O设备，而该设备现在完成了工作，某些被阻塞的等待该I/O的进程就成为可运行的就绪进程。是否让新就绪的进程运行，这取决于 调度程序的决定，或者让中断发生时运行的进程继续运行，或者应该让某个其他进程运行。</p>
<p><strong>调度算法分类</strong><br>
根据如何处理时钟中断，可以把调度算法分为两类。<br>
  非抢占式调度算法挑选一个进 程，然后让该进程运行直至被阻塞（阻塞在I/O上或等待另一个进程），或者直到该进程自动释放CPU。 即使该进程运行了若干个小时，它也不会被强迫挂起。这样做的结果是，在时钟中断发生时不会进行调 度。在处理完时钟中断后，如果没有更高优先级的进程等待到时，则被中断的进程会继续执行。<br>
  相反，抢占式调度算法挑选一个进程，并且让该进程运行某个固定时段的最大值。如果在该时段结 束时，该进程仍在运行，它就被挂起，而调度程序挑选另一个进程运行（如果存在一个就绪进程）。进 行抢占式调度处理，需要在时间间隔的末端发生时钟中断，以便把CPU控制返回给调度程序。如果没有 可用的时钟，那么非抢占式调度就是惟一的选择了。</p>
<p><strong>调度算法分类</strong><br>
在不同的系统中，调度程序的优化是不同的。这里有必要 划分出三种环境：<br>
1）	批处理。<br>
2）	交互式。<br>
3）	实时。</p>
<p><strong>调度算法的目标</strong><br>
<img src="https://lixin-scut.github.io//post-images/1584525112161.png" alt=""></p>
<p><strong>策略和机制</strong><br>
  将调度机制（scheduling mechanism）与调度策略（scheduling policy）分离，也就是将调度算法以某种形式参数化，而参数可以由用户进程填写。</p>
<p><strong>线程调度</strong><br>
  当若干进程都有多个线程时，就存在两个层次的并行：进程和线程。在这样的系统中调度处理有本 质差别，这取决于所支持的是用户级线程还是内核级线程（或两者都支持）。<br>
  首先考虑用户级线程。由于内核并不知道有线程存在，所以内核还是和以前一样地操作，选取一个进程，并给予时间片控制。进程中的线程调度程序决定哪个线程运行。由于多 道线程并不存在时钟中断，所以这个线程可以按其意愿任意运行多长时间。如果该线程用完了进程的全 部时间片，内核就会选择另一个进程运行。<br>
  在进程终于又一次运行时，线程会接着运行。该线程会继续耗费进程的所有时间片，直到它完成工作。不过，该线程的这种不合群的行为不会影响到其他的进程。其他进程会得到调度程序所分配的 合适份额，不会考虑进程内部所发生的事。<br>
<img src="https://lixin-scut.github.io//post-images/1584525832250.png" alt=""><br>
  现在考虑使用内核级线程的情形。内核选择一个特定的线程运行。它不用考虑该线程属于哪个进程， 不过如果有必要的话，它可以这样做。对被选择的线程赋予一个时间片，而旦如果超过了时间片，就会 强制挂起该线程。</p>
<p><strong>内核线程与用户线程调度的区别</strong><br>
用户级线程和内核级线程之间的差别在于性能。用户级线程的线程切换需要少量的机器指令，而内核级线程需要完整的上下文切换，修改内存映像，使高速缓存失效，这导致了若干数量级的延退。<br>
  从进程A的一个线程切换到进程B的一个线程，其代价高于运行进程A的第2个线程（因为必须修改 内存映像，清除内存高速缓存的内容），内核对此是了解的，并可运用这些信息做出决定。例如，给定两个在其他方面同等重要的线程，其中一个线程与刚好阻塞的线程属于同一个进程，而另一个线程属于 其他的进程，那么应该倾向前者。<br>
  另一个重要因素是用户级线程可以使用专为应用程序定制的线程调度程序。由于运行系统了解所有线程的作用，所以会直接选择分派线程接着运行，这样分派线程就会启动另一个工作线程运行。在一个工作线程经常阻塞在磁盘I/O上的环境中，这个策略将并行度最大化。 而在内核级线程中，内核从来不了解每个线程的作用（虽然它们被赋予了不同的优先级）。不过，一般而言，应用定制的线程调度程序能够比内核更好地满足应用的需要。</p>
<p><strong>批处理系统中的调度</strong></p>
<ol>
<li>先来先服务<br>
  最简单的是非抢占式的先来先服务(first-come first-severd)算法。使用该算 法，进程按照它们请求CPU的顺序使用CPU。基本上，有一个就绪进程的单一队列。</li>
<li>最短作业优先<br>
  适用于运行时间可以预知的另一个非抢占式的批处理调度算法。</li>
<li>最短剩余时间优先<br>
  最短作业优先的抢占式版本是景短剩余时间优先(shortest remaining time next)算法。使用这个算 法，调度程序总是选择剩余运行时间最短的那个进程运行。再次提醒，有关的运行时间必须提前掌握。 当一个新的作业到达时，其整个时间同当前进程的剩余时间做比较。如果新的进程比当前运行进程需要 更少的时间，当前进程就被挂起，而运行新的进程。</li>
</ol>
<p><strong>交互式系统中的调度</strong><br>
  现在考察用于交互式系统中的一些调度算法，它们在个人计算机、服务器和其他类系统中都是常用的。</p>
<ol>
<li>轮转调度<br>
  一种最古老、最简单、最公平且使用最广的算法是轮转调度(round robin)。每个进程被分配一个 时间段，称为时间片(quantum),即允许该进程在该时间段中运行。如果在时间片结束时该进程还在运 行，则将剥夺CPU并分配给另一个进程。如果该进程在时间片结束前阻塞或结束，则CPU立即进行切换。当一 个进程用完它的时间片后，就被移到队列的末尾<br>
  时间片轮转调度中惟一有趣的一点是时间片的长度。CPU时间的20%浪费在管理开 销上。<br>
  时间片设得太短会导致过多的进程切换，降低了CPU效率，而设得太长又可能 引起对短的交互请求的响应时间变长。将时间片设为20ms~50 ms通常是一个比较合理的折中。</li>
<li>优先级调度<br>
  轮转调度做了一个隐含的假设，即所有的进程同等重要，但外部因素考虑在内的需要就导致了优先级调度。其基本思想很清楚：每个进程被赋予一个优先级，允许优先级最高的可运行进程先运行。<br>
  为了防止高优先级进程无休止地运行下去，调度程序可以在每个时钟滴答(即每个时钟中断)降低 当前进程的优先级。如果这个动作导致该进程的优先级低于次高优先级的进程，则进行进程切换。一个可采用的方法是，每个进程可以被赋予一个允许运行的最大时间片，当这个时间片用完时，下一个次高 优先级的进程获得机会运行。<br>
  优先级可以是静态赋予或动态赋予。如果不偶尔对优先级进行调整，则低优先级 进程很可能会产生饥饿现象。</li>
<li>多级队列<br>
  如前所述，长时间片的进程又会影响到响应时间，其解决办法是设立优先级类。属于最高优先级类的进程运行一个时间片，属于次高优先级类的进程运行2个时间片，再次一级运行4个时间片，以此类推。当一个进程用完分配的时间片后，它被移到下一类。</li>
<li>最短进程优先</li>
<li>保证调度</li>
<li>彩票调度</li>
<li>公平分享调度</li>
</ol>
<p><strong>实时系统中的调度</strong><br>
  实时系统通常可以分为硬实时（hard real time）和软实时（soft real time）,前者的含义是必须满足绝对的截止时间，后者的含义是虽然不希望偶尔错失截止时间，但是可以容忍。<br>
  实时系统中的事件可以按照响应方式进一步分类为周期性（以规则的时间间隔发生）事件或非周期 性（发生时间不可预知）事件。<br>
  实时系统使用的调度算法可以是上面介绍的算法中的任意一种。从实用考虑，轮转调度和优先级调度更为常用。惟一的局限是，缺乏一个时钟将运行过长的线程加以中断。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[用户态和内核态]]></title>
        <id>https://lixin-scut.github.io//post/yong-hu-tai-he-nei-he-tai</id>
        <link href="https://lixin-scut.github.io//post/yong-hu-tai-he-nei-he-tai">
        </link>
        <updated>2020-03-18T08:35:09.000Z</updated>
        <content type="html"><![CDATA[<h3 id="用户态和内核态">用户态和内核态</h3>
<p>  当一个任务（进程）执行系统调用而陷入内核代码中执行时，我们就称进程处于内核运行态（或简称为内核态）。此时处理器处于特权级最高的（0级）内核代码中执行。<br>
  当进程处于内核态时，执行的内核代码会使用当前进程的内核栈。每个进程都有自己的内核栈。当进程在执行用户自己的代码时，则称其处于用户运行态（用 户态）。即此时处理器在特权级最低的（3级）用户代码中运行。<br>
  用户运行一个程序，该程序所创建的进程开始是运行在用户态的，如果要执行文件操作，网络数据发送等操作，必须通过write，send等系统调用，这些系统调用会调用内核中的代码来完成操作，这时，必须切换到Ring0，然后进入3GB-4GB中的内核地址空间去执行这些代码完成操作，完成后，切换回Ring3，回到用户态。这样，用户态的程序就不能 随意操作内核地址空间，具有一定的安全保护作用。</p>
<h3 id="区分内核态和用户态的原因">区分内核态和用户态的原因</h3>
<p>  在CPU中运行的操作系统程序和用户程序对应的机器指令集是不同的。操作系统程序使用所有指令，但用户程序只能使用部分指令。从资源管理和程序控制执行的角度出发，将指令系统分为两大部分：特权指令和非特权指令。在程序执行时，根据执行程序对资源和机器指令的使用权限，把机器设置为两个状态：内核态和用户态。<br>
  避免代码进行潜在危险的操作，以防止给操作系统带来安全隐患。系统调用与返回的情况下进行两种方式的转换。<br>
  用户态状态下，执行的代码被硬件限定，不能进行某些操作，比如写入其他进程的存储空间，以防止给操作系统带来安全隐患。内核禁止此状态下的代码进行潜在危险的操作，比如写入系统配置文件、杀掉其他用户的进程、重启系统等。</p>
<h3 id="用户态切换到内核态的3种方式">用户态切换到内核态的3种方式：</h3>
<ol>
<li>系统调用<br>
这是用户态进程主动要求切换到内核态的一种方式，用户态进程通过系统调用申请使用操作系统提供的服务程序完成工作，比如前例中fork()实际上就是执行了一个创建新进程的系统调用。而系统调用的机制其核心还是使用了操作系统为用户特别开放的一个中断来实现，例如Linux的int 80h中断。</li>
<li>异常<br>
当CPU在执行运行在用户态下的程序时，发生了某些事先不可知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关程序中，也就转到了内核态，比如缺页异常。</li>
<li>外围设备的中断<br>
当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序，如果先前执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了由用户态到内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[编译与链接]]></title>
        <id>https://lixin-scut.github.io//post/bian-yi-yu-lian-jie</id>
        <link href="https://lixin-scut.github.io//post/bian-yi-yu-lian-jie">
        </link>
        <updated>2020-03-18T07:55:50.000Z</updated>
        <content type="html"><![CDATA[<p>其实叫编译过程是不对的，因为编译与链接都只是C++文本文件到可执行文件的一环，但是似乎大家是是习惯了叫做编译，我也暂时没想到好的名称来代替，就暂时只用这个博文名吧。</p>
<p><strong>预处理</strong></p>
<ul>
<li>
<p>展开所有的宏定义，完成字符常量替换。</p>
</li>
<li>
<p>处理条件编译语句，通过是否具有某个宏来决定过滤掉哪些代码。</p>
</li>
<li>
<p>处理#include指令，将被包含的文件插入到该指令所在位置。</p>
</li>
<li>
<p>过滤掉所有注释语句。</p>
</li>
<li>
<p>添加行号和文件名标识。</p>
</li>
<li>
<p>保留所有#pragma编译器指令。</p>
</li>
</ul>
<p><strong>编译</strong></p>
<ul>
<li>
<p>词法分析。</p>
</li>
<li>
<p>语法分析。</p>
</li>
<li>
<p>语义分析。</p>
</li>
<li>
<p>中间语言生成。</p>
</li>
<li>
<p>目标代码生成与优化。</p>
</li>
</ul>
<p><strong>链接</strong></p>
<p>各个源代码模块独立的被编译，然后将他们组装起来成为一个整体，组装的过程就是链接。被链接的各个部分本本身就是二进制文件，所以在被链接时需要将所有目标文件的代码段拼接在一起，然后将所有对符号地址的引用加以修正。</p>
<ul>
<li>
<p>静态链接</p>
<p>静态链接最简单的情况就是在编译时和静态库链接在一起成为完整的可执行程序。这里所说的静态库就是对多个目标文件（.o）文件的打包，通常静态链接的包名为<code>lib****.a</code>，静态链接所有被用到的目标文件都会复制到最终生成的可执行目标文件中。这种方式的好处是在运行时，可执行目标文件已经完全装载完毕，只要按指令序执行即可，速度比较快，但缺点也有很多</p>
</li>
</ul>
<p>静态链接是对目标文件的打包，打包命令如下</p>
<pre><code>    gcc -c test1.c    // 生成test1.o
    gcc -c test2.c    // 生成test2.c
    ar cr libtest.a test1.o test2.o
</code></pre>
<p>首先编译得到test1.o和test2.o两个目标文件，之后通过ar命令将这两个文件打包为.a文件，文件名格式为lib + 静态库名 + .a后缀。在生成可执行文件需要使用到它的时候只需要在编译时加上即可。需要注意的是，使用静态库时加在最后的名字不是libtest.a，而是l + 静态库名。</p>
<pre><code>    gcc -o main main.c -ltest
</code></pre>
<ul>
<li>
<p>动态链接</p>
<p>静态链接发生于编译阶段，加载至内存前已经完整，但缺点是如果多个程序都需要使用某个静态库，则该静态库会在每个程序中都拷贝一份，非常浪费内存资源，所以出现了动态链接的方式来解决这个问题。</p>
<p>动态链接在形式上倒是和静态链接非常相似，首先也是需要打包，打包成动态库，不过文件名格式为lib + 动态库名 + .so后缀。不过动态库的打包不需要使用ar命令，gcc就可以完成，但要注意在编译时要加上-fPIC选项，打包时加上-shared选项。</p>
<pre><code>  gcc -fPIC -c test1.c 
  gcc -fPIC -c test2.c
  gcc -shared test1.o test2.o -o libtest.so
</code></pre>
<p>使用动态链接的用法也和静态链接相同。</p>
<pre><code>  gcc -o main main.c -ltest
</code></pre>
</li>
</ul>
<p>如果仅仅像上面的步骤是没有办法正常使用库的，我们可以通过加-Lpath指定搜索库文件的目录（-L.表示当前目录），默认情况下会到环境变量LD_LIBRARY_PATH指定的目录下搜索库文件，默认情况是/usr/lib，我们可以将库文件拷贝到那个目录下再链接。</p>
<p>二者的优缺点：</p>
<ul>
<li>
<p>动态库运行时会先检查内存中是否已经有该库的拷贝，若有则共享拷贝，否则重新加载动态库（C语言的标准库就是动态库）。静态库则是每次在编译阶段都将静态库文件打包进去，当某个库被多次引用到时，内存中会有多份副本，浪费资源。</p>
</li>
<li>
<p>动态库另一个有点就是更新很容易，当库发生变化时，如果接口没变只需要用新的动态库替换掉就可以了。但是如果是静态库的话就需要重新被编译。</p>
</li>
<li>
<p>不过静态库也有优点，主要就是静态库一次性完成了所有内容的绑定，运行时就不必再去考虑链接的问题了，执行效率会稍微高一些。</p>
</li>
</ul>
<p><strong>链接</strong></p>
<p>符号解析</p>
<ul>
<li>
<p>可重定位目标文件</p>
<p>对于独立编译的可重定位目标文件，其ELF文件格式包括ELF头（指定文件大小及字节序）、.text（代码段）、.rodata（只读数据区）、.data（已初始化数据区）、.bss（未初始化全局变量）、.symtab（符号表）等，其中链接时最需要关注的就是符号表。每个可重定位目标文件都有一张符号表，它包含该模块定义和引用的符号的信息，简而言之就是我们在每个模块中定义和引用的全局变量（包括定义在本模块的全局变量、静态全局变量和引用自定义在其他模块的全局变量）需要通过一张表来记录，在链接时通过查表将各个独立的目标文件合并成一个完整的可执行文件。</p>
</li>
<li>
<p>解析符号表</p>
<p>解析符号引用的目的是将每个引用与可重定位目标文件的符号表中的一个符号定义联系起来。</p>
</li>
</ul>
<p>重定位</p>
<ul>
<li>
<p>合并节</p>
<p>多个可重定位目标文件中相同的节合并成一个完整的聚合节，比如多个目标文件的.data节合并成可执行文件的.data节。链接器将运行时存储地址赋予每个节，完成这步每条指令和全局变量都有运行时地址了。</p>
</li>
<li>
<p>重定位符号引用</p>
<p>这步修改全部代码节和数据节对每个符号的符号引用，使其指向正确的运行时地址。局部变量可以通过进栈、出栈临时分配，但全局变量（&quot;符号&quot;）的位置则是在各个可重定位目标文件中预留好的。通过上一步合并节操作后，指令中所有涉及符号的引用都会通过一定的寻址方式来定位该符号，比如相对寻址、绝对寻址等。</p>
</li>
</ul>
<p>可执行目标文件</p>
<ul>
<li>
<p>ELF头部</p>
<p>描述文件总体格式，并且包括程序的入口点（entry point），也就是程序运行时执行的第一条指令地址。</p>
</li>
<li>
<p>段头部表</p>
<p>描述了可执行文件数据段、代码段等各段的大小、虚拟地址、段对齐、执行权限等。实际上通过段头部表描绘了虚拟存储器运行时存储映像，比如每个UNIX程序的代码段总是从虚拟地址Ox0804800开始的。</p>
</li>
<li>
<p>其他段</p>
<p>和可重定位目标文件各段基本相同，但完成了多个节的合并和重定位工作。</p>
</li>
</ul>
<p><strong>加载</strong></p>
<ul>
<li>
<p>克隆</p>
<p>新程序的执行首先需要通过父进程外壳通过fork得到一个子进程，该子进程除了pid等标识和父进程不同外其他基本均与父进程相同。</p>
</li>
<li>
<p>重新映射</p>
<p>当子进程执行execve系统调用时会先清空子进程现有的虚拟存储器段（简而言之就是不再映射到父进程的各个段），之后重新创建子进程虚拟存储器各段和可执行目标文件各段的映射。这个阶段我们可以理解为对复制来的父进程页表进程重写，映射到外存中可执行文件的各个段。</p>
</li>
<li>
<p>虚页调入</p>
<p>加载过程并没有实际将磁盘中可执行文件调入内存，所做的工作仅仅是复制父进程页表、清空旧页表、建立新页表映射工作。之后加载器跳转到入口地址_start开始执行程序，接下来的过程需要配合虚拟存储器来完成。CPU获得指令的虚拟地址后，若包含该指令或数据的页尚未调入内存则将其从外存中调入，调入内存后修改页表得到虚拟页号和物理页号的对应关系。之后重新取同一条指令或数据时因该页已经被调入内存，所以通过虚拟地址得到虚拟页号，虚拟页号通过查页表可以得到物理页号，通过物理页号 + 页内偏移得到具体的物理地址，此时可以通过物理地址取得想要的数据。</p>
</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[在main()函数之前执行代码]]></title>
        <id>https://lixin-scut.github.io//post/zai-mainhan-shu-zhi-qian-zhi-xing-dai-ma</id>
        <link href="https://lixin-scut.github.io//post/zai-mainhan-shu-zhi-qian-zhi-xing-dai-ma">
        </link>
        <updated>2020-03-18T07:22:16.000Z</updated>
        <content type="html"><![CDATA[<p>这个是一道面试题，挺有趣的，考察的也算是对已有知识的利用和知识面的广度。</p>
<p>1.利用全局对象和静态对象的性质<br>
在main函数之前声明一个类的全局的对象。那么其执行顺序，根据全局对象的生存期和作用域，肯定先于main函数。<br>
静态对象同理</p>
<p>2.attribute关键字<br>
gcc中可以使用attribute关键字，声明constructor和destructor函数</p>
<pre><code>__attribute__((constructor)) void before_main()  
{  
   printf(&quot;before main\n&quot;); 
}  
  
__attribute__((destructor)) void after_main()  
{  
   printf(&quot;after main\n&quot;);  
}
</code></pre>
<p>3.onexit函数<br>
microsoft的C++编译器支持onexit函数。原型如下：</p>
<pre><code>_onexit_t _onexit(
   _onexit_t function
);

_onexit_t_m _onexit_m(
   _onexit_t_m function
);
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[覆盖、重载和隐藏的区别]]></title>
        <id>https://lixin-scut.github.io//post/fu-gai-chong-zai-he-yin-cang-de-qu-bie</id>
        <link href="https://lixin-scut.github.io//post/fu-gai-chong-zai-he-yin-cang-de-qu-bie">
        </link>
        <updated>2020-03-18T07:13:28.000Z</updated>
        <content type="html"><![CDATA[<ul>
<li>覆盖（override）是派生类中重新定义的函数，其函数名、参数列表（个数、类型和顺序）、返回值类型和父类完全相同，只有函数体有区别。派生类虽然继承了基类的同名函数，但用派生类对象调用该函数时会根据对象类型调用相应的函数。覆盖<strong>只能发生在类的成员函数</strong>中（对于override来说，一般用在虚函数上）。</li>
<li>隐藏是指派生类函数屏蔽了与其同名的函数，这里仅要求基类和派生类函数的函数名相同即可。隐藏比覆盖涵盖的范围更宽泛，毕竟参数不加限定。</li>
<li>重载是具有相同函数名但参数列表不同（个数、类型或顺序）的两个函数（不关心返回值），当调用函数时根据传递的参数列表来确定具体调用哪个函数。重载<strong>可以是同一个类的成员函数也可以是类外函数</strong>。</li>
<li>注意隐藏和重载的重要区别在于是否可见和候选函数，如果被隐藏了，等于优先级降低，所以可能直接不可见，无法作为候选函数，只有当前作用域没有适合的候选函数时才会到外层作用域考虑被隐藏的同名函数</li>
</ul>
<p><strong>重载和函数模板的区别</strong></p>
<ol>
<li>重载需要多个函数，这些函数彼此之间函数名相同，但参数列表中参数数量和类型不同。在区分各个重载函数时我们并不关心函数体。</li>
<li>模板函数是一个通用函数，函数的类型和形参不直接指定而用虚拟类型来代表。但只适用于形参个数相同而类型不同的函数。</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[深拷贝与浅拷贝]]></title>
        <id>https://lixin-scut.github.io//post/shen-kao-bei-yu-qian-kao-bei</id>
        <link href="https://lixin-scut.github.io//post/shen-kao-bei-yu-qian-kao-bei">
        </link>
        <updated>2020-03-18T06:59:01.000Z</updated>
        <content type="html"><![CDATA[<ol>
<li>浅拷贝：浅拷贝仅仅是拷贝向被指向对象的内存地址，如果原地址中对象被改变了，那么浅拷贝指向的对象也会相应改变。所以指针和引用的拷贝都属于浅拷贝</li>
<li>深拷贝：开辟了一块新的内存地址用于存放实际指向的对象，最后会存在两份相同的数据。</li>
<li>所以当同一类的不同对象互相赋值时，需要注意含有指针或引用的成员。特别是指向动态内存中的对象，如果B中有一个成员变量指针已经申请了动态内存，那A中的那个成员变量也指向同一块内存。这就会出现问题：当B把内存释放了，这时A的指针就是空悬指针了</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[图 329. 矩阵中的最长递增路径[困难][未做出]]]></title>
        <id>https://lixin-scut.github.io//post/tu-329-ju-zhen-zhong-de-zui-chang-di-zeng-lu-jing-kun-nan-wei-zuo-chu</id>
        <link href="https://lixin-scut.github.io//post/tu-329-ju-zhen-zhong-de-zui-chang-di-zeng-lu-jing-kun-nan-wei-zuo-chu">
        </link>
        <updated>2020-03-18T04:55:39.000Z</updated>
        <content type="html"><![CDATA[<blockquote>
<p>给定一个整数矩阵，找出最长递增路径的长度。<br>
对于每个单元格，你可以往上，下，左，右四个方向移动。 你不能在对角线方向上移动或移动到边界外（即不允许环绕）。<br>
示例 1:<br>
输入: nums =<br>
[<br>
[9,9,4],<br>
[6,6,8],<br>
[2,1,1]<br>
]<br>
输出: 4<br>
解释: 最长递增路径为 [1, 2, 6, 9]。<br>
示例 2:<br>
输入: nums =<br>
[<br>
[3,4,5],<br>
[3,2,6],<br>
[2,2,1]<br>
]<br>
输出: 4<br>
解释: 最长递增路径是 [3, 4, 5, 6]。注意不允许在对角线方向上移动。<br>
来源：力扣（LeetCode）<br>
链接：https://leetcode-cn.com/problems/longest-increasing-path-in-a-matrix<br>
著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。</p>
</blockquote>
<p>【未做出】<br>
首先我想用的是动态规划，但是很明显单纯的动态规划是不够的，<br>
因为动态规划需要依赖于过去的状态和状态转移方程，而我们无法从后面的信息去更新现有的信息（右下角更新左上角）<br>
所以看了题解之后发现果然是必须利用存储信息的<br>
利用存储信息然后不断地更新旧信息，从而使得不需要更新的信息只需要O(1)的时间复杂度<br>
代码如下：<br>
注意diretion数组，用于上下左右四个位置的转移，减少循环和判断条件的复杂度</p>
<pre><code>class Solution {
public:
    int longestIncreasingPath(vector&lt;vector&lt;int&gt;&gt;&amp; matrix) {
        if(matrix.empty())
        {   return 0; }
        row = matrix.size(); 
        col = matrix[0].size();
        
        vector&lt;vector&lt;int&gt;&gt; cache(row,vector&lt;int&gt;(col,0));
        int res = 0;
        
        for(int r = 0; r &lt; row; ++r )
        {
            for(int c = 0; c &lt; col; ++c)
            {
                int temp = longestIncreasingPath(matrix, r, c, cache);
                res = res &gt; temp? res : temp;
            }
        }
        
        return res;
    }
    
    int longestIncreasingPath(vector&lt;vector&lt;int&gt;&gt;&amp; matrix, int r, int c, vector&lt;vector&lt;int&gt;&gt;&amp; cache)
    {
        if(cache[r][c] != 0)
        {   return cache[r][c]; }
        
        for(auto d : direction)
        {
            if(r+d[0] &gt;= 0 &amp;&amp; r+d[0] &lt; row 
               &amp;&amp; c+d[1] &gt;= 0 &amp;&amp; c+d[1] &lt; col 
               &amp;&amp; matrix[r+d[0]][c+d[1]] &gt; matrix[r][c])
            {
                cache[r][c] = max(cache[r][c],longestIncreasingPath(matrix, r+d[0], c+d[1], cache));
        
            }
        }
        
        return ++cache[r][c];
    }

private:
    int row, col;
    vector&lt;vector&lt;int&gt;&gt; direction  = { { 0 , 1 }, { 1 , 0 }, { 0 , -1 }, { -1 , 0 } };
};
</code></pre>
<p>官方题解：</p>
<blockquote>
<p>正文<br>
方法一：朴素的深度优先搜索 【超时】<br>
直觉<br>
深度优先搜索可以找到从任何单元格开始的最长递增路径。我们可以对全部单元格进行深度优先搜索。<br>
算法<br>
每个单元格可以看作图<br>
G 中的一个定点。若两相邻细胞的值满足a&lt;b，则存在有向边 (a,b)。问题转化成：<br>
寻找有向图 G 中的最长路径。<br>
很显然,我们可以使用深度优先搜索或广度优先搜索从根开始访问连接的所有细胞。在搜索期间更新路径的最大长度，并在搜索完成后得到答案。<br>
一般而言，在深度优先搜索或广度优先搜索中，我们可以使用集合visited 来避免重复访问。在下一节中我们将介绍基于此的更优算法。</p>
</blockquote>
<pre><code>// Naive DFS Solution
// Time Limit Exceeded
public class Solution {
  private static final int[][] dirs = {{0, 1}, {1, 0}, {0, -1}, {-1, 0}};
  private int m, n;

  public int longestIncreasingPath(int[][] matrix) {
      if (matrix.length == 0) return 0;
      m = matrix.length;
      n = matrix[0].length;
      int ans = 0;
      for (int i = 0; i &lt; m; ++i)
          for (int j = 0; j &lt; n; ++j)
              ans = Math.max(ans, dfs(matrix, i, j));
      return ans;
  }

  private int dfs(int[][] matrix, int i, int j) {
      int ans = 0;
      for (int[] d : dirs) {
          int x = i + d[0], y = j + d[1];
          if (0 &lt;= x &amp;&amp; x &lt; m &amp;&amp; 0 &lt;= y &amp;&amp; y &lt; n &amp;&amp; matrix[x][y] &gt; matrix[i][j])
              ans = Math.max(ans, dfs(matrix, x, y));
      }
      return ++ans;
  }
}
</code></pre>
<blockquote>
<p>复杂度分析<br>
时间复杂度 ：O(2^(m+n))。对每个有效递增路径均进行搜索。在最坏情况下，会有 O(2^(m+n)) 次调用。例如：<br>
空间复杂度 ： O(mn)。 对于每次深度优先搜索，系统栈需要 O(h) 空间，其中 h 为递归的最深深度。最坏情况下，O(h)=O(mn)。</p>
</blockquote>
<blockquote>
<p>解法二：记忆化深度优先搜索 【通过】<br>
直觉<br>
将递归的结果存储下来，这样每个子问题只需要计算一次。<br>
算法<br>
从上面的分析中，我们知道在淳朴的深度优先搜索方法中有许多重复的计算。<br>
一个优化途径是我们可以用一个集合来避免一次深度优先搜索中的重复访问。该优化可以将一次深度优先搜索的时间复杂度优化到 O(mn)<br>
O(mn)，总时间复杂度 O(m<sup>2*n</sup>2 )。<br>
下面介绍一个更有力的优化方法，记忆化。<br>
在计算中，记忆化是一种优化技术，它通过存储“昂贵”的函数调用的结果，在相同的输入再次出现时返回缓存的结果，以此加快程序的速度。<br>
在本问题中，我们多次递归调用 dfs(x, y) 。但是，如果我们已经知道四个相邻单元格的结果，就只需要常数时间。在搜索过程中，如果未计算过单元格的结果，我们会计算并将其缓存；否则，直接从缓存中获取之。<br>
Java</p>
</blockquote>
<pre><code>// DFS + Memoization Solution
// Accepted and Recommended
public class Solution {
    private static final int[][] dirs = {{0, 1}, {1, 0}, {0, -1}, {-1, 0}};
    private int m, n;

    public int longestIncreasingPath(int[][] matrix) {
        if (matrix.length == 0) return 0;
        m = matrix.length; n = matrix[0].length;
        int[][] cache = new int[m][n];
        int ans = 0;
        for (int i = 0; i &lt; m; ++i)
            for (int j = 0; j &lt; n; ++j)
                ans = Math.max(ans, dfs(matrix, i, j, cache));
        return ans;
    }

    private int dfs(int[][] matrix, int i, int j, int[][] cache) {
        if (cache[i][j] != 0) return cache[i][j];
        for (int[] d : dirs) {
            int x = i + d[0], y = j + d[1];
            if (0 &lt;= x &amp;&amp; x &lt; m &amp;&amp; 0 &lt;= y &amp;&amp; y &lt; n &amp;&amp; matrix[x][y] &gt; matrix[i][j])
                cache[i][j] = Math.max(cache[i][j], dfs(matrix, x, y, cache));
        }
        return ++cache[i][j];
    }
}

</code></pre>
<blockquote>
<p>复杂度分析<br>
时间复杂度 : O(mn)。 每个顶点/单元格均计算一次，且只被计算一次。每条边也均计算一次并只计算一次。总时间复杂度是 O(V+E)。V 是顶点总数，E 是边总数。本问题中，O(V)=O(mn)，O(E)=O(4V)=O(mn)。<br>
空间复杂度 : O(mn)。缓存决定了空间复杂度。</p>
</blockquote>
<blockquote>
<p>方法三：“剥洋葱”（动态规划） 【通过】<br>
直觉<br>
每个细胞的结果只与相邻的结果相关，能否使用动态规划？<br>
算法<br>
如果我们定义从单元格 (i,j) 开始的最长递增路径为函数f(i,j)<br>
则可以写出状态转移函数<br>
<code>f(i,j)=max{f(x,y)∣(x,y) is a nei∗∗∗or of(i,j) and matrix[x][y]&gt;matrix[i][j]}+1</code><br>
此公式与以前方法中使用的公式相同。有了状态转移函数，你可能会觉得可以使用动态规划来推导出所有结果，去他的深度优先搜索!<br>
这听起来很美好，可惜你忽略了一件事：我们没有依赖列表。<br>
想要让动态规划有效，如果问题 B 依赖于问题 A 的结果，就必须确保问题 A 比问题 B先计算。这样的依赖顺序对许多问题十分简单自然。如著名的斐波那契数列：<br>
F(0)=1,F(1)=1,F(n)=F(n−1)+F(n−2)<br>
子问题 F(n) 依赖于 F(n−1) 和 F(n−2)。因此，自然顺序就是正确的计算顺序。被依赖者总会先被计算。<br>
这种依赖顺序的术语是“拓扑顺序”或“拓扑排序”：<br>
对有向无环图的拓扑排序是顶点的一个线性排序，使得对于任何有向边 (u,v)，顶点 u 都在 顶点 v 的前面。<br>
在本问题中，拓扑顺序并不简单自然。没有矩阵的值，我们无法知道两个邻居 A 和 B 的依赖关系。作为预处理，我们必须显式执行拓扑排序。之后，我们可以按照存储的拓扑顺序使用状态转移函数动态地解决问题。<br>
有多种实现拓扑排序的方法。这里我们使用的是一种被称为“剥洋葱”的方法。其思路是在一个有向无环图中，会有一些不依赖于其他顶点的顶点，称为“叶子”。我们将这些叶子放在一个列表中（他们的内部排序不重要），然后将他们从图中移除。移除之后，会产生新的“叶子”。重复以上过程，就像一层一层一层地拨开洋葱的心。最后，列表中就会存储有效的拓扑排序。<br>
在本问题中，因为我们想要求出在整个图中最长的路径，也就是“洋葱”的层总数。因此，我们可以在“剥离”的期间计算层数，在不调用动态规划的情况下返回计数。</p>
</blockquote>
<pre><code>// Topological Sort Based Solution
// An Alternative Solution
public class Solution {
    private static final int[][] dir = {{0, 1}, {1, 0}, {0, -1}, {-1, 0}};
    private int m, n;
    public int longestIncreasingPath(int[][] grid) {
        int m = grid.length;
        if (m == 0) return 0;
        int n = grid[0].length;
        // padding the matrix with zero as boundaries
        // assuming all positive integer, otherwise use INT_MIN as boundaries
        int[][] matrix = new int[m + 2][n + 2];
        for (int i = 0; i &lt; m; ++i)
            System.arraycopy(grid[i], 0, matrix[i + 1], 1, n);

        // calculate outdegrees
        int[][] outdegree = new int[m + 2][n + 2];
        for (int i = 1; i &lt;= m; ++i)
            for (int j = 1; j &lt;= n; ++j)
                for (int[] d: dir)
                    if (matrix[i][j] &lt; matrix[i + d[0]][j + d[1]])
                        outdegree[i][j]++;

        // find leaves who have zero out degree as the initial level
        n += 2;
        m += 2;
        List&lt;int[]&gt; leaves = new ArrayList&lt;&gt;();
        for (int i = 1; i &lt; m - 1; ++i)
            for (int j = 1; j &lt; n - 1; ++j)
                if (outdegree[i][j] == 0) leaves.add(new int[]{i, j});

        // remove leaves level by level in topological order
        int height = 0;
        while (!leaves.isEmpty()) {
            height++;
            List&lt;int[]&gt; newLeaves = new ArrayList&lt;&gt;();
            for (int[] node : leaves) {
                for (int[] d:dir) {
                    int x = node[0] + d[0], y = node[1] + d[1];
                    if (matrix[node[0]][node[1]] &gt; matrix[x][y])
                        if (--outdegree[x][y] == 0)
                            newLeaves.add(new int[]{x, y});
                }
            }
            leaves = newLeaves;
        }
        return height;
    }
}
</code></pre>
<blockquote>
<p>复杂度分析<br>
时间复杂度 : O(mn)。拓扑排序的时间复杂度为 O(V+E)=O(mn)。V 是顶点总数，<br>
E 是边总数。本问题中，O(V)=O(mn)，O(E)=O(4V)=O(mn)。<br>
空间复杂度 : O(mn)。我们需要存储出度和每层的叶子。<br>
要点<br>
记忆化: 对于大量重复调用的问题，缓存其结果。<br>
动态规划要求按照拓扑顺序解决子问题。对于很多问题，拓扑顺序与自然秩序一致。而对于那些并非如此的问题，需要首先执行拓扑排序。因此,对于复杂拓扑问题（如本题），使用记忆化搜索通常是更容易更好的选择。</p>
</blockquote>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[链表的环问题]]></title>
        <id>https://lixin-scut.github.io//post/lian-biao-de-huan-wen-ti</id>
        <link href="https://lixin-scut.github.io//post/lian-biao-de-huan-wen-ti">
        </link>
        <updated>2020-03-17T02:16:14.000Z</updated>
        <content type="html"><![CDATA[<p>因为链表的环问题比较多，我直接整理为一个博文，方便查阅</p>
<p>相关博文传送门<br>
<a href="https://lixin-scut.github.io/post/lian-biao-142-huan-xing-lian-biao-iizhong-deng-wei-zuo-chu/">链表 142. 环形链表 II[中等]</a><br>
<a href="https://lixin-scut.github.io/post/lian-biao-141-huan-xing-lian-biao-nan-du-jian-dan/">链表 141. 环形链表 难度：简单</a><br>
<a href="https://lixin-scut.github.io/post/lian-biao-ti-23lian-biao-zhong-huan-de-ru-kou-jie-dian/">链表 题23:链表中环的入口节点</a></p>
<p>链表的环问题主要可以分为下面几个部分：</p>
<ol>
<li>链表长度</li>
<li>链表是否有环</li>
<li>链表环入口</li>
<li>链表环长度<br>
下面就逐一解决</li>
</ol>
<h3 id="单链表长度">单链表长度</h3>
<p><strong>思路：</strong><br>
这个比较简单，直接遍历一次并计数即可<br>
<strong>代码：</strong></p>
<pre><code>//计算单链表长度
int lengthNode(Node *node)
{
	if (nullptr == node) // 防止漏写= 变为 赋值node为空指针
	{
		cout &lt;&lt; &quot;error&quot; &lt;&lt; endl;
		return 0;
	}
	int length= 0;
	Node *pTmp = node;
	while (pTmp-&gt;next) //从头到尾遍历链表，计数器依次累加
	{
		pTmp = pTmp-&gt;next;
		++length;
	}
	return length;
}
</code></pre>
<h3 id="单链表是否有环">单链表是否有环</h3>
<p><strong>思路：</strong><br>
  设置两个指针，都指向头结点，一个走的快，一个走的慢，<br>
  如果有环，那么若干步以后，快指针总会超过慢的指针一圈；<br>
  如果没有，那么若干步以后，快指针指向NULL。</p>
<p><strong>数学证明：</strong></p>
<blockquote>
<p>根据floyd判圈办法，一个快指针一个慢指针，二者一定在环上相遇，设相遇点为M点，<br>
快是慢的速度的2倍，时间相同，设慢的距离为s，那么快的距离为2s<br>
m为链表头距离环开始位置的距离，k为环开始位置到M点的距离, N为环长度<br>
s = m + aN +k, 2s = m + bN +k，二者相减，s = (a-b)*N<br>
由此可见，慢指针走过的距离是环长的整数倍，即链表头到M点是环长的整数倍<br>
如果是1倍的话，把m截距离旋转到环上，跟环融合，那么链表头一定落在M点，<br>
即fast和slow都落在M点，那么二者到环开始位置距离相同，必然在此处相遇。<br>
如果是N倍（N&gt;1）时，只不过slow指针多转几圈而已，后二者仍在此处相遇</p>
</blockquote>
<p><strong>代码</strong></p>
<pre><code>bool hasCycle(ListNode *head) {
        if(!head)
            return false;
        ListNode *fast=head-&gt;next;
        ListNode *slow=head;
        while(fast!=slow){
            if(fast==NULL||fast-&gt;next==NULL)
                return false;
            fast=fast-&gt;next-&gt;next;
            slow=slow-&gt;next;
        }
        return true;
    }
</code></pre>
<h3 id="单链表环入口">单链表环入口</h3>
<p><strong>思路</strong><br>
  依然使用双指针法。首先使得两个指针相遇<br>
  然后slow指针位置不变 ，将fast指针重新指向链表头部节点 ；slow和fast同时每轮向前走 1 步；<br>
  两指针重合时指向链表环入口 。<br>
  返回slow指针指向的节点。</p>
<p><strong>数学证明</strong></p>
<blockquote>
<p>双指针第一次相遇： 设两指针 fast，slow 指向链表头部 head，fast 每轮走 2 步，slow 每轮走 1 步；<br>
当fast == slow时， 两指针在环中 第一次相遇 。<br>
下面分析此时fast 与 slow走过的 步数关系 ：<br>
设链表共有 a+b 个节点，其中 链表头部到链表入口 有 a 个节点（不计链表入口节点）， 链表环 有 b 个节点（这里需要注意，a 和 b 是未知数）；设两指针分别走了f，s 步，则有：<br>
fast 走的步数是slow步数的 2 倍，即 f=2s；（解析： fast 每轮走 2 步）<br>
fast 比 slow多走了 n 个环的长度，即f=s+nb；（ 解析： 双指针都走过 a 步，然后在环内绕圈直到重合，重合时 fast 比 slow 多走 环的长度整数倍 ）；<br>
以上两式相减得：f=2nb，s=nb，即fast和slow 指针分别走了 2n，n个环的周长 （注意： n 是未知数，不同链表的情况不同）。<br>
目前情况分析：<br>
如果让指针从链表头部一直向前走并统计步数k，那么所有 走到链表入口节点时的步数 是：k=a+nb（先走 a 步到入口节点，之后每绕 1 圈环（ b 步）都会再次到入口节点）。<br>
而目前，slow 指针走过的步数为 nb 步。因此，我们只要想办法让 slow 再走 a 步停下来，就可以到环的入口。<br>
但是我们不知道 a 的值，该怎么办？依然是使用双指针法。我们构建一个指针，此指针需要有以下性质：此指针和slow 一起向前走 a 步后，两者在入口节点重合。那么从哪里走到入口节点需要 a 步？答案是链表头部head。<br>
双指针第二次相遇：<br>
slow指针位置不变 ，将fast指针重新 指向链表头部节点 ；slow和fast同时每轮向前走 1 步；<br>
TIPS：此时 f=0，s=nb ；<br>
当 fast 指针走到f=a 步时，slow 指针走到步s=a+nb，此时 两指针重合，并同时指向链表环入口 。<br>
返回slow指针指向的节点。</p>
</blockquote>
<p><strong>代码</strong></p>
<pre><code>ListNode *detectCycle(ListNode *head)
{
        if(nullptr == head) 
				{ return NULL; }
        ListNode *fast = head-&gt;next,*slow=head;
        while(fast != slow)
				{
            if(nullptr != fast &amp;&amp; nullptr != fast-&gt;next)
						{
                fast = fast-&gt;next-&gt;next; //注意判断条件和两次连续next，没必要分开两次判断next
						}
            else
             {   return NULL; }
            slow = slow-&gt;next;
        }
        fast = head;
        slow = slow-&gt;next;//注意这里，因为fast=head;相当于提前走了一步
        while(fast != slow)
       {     
						 fast = fast-&gt;next;
						 slow = slow-&gt;next;
				 }
        return slow;     
}
</code></pre>
<h3 id="单链表环长度">单链表环长度</h3>
<p><strong>思路</strong><br>
  快慢指针第一次相遇（超一圈）时开始计数，计数器累加，第二次相遇时停止计数<br>
  第二次相遇的时候快指针比慢指针正好又多走了一圈，也就是多走的距离等于环长</p>
<p><strong>代码：</strong></p>
<pre><code>//计算单链表环的长度  
int loopLength(pNode pHead)  
{  
	//首先通过上面的借口判断，链表是否有环
	if(isLoop(pHead) == false) 
	{
		return 0;  //没有环，则直接返回
	}
	pNode fast = pHead;  
	pNode slow = pHead;  
	int length = 0;  //环的长度
	bool begin = false;  //第一次相遇的 flag
	bool agian = false;  //第二次相遇的 flag
	while( fast != NULL &amp;&amp; fast-&gt;next != NULL)  
	{  
		fast = fast-&gt;next-&gt;next;  
		slow = slow-&gt;next;  
		//超两圈后停止计数，挑出循环  
		if(fast == slow &amp;&amp; agian == true)  
		{
			break;  
		}
		
		//超一圈后开始计数  
		if(fast == slow &amp;&amp; agian == false)  
		{             
			begin = true;  
			agian = true;  
		}  
		
		//计数 +1  
		if(begin == true)  
		{
			++length;
		}
	}  
	
	return length;  
} 
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[volatile关键字]]></title>
        <id>https://lixin-scut.github.io//post/volatile-guan-jian-zi</id>
        <link href="https://lixin-scut.github.io//post/volatile-guan-jian-zi">
        </link>
        <updated>2020-03-16T10:32:07.000Z</updated>
        <content type="html"><![CDATA[<p>  volatile 关键字是一种类型修饰符，用它声明的类型变量表示可以被某些编译器未知的因素更改，比如：操作系统、硬件或者其它线程等。<br>
  遇到这个关键字声明的变量，编译器对访问该变量的代码就不再进行优化，比如<br>
  <code>int num1 = numConst; int num2 = numConst;</code><br>
  由于编译器认为num2和num1所需赋的值一致，可能会把寄存器中num1的值直接给num2，但是多线程中很可能numConst已经被另一个线程改变了，从而导致num2的值不正确。<br>
  如果使用volatile来限定numConst，则可以提供对特殊地址的稳定访问。声明时语法：<br>
  <code>int volatile vInt;</code><br>
  当要求使用 volatile 声明的变量的值的时候，系统总是重新从它所在的内存读取数据，即使它前面的指令刚刚从该处读取过数据。而且读取的数据立刻被保存。<br>
volatile用在如下的几个地方：</p>
<ol>
<li>中断服务程序中修改的供其它程序检测的变量需要加volatile；</li>
<li>多进程或多线程的并行并发环境下各任务间共享的标志应该加volatile；</li>
<li>存储器映射的硬件寄存器通常也要加volatile说明，因为每次对它的读写都可能由不同意义；</li>
</ol>
<p>详细用法可参考<a href="https://www.cnblogs.com/god-of-death/p/7852394.html">C/C++ Volatile关键词深度剖析</a></p>
]]></content>
    </entry>
</feed>
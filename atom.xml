<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://lixin-scut.github.io/</id>
    <title>Lixin-SCUT</title>
    <updated>2020-03-03T08:20:31.087Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://lixin-scut.github.io/"/>
    <link rel="self" href="https://lixin-scut.github.io//atom.xml"/>
    <subtitle>In the darkest night,Rising like a spire.</subtitle>
    <logo>https://lixin-scut.github.io//images/avatar.png</logo>
    <icon>https://lixin-scut.github.io//favicon.ico</icon>
    <rights>All rights reserved 2020, Lixin-SCUT</rights>
    <entry>
        <title type="html"><![CDATA[死锁]]></title>
        <id>https://lixin-scut.github.io//post/si-suo</id>
        <link href="https://lixin-scut.github.io//post/si-suo">
        </link>
        <updated>2020-03-03T07:25:22.000Z</updated>
        <content type="html"><![CDATA[<h3 id="死锁">死锁</h3>
<p>  如果一个进程集合中的每个进程都在等待只能由该进程集合中的其他进程才能引发的事件，该进程集合就是死锁的。<br>
  由于所有的进程都在等待，所以没有一个进程能引发可以唤醒该进程集合中的其他进程的事件，这样, 所有的进程都只好无限期等待。<br>
  在大多数情况下，每个进程所等待的事件是释放该进程集合中其他进程所占有的资源。换言之，这个死锁进程集合中的每一个进程都在等待另一个死锁的进程已经占有的资源。但是由于所有进程都不能运行，它们中的任何一个都无法释放资源，所以没有一个进程可以被唤醒。 这种死锁称为资源死锁（resource deadlock）。</p>
<h3 id="发生条件">发生条件</h3>
<p>资源死锁的条件<br>
发生（资源）死锁的四个必要条件：<br>
1）	互斥条件。每个资源要么已经分配给了一个进程，要么就是可用的。<br>
2）	占有和等待条件。已经得到了某个资源的进程可以再请求新的资源。<br>
3）	不可抢占条件。已经分配给一个进程的资源不能强制性地被抢占，它只能被占有它的进程显式地释放。<br>
4）	环路等待条件。死锁发生时，系统中一定有由两个或两个以上的进程组成的一条环路，该环路中的每个进程都在等待着下一个进程所占有的资源。<br>
  死锁发生时，以上四个条件一定是<strong>同时满足</strong>的。如果其中任何一个条件不成立，死锁就不会发生。</p>
<h3 id="处理策略">处理策略</h3>
<p>有四种处理死锁的策略：<br>
1）	鸵鸟算法：忽略该问题。也许如果你忽略它，它也会忽略你。<br>
2）	检测死锁并恢复。让死锁发生，检测它们是否发生，一旦发生死锁，采取行动解决问题。<br>
3）	死锁避免，仔细对资源进行分配，动态地避免死锁。<br>
4）	通过破坏引起死锁的四个必要条件之一，防止死锁的产生。</p>
<h3 id="死锁检测">死锁检测</h3>
<p>  对系统构造一张资源分配图，如果这张图包含了一个或一个以上的环， 那么死锁就存在。在此环中的任何一个进程都是死锁进程。如果没有这样的环，系统就没有发生死锁。<br>
  如果有多种相同的资源存在，就需要采用另一种方法来检测死锁：基于矩阵的算 法来检测这个进程中的死锁。</p>
<h3 id="从死锁中恢复">从死锁中恢复</h3>
<ol>
<li>利用抢占恢复<br>
临时将某个资源从它的当前所有者那里转移到另一个进程</li>
<li>利用回滚恢复<br>
周期性地对进程进行检查点检查（checkpointed）。进程检查点检查就是将进程的状态写入一个文件以备以后重启。将该进程复位到一个更早的状态，那时它还没有取得所需的资源，接着就把这个资源分配给一个 死锁进程。如果复位后的进程试图重新获得对该资源的控制，它就必须一直等到该资源可用时为止。</li>
<li>通过杀死进程恢复<br>
最直接也是最简单的解决死锁的方法是杀死一个或若干个进程。一种方法是杀掉环中的一个进程。如果走运的话，其他进程将可以继续。如果这样做行不通的话，就需要继续杀死别的进程直到打破死锁环。<br>
  另一种方法是选一个环外的进程作为牺牲品以释放该进程的资源。<br>
  另一方面，更新数据库的进程在第二次运行时并非总是安全的。如果一个进程将数据库的某个记录 加1,那么运行它一次，将它杀死后，再次执行，就会对该记录加2,这显然是错误的。</li>
</ol>
<h3 id="死锁避免">死锁避免</h3>
<ol>
<li>资源轨迹图</li>
<li>安全状态和不安全状态<br>
  不安全状态并不是死锁。系统能运行一段时间。实际上，甚至有一个进程能够完成。安全状态和不安全状态的区别是：从安全状态出发，系统能够保证所有进程都 能完成，而从不安全状态出发，就没有这样的保证。</li>
<li>银行家算法<br>
  银行家算法就是对每一个请求迸行检查，检查如果满足这一请求是否会达到安全状态。若是，那么 就满足该请求，若否，那么就推迟对这一请求的满足。为了看状态是否安全，银行家看他是否有足够的 资源满足某一个客户。如果可以，那么这笔投资认为是能够收回的，并且接着检查最接近最大限额的一 个客户，以此类推。如果所有投资最终都被收回，那么该状态是安全的，最初的请求可以批准。</li>
</ol>
<h3 id="死锁预防">死锁预防</h3>
<ol>
<li>破坏互斥条件：如果资源不被一个进程所独占，那么死锁肯定不会产生。<br>
  允许两 个进程同时使用打印机会造成混乱，通过采用假脱机打印机（spooling printer）技术可以允许若干个进程同时产生输出。该模型中惟一真正请求使用物理打印机的进程是打印机守护进程，由于守护进程决不会请求别的资源，所以不会因打印机而产生死锁。</li>
<li>破坏占有和等待条件：只要禁止已持有资源的进程再等待其他资源便可以消 除死锁。<br>
  一种实现方法是规定所有进程在开始执行前请求所需的全部资源。如果所需的全部资源可用， 那么就将它们分配给这个进程，于是该进程肯定能够运行结束。如果有一个或多个资源正被使用，那么就不进行分配，进程等待。<br>
  另一种破坏占有和等待条件的略有不同的方案是，要求当一个进程请求资源时，先暂时释放其当前占用的所有资源，然后再尝试一次获得所需的全部资源。</li>
<li>破坏不可抢占条件<br>
  现在只剩下一个条件了。消除环路等待有几种方法。一种是保证每一个进程在任何时刻只能占用一个资源，如果要请求另外一个资源，它必须先释放第一个资源。但<br>
  该算法的一个变种是摈弃必须按升序请求资源的限制，而仅仅要求不允许进程请求比当前所占有资源编号低的资源。</li>
</ol>
<h3 id="两阶段加锁">两阶段加锁</h3>
<p>  在第一阶段，进程试图对所有所需的记录进行加锁， 一次锁一个记录。如果第一阶段加锁成功，就开始第二阶段，完成更新然后释放锁。在第一阶段并没有做实际的工作。<br>
  如果在第一阶段某个进程需要的记录已经被加锁，那么该进程释放它所有加锁的记录，然后重新开始第一阶段。从某种意义上说，这种方法类似于提前或者至少是未实施一些不可逆的操作之前请求所有资源。<br>
  如果在第一阶段遇到了已加锁的记录，并不会释放锁然后重新开始， 这就可能产生死锁。<br>
  不过，在一般意义下，这种策略并不通用。例如，在实时系统和进程控制系统中，由于一个进程缺 少一个可用资源就半途中断它，并重新开始该进程，这是不可接受的。</p>
<h3 id="通信死锁">通信死锁</h3>
<p>  另一种死锁发生在通信系统中（比如说网络），即两个或两个以上进程利用发送信息来通信时。一种普遍的情形是进程A向进程B发送请求信息，然后阻塞直至B回复。假设请求信息丢失，A将阻塞以等待回复，而B 会阻塞等待一个向其发送命令的请求，因此发生死锁。<br>
  仅仅如此并非经典的资源死锁。A没有占有B所需的资源，反之亦然。事实上，并没有完全可见的资源。但是，根据标准的定义，在一系列进程中，每个进程因为等待另外一个进程引发的事件而产生阻塞，这就是一种死锁。相比于更加常见的资源死锁，我们把上面这种情况叫做通信死锁 （communication deadlock）</p>
<h3 id="活锁">活锁</h3>
<p>  在某种情形下，轮询（忙等待）可用于进入临界区或存取资源。<br>
  现在假设有一对进程使用两种资源。每个进程需要两种资源，它们利用轮询原语enter_region去尝试取得必要的锁，如果尝试失败，则该进程继续尝试。如果进程A先运行并得到资源1,然后进程2运行并得到资源2,以后不管哪一个进程运行，都不会有任何进展，但是哪一个进程也没有被阻塞。结果 是两个进程总是一再消耗完分配给它们的CPU配 额，但是没有进展也没有阻塞。因此，没有出现 死锁现象（因为没有进程阻塞），但是从现象上 看好像死锁发生了，这就是活锁（livelock）。</p>
<h3 id="饥饿">饥饿</h3>
<p>  与死锁和活锁非常相似的一个问题是饥饿（starvation）。在动态运行的系统中，在任何时刻都可能请求资源。这就需要一些策略来决定在什么时候谁获得什么资源。虽然这个策略表面上很有道理，但依 然有可能使一些进程永远得不到服务，虽然它们并不是死锁进程。<br>
作为一个例子，考虑打印机分配。设想系统采用某种算法来保证打印机分配不产生死锁。现在假设若干进程同时都请求打印机，究竟哪一个进程能获得打印机呢？<br>
一个可能的分配方案是把打印机分配给打印最小文件的进程（假设这个信息可知）。这个方法让尽 量多的顾客满意，并且看起来很公平。我们考虑下面的情况：在一个繁忙的系统中，有一个进程有一个 很大的文件要打印，每当打印机空闲，系统纵观所有进程，并把打印机分配给打印最小文件的进程。如 果存在一个固定的进程流，其中的进程都是只打印小文件，那么，要打印大文件的进程永远也得不到打 印机。很简单，它会饥饿而死”（无限制地推后，尽管它没有被阻塞）。<br>
  饥饿可以通过先来先服务资源分配策略来避免。在这种机制下，等待最久的进程会是下一个被调度的进程。随着时间的推移，所有进程都会变成最“老”的，因而，最终能够获得资源而完成。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Linux文件系统]]></title>
        <id>https://lixin-scut.github.io//post/linux-wen-jian-xi-tong</id>
        <link href="https://lixin-scut.github.io//post/linux-wen-jian-xi-tong">
        </link>
        <updated>2020-03-03T07:09:15.000Z</updated>
        <content type="html"><![CDATA[<h3 id="文件系统">文件系统</h3>
<p>磁盘分区完毕后还需要进行格式化(format)，之后操作系统才能够使用这个文件系统。这是因为每种操作系统所设定的文件属性/权限并不相同。为了存放这些文件所需的数据，因此就需要将分区槽进行格式化，以成为操作系统能够利用的『文件系统格式(filesystem)』<br>
文件系统通常会将这两部份的数据（文件权限(rwx)与文件属性(拥有者、 群组、时间参数等)）分别存放在不同的区块，权限与属性放置到 inode 中，至于实际数据则放置到 data block 区块中</p>
<h3 id="inode">inode</h3>
<p>superblock：记录此 filesystem 的整体信息，包括 inode/block 的总量、使用量、剩余量， 以及文件系统的 格式与相关信息等；<br>
inode：记录文件的属性，一个文件占用一个 inode，同时记录此文件的数据所在的 block 号码；</p>
<p>  每个文件都会占用一个 inode ，inode 内则有文件数据放置的 block 号码。<br>
  一个incode可能会拥有（占用）多个block，这种数据存取的方法我们称为索引式文件系统(indexed allocation)</p>
<p>inode 记录的文件数据至少有底下这些<br>
该文件的存取模式(read/write/excute)；<br>
该文件的拥有者与群组(owner/group)；<br>
该文件的容量；<br>
该文件建立或状态改变的时间(ctime)；<br>
最近一次的读取时间(atime)；<br>
最近修改的时间(mtime)；<br>
定义文件特性的旗标(flag)，如 SetUID...；<br>
该文件真正内容的指向 (pointer)；<br>
每个 inode 大小均固定为 128 bytes (新的 ext4 与 xfs 可设定到 256 bytes)；<br>
每个文件都仅会占用一个 inode 而已；<br>
  承上，因此文件系统能够建立的文件数量与 inode 的数量有关；<br>
  系统读取文件时需要先找到 inode，并分析 inode 所记录的权限与用户是否符合，若符合才能够开始实际 读取 block 的内容。</p>
<h3 id="软链接和硬链接">软链接和硬链接</h3>
<p><strong>hard link</strong>：多个档名对应到同一个 inode 号码<br>
  hard link 只是在某个目录下新增一笔档名链接到某 inode 号码的关连记录而已<br>
  硬链接hard link最大的好处就是 『安全』，如果你将任何一个『档名』删除，其实 inode 与 block 都还是存在的<br>
  使用 hard link 设定链接文件时，磁盘的空间与 inode 的数目都不会改变<br>
  hard link 的制作中，其实还是可能会改变系统的 block 的，那就是当你新增这笔数据却刚好将目录的 block 填满时，就可能会新加一个 block 来记录文件名关连性，而导致磁盘空间的变化。不过， 一般 hard link 所用掉的关连数据量很小，所以通常不会改变 inode 与磁盘空间的大小<br>
hard link 是有限制的：</p>
<ol>
<li>不能跨 Filesystem；</li>
<li>不能直接 link 目录。</li>
<li>如果使用 hard link 链接到目录时， 链接的数据需要连同被链接目录底下的所有数据都建立链接</li>
</ol>
<p><strong>Symbolic Link</strong>(符号链接，亦即是快捷方式)<br>
  Symbolic link 就是在建立一个独立的 文件，而这个文件会让数据的读取指向他它link 的那个文件的档名！由于只是利用文件来做为指向的 动作， 所以，当来源档被删除之后，symbolic link 的文件会『开不了』，<br>
  符号链接可以跨越文件系统！！！也可以链接项目，因为只看文件名不看inode<br>
  两个文件指向不同的 inode 号码，当然就是两个独立的文件存在！ 而且连结档的重要内容就是他会写上目标文件的『文件名』<br>
  Symbolic Link 与 Windows 的快捷方式可以给他划上等号，由 Symbolic link 所建立的文件为一个独立的新的文件，所以会占用掉 inode 与 block</p>
<p>  个人测试：Symbolic Link之后删除源文件，会显示No such file 。但是！！！！我重建源文件后（用vim重建不同内容的同名文件或者用ln硬链接同名文件），会自动连接上！！！<br>
  stat对于软连接不会寻找源文件，lstat才会获取原始文件</p>
<p>使用 ln 如果不加任何参数的话，那么就是 Hard Link使用 ln 如果不加任何参数的话，那么就是 Hard Link要制作连结档就必须要使用 ln 这个指令，使用 ln 如果不加任何参数的话，那么就是 Hard Link</p>
<pre><code>[root@study ~]# ln [-sf] 来源文件 目标文件
选项与参数：
-s ：如果不加任何参数就进行连结，那就是 hard link，至于 -s 就是 symbolic link
-f ：如果 目标文件 存在时，就主动的将目标文件直接移除后再建立
</code></pre>
<p>关于目录的 link 数量<br>
  以 hard link 进行『文件的连结』时，可以发现，在 ls -l 所显 示的第二字段会增加一才对<br>
  当我们建立一个新目录名称为 /tmp/testing 时，基本上会有三个东西，那就是：</p>
<pre><code>/tmp/testing
/tmp/testing/.
/tmp/testing/..
</code></pre>
<p>所以新的目录的 link 数为 2 ，而上层目录的 link 数则会增加 1</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Math  题43:	整数中1出现的次数[未做出]]]></title>
        <id>https://lixin-scut.github.io//post/math-ti-43-zheng-shu-zhong-1-chu-xian-de-ci-shu-wei-zuo-chu</id>
        <link href="https://lixin-scut.github.io//post/math-ti-43-zheng-shu-zhong-1-chu-xian-de-ci-shu-wei-zuo-chu">
        </link>
        <updated>2020-03-03T00:53:59.000Z</updated>
        <content type="html"><![CDATA[<p>题目描述：</p>
<blockquote>
<p>输入一个整数n，求1~n这n个整数的十进制表示中1出现的次数。例如，输入12, 1〜12这些整数中包含1的数字有1、10、11和12,共出现了5次。</p>
</blockquote>
<p>  一开始把题目看成了统计当前数字中的1....<br>
  暴力法比较麻烦的是不仅要循环递增数字，还要循环数字本身，数字一旦大了时间复杂度就爆炸了<br>
  然后就是书中的规律法，比较有趣，就是使用逐位计算，需要注意的就是</p>
<ol>
<li>位数为1时的处理</li>
<li>最高位为1的次数需要额外+1</li>
<li>剩余位需要-2（当前位和最高位），理解为何剩余位可以取0-9而不是除去1或者只能取到当前最大值</li>
</ol>
<pre><code>class Solution {
public:
    //数学规律递归法【未做出】
    int NumberOf1Between1AndN_Solution(int n)
    {
        if(n&lt;1)
            return 0;
        string ns=to_string(n);
        int length=ns.size();
        int count=0;
        for(auto i:ns){
            count+=count_one(i-'0',length,n);
            --length;
        }
        return count;
    }
    
    int count_one(int i,int bit,int &amp;n){
        int count=0;
        if(i==0&amp;&amp;bit==1)
            return 0;
        if(bit==1){
            return 1;
        }
        
        //最高位为1的次数
        if(i&gt;1)
            count+=pow(10,bit-1);
        else if(i==1)
            count+=n-1*pow(10,bit-1)+1;
        
        //剩余位数为1的次数 
        count+=i*(bit-1)*pow(10,bit-2);
        n-=i*pow(10,bit-1);
        return count;
    }
    
    
    /*
    //逐个数计算法
    int NumberOf1Between1AndN_Solution(int n)
    {
        if(n&lt;1)
            return 0;
        int count;
        count=0;
        for(int i=1;i&lt;=n;++i){
            count+=count_one(i);
        }
        return count;
    }
    
    int count_one(int n){
        int count=0;
        int temp;
        while(n&gt;0){
            temp=n%10;
            if(temp==1)
                ++count;
            n/=10;
        }
        return count;
    }
    */
};
</code></pre>
<p>书本题解：<br>
  最直观的方法, 也就是累加1〜n中每个整数1出现的次数。我们可以每次通过对10求余数判断整数的个位数字是不是1。如果这个数字大于10,则除以10之后再判断个位数字是不是1。<br>
  在上述思路中，我们对每个数字都要做除法和求余运算，以求出该数字中1出现的次数。如果输入数字n，n有O(logn)位，我们需要判断每一位是不是1,那么它的时间复杂度是O(nlogn)。当输入的n非常大的时候，需要大量的计算，运算效率不高。<br>
  如果希望不用计算每个数字的1的个数，那就只能去寻找1在数字中出现的规律了。为了找到规律，我们不妨用一个稍微大一点的数字如21345 作为例子来分析。我们把1〜21345的所有数字分为两段：一段是1〜1345： 另一段是1346〜21345。<br>
  我们先看1346〜21345中1出现的次数。1的出现分为两种情况。首先分析1出现在最高位(本例中是万位)的情况。在1346-21345的数字中， 1出现在10000〜19999这10000个数字的万位中，一共出现了10^4次。<br>
  值得注意的是，并不是对所有5位数而言在万位出现的次数都是10000 次。对于万位是1的数字如输入12345, 1只出现在10000-12345的万位, 出现的次数不是1次，而是2346次，也就是除去最高数字之后剩下的数字再加上1 (2345+1=2346次)。<br>
  接下来分析1出现在除最高位之外的其他4位数中的情况。例子中 1346〜21345这20000个数字中后4位中1出现的次数是8000次。由于最高位是2,我们可以再把1346〜21345分成两段：1346〜11345和11346〜21345,每一段剩下的4位数字中，选择其中一位是1，其余三位可以在0〜 9这10个数字中任意选择，因此根据排列组合原则，总共出现的次数是2X 4x10^3=8000 次。<br>
  至于在1〜1345中1出现的次数，我们就可以用递归求得了。这也是 我们为什么要把1〜21345分成1〜1345和1346-21345两段的原因。因为把21345的最高位去掉就变成1345,便于我们采用递归的思路。<br>
  这种思路是每次去掉最高位进行递归，递归的次数和位数相同。一个数字n有O(logn)位，因此这种思路的时间复杂度是O(logn),比前面的原始方法要好很多。</p>
<pre><code>int NumberOf1(unsigned int n);

int NumberOf1Between1AndN_Solution1(unsigned int n)
{
    int number = 0;

    for(unsigned int i = 1; i &lt;= n; ++ i)
        number += NumberOf1(i);

    return number;
}

int NumberOf1(unsigned int n)
{
    int number = 0;
    while(n)
    {
        if(n % 10 == 1)
            number ++;

        n = n / 10;
    }

    return number;
}

// ====================方法二====================
int NumberOf1(const char* strN);
int PowerBase10(unsigned int n);

int NumberOf1Between1AndN_Solution2(int n)
{
    if(n &lt;= 0)
        return 0;

    char strN[50];
    sprintf(strN, &quot;%d&quot;, n);

    return NumberOf1(strN);
}

int NumberOf1(const char* strN)
{
    if(!strN || *strN &lt; '0' || *strN &gt; '9' || *strN == '\0')
        return 0;

    int first = *strN - '0';
    unsigned int length = static_cast&lt;unsigned int&gt;(strlen(strN));

    if(length == 1 &amp;&amp; first == 0)
        return 0;

    if(length == 1 &amp;&amp; first &gt; 0)
        return 1;

    // 假设strN是&quot;21345&quot;
    // numFirstDigit是数字10000-19999的第一个位中1的数目
    int numFirstDigit = 0;
    if(first &gt; 1)
        numFirstDigit = PowerBase10(length - 1);
    else if(first == 1)
        numFirstDigit = atoi(strN + 1) + 1;

    // numOtherDigits是01346-21345除了第一位之外的数位中1的数目
    int numOtherDigits = first * (length - 1) * PowerBase10(length - 2);
    // numRecursive是1-1345中1的数目
    int numRecursive = NumberOf1(strN + 1);

    return numFirstDigit + numOtherDigits + numRecursive;
}

int PowerBase10(unsigned int n)
{
    int result = 1;
    for(unsigned int i = 0; i &lt; n; ++ i)
        result *= 10;

    return result;
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[数组 题42:连续子数组的最大和]]></title>
        <id>https://lixin-scut.github.io//post/shu-zu-ti-42lian-xu-zi-shu-zu-de-zui-da-he</id>
        <link href="https://lixin-scut.github.io//post/shu-zu-ti-42lian-xu-zi-shu-zu-de-zui-da-he">
        </link>
        <updated>2020-03-03T00:31:57.000Z</updated>
        <content type="html"><![CDATA[<p>题目描述</p>
<blockquote>
<p>输入一个整型数组，数组里有正数也有负数。数组中的一个或连续多个整数组成一个子数组。求所有子数组的和的最大值。要求时间复杂度为O(n)<br>
例如:{6,-3,-2,7,-15,1,2,2},连续子向量的最大和为8(从第0个开始,到第3个为止)。</p>
</blockquote>
<p>非常简单，就是如果max小于0的话说明它对当前值已经没有增益了，必须舍弃掉<br>
而大于等于0的话则值得继续加下去<br>
需要注意的点是必须把max和res初始化为INT_MIN，仅仅值初始化或者初始化为0的话如果整个数组都是负数的话会返回错误的结果<br>
然后这个条件判断最后可以转化为动态规划</p>
<pre><code>class Solution {
public:
    int FindGreatestSumOfSubArray(vector&lt;int&gt; array) {
        int max,res;
        max=INT_MIN;
        res=INT_MIN;
        for(auto num:array){
            /*
            if(max&lt;0)
                max=num;
            else
                max+=num;
             */
            max=num&gt;max+num?num:max+num;//动态规划
            res=res&gt;max?res:max;
        }
        return res;
    }
};
</code></pre>
<p>书本题解：</p>
<blockquote>
<p>动态规划法<br>
  如果算法的功底足够扎实，那么我们还可以用动态规划的思想来分析这个问题。如果用函数f(i)表示以第i个数字结尾的子数组的最大和，那么我们需要求出max[f(i)],<br>
  当以第i-1个数字结尾的子数组中所有数字的和小于0时，如果把这个负数与第，个数累加，则得到的结果比第i个数字本身还要小，所以这种情况下以第i个数字结尾的子数组就是第i个数字本身。如果以第i-1个数字结尾的子数组中所有数字的和大于0, 则与第i个数字累加就得到以第i个数字结尾的子数组中所有数字的和。<br>
  注意，虽然通常我们用递归的方式分析动态规划的问题，但最终都会基于循环去编码。<br>
  面试的时候我们要考虑无效的输入，如输入的数组参数为空指针、数 组长度小于等于0等情况。此时我们让函数返回什么数字？如果返回0,那我们又怎么区分子数组的和的最大值是0和无效输入这两种不同情况呢？ 因此，我们定义了一个全局变量来标记是否输入无效。</p>
</blockquote>
<pre><code>bool g_InvalidInput = false;

int FindGreatestSumOfSubArray(int *pData, int nLength)
{
    if((pData == nullptr) || (nLength &lt;= 0))
    {
        g_InvalidInput = true;
        return 0;
    }

    g_InvalidInput = false;

    int nCurSum = 0;
    int nGreatestSum = 0x80000000;
    for(int i = 0; i &lt; nLength; ++i)
    {
        if(nCurSum &lt;= 0)
            nCurSum = pData[i];
        else
            nCurSum += pData[i];

        if(nCurSum &gt; nGreatestSum)
            nGreatestSum = nCurSum;
    }

    return nGreatestSum;
} 
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[数组 题41:数据流的中位数]]></title>
        <id>https://lixin-scut.github.io//post/shu-zu-ti-41shu-ju-liu-de-zhong-wei-shu</id>
        <link href="https://lixin-scut.github.io//post/shu-zu-ti-41shu-ju-liu-de-zhong-wei-shu">
        </link>
        <updated>2020-03-03T00:12:48.000Z</updated>
        <content type="html"><![CDATA[<p>题目描述</p>
<blockquote>
<p>如何得到一个数据流中的中位数？如果从数据流中读出奇数个数值，那么中位数就是所有数值排序之后位于中间的数值。如果从数据流中读出偶数个数值，那么中位数就是所有数值排序之后中间两个数的平均值。我们使用Insert()方法读取数据流，使用GetMedian()方法获取当前读取数据的中位数。</p>
</blockquote>
<p>  这道题没啥好说的，其实是左大顶堆和右小顶堆的配合<br>
  主要就是要控制好两个堆的数量之差，相差不能超过1，并且必须有一个得是保存中心点的<br>
  然后就是注意每次插入都要手动更新min，不能指望客户每次插入都查询min，否则就会导致多次插入出现问题</p>
<p>  最坑的点就是！！！size()返回的是无符号数！！！一定要防止size()相减得到负数或者size()和负数比较！！！<br>
  否则无符号数和有符号数一起运算时，有符号数强行转化为无符号数，接着负数会强行转化为一个很大的正数，导致判断一直通过或者一直不通过</p>
<pre><code>class Solution {
public:
    void Insert(int num)
    {
        if(left_max.size()==0&amp;&amp;right_min.size()==0){
            left_max.push(num);
            mid=GetMedian();
            return;
        }
                
        if((double)num&lt;=mid)
            left_max.push(num);
        else
            right_min.push(num);
        if(left_max.size()&gt;right_min.size()+1){
            right_min.push(left_max.top());
            left_max.pop();
        }
        if(right_min.size()&gt;left_max.size()){
            left_max.push(right_min.top());
            right_min.pop();
        }
        mid=GetMedian();
    }

    double GetMedian()
    { 
        if(left_max.size()==0&amp;&amp;right_min.size()==0)
            return 0.0;
        if(left_max.size()==right_min.size())
            mid=static_cast&lt;double&gt;(left_max.top()+right_min.top())/2;
        else 
            mid=static_cast&lt;double&gt;(left_max.top());
        return mid;
    }

private:
    priority_queue&lt;int&gt; left_max;
    priority_queue&lt;int,vector&lt;int&gt;,greater&lt;int&gt;&gt; right_min;
    double mid;
};
</code></pre>
<p>书本题解<br>
<img src="https://lixin-scut.github.io//post-images/1583195223562.png" alt=""><br>
<img src="https://lixin-scut.github.io//post-images/1583195244385.png" alt=""></p>
<blockquote>
<p>  我们注意到整个数据容器被分隔成两部分。位于容器左边部分的数据比右边的数据小。另外，P1指向的数据是左边部分最大的数，P2指向的数据是左边部分最小的数。<br>
  如果能够保证数据容器左边的数据都小于右边的数据，那么即使左、 右两边内部的数据没有排序，也可以根据左边最大的数及右边最小的数得 到中位数。如何快速从一个数据容器中找出最大数？用最大堆实现这个数据容器，因为位于堆顶的就是最大的数据。同样，也可以快速从最小堆中找出最小数。<br>
  因此，可以用如下思路来解决这个问题：用一个最大堆实现左边的数据容器，用一个最小堆实现右边的数据容器。往堆中插入一个数据的时间 效率是O(logn)。由于只需要O(1)时间就可以得到位于堆顶的数据，因此得 到中位数的时间复杂度是O(1)。</p>
</blockquote>
<pre><code>template&lt;typename T&gt; class DynamicArray
{
public:
    void Insert(T num)
    {
        if(((min.size() + max.size()) &amp; 1) == 0)
        {
            if(max.size() &gt; 0 &amp;&amp; num &lt; max[0])
            {
                max.push_back(num);
                push_heap(max.begin(), max.end(), less&lt;T&gt;());

                num = max[0];

                pop_heap(max.begin(), max.end(), less&lt;T&gt;());
                max.pop_back();
            }

            min.push_back(num);
            push_heap(min.begin(), min.end(), greater&lt;T&gt;());
        }
        else
        {
            if(min.size() &gt; 0 &amp;&amp; min[0] &lt; num)
            {
                min.push_back(num);
                push_heap(min.begin(), min.end(), greater&lt;T&gt;());

                num = min[0];

                pop_heap(min.begin(), min.end(), greater&lt;T&gt;());
                min.pop_back();
            }

            max.push_back(num);
            push_heap(max.begin(), max.end(), less&lt;T&gt;());
        }
    }

    T GetMedian()
    {
        int size = min.size() + max.size();
        if(size == 0)
            throw exception(&quot;No numbers are available&quot;);

        T median = 0;
        if((size &amp; 1) == 1)
            median = min[0];
        else
            median = (min[0] + max[0]) / 2;

        return median;
    }

private:
    vector&lt;T&gt; min;
    vector&lt;T&gt; max;
};
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[归并排序]]></title>
        <id>https://lixin-scut.github.io//post/gui-bing-pai-xu</id>
        <link href="https://lixin-scut.github.io//post/gui-bing-pai-xu">
        </link>
        <updated>2020-03-02T18:21:50.000Z</updated>
        <content type="html"><![CDATA[<p><a href="https://lixin-scut.github.io/post/pai-xu-suan-fa/">排序算法及其实现</a></p>
<p>  归并排序(Merging Sort)就是利用归并的思想实现的排序方法。它的原理是假设初始序列含有n个记录，则可以看成是n个有序的子序列，每个子序列的长度为1,然后两两归并，得到「n/2」(「x」表示不小于x的最小整数)个长度为2或1的有序子序列;再两两归并，......，<br>
  如此重复，直至得到一个长度为n的有序序列为止，这种排序方法称为2路归并排序。</p>
<pre><code>class MergingSort
{
public:
    void MergingSort0(vector&lt;int&gt; &amp;numbers);

private:
    void Divide(vector&lt;int&gt; &amp;numbers, int beg, int end);
    void Merge(vector&lt;int&gt; &amp;numbers, int beg, int mid, int end);
};

void MergingSort::MergingSort0(vector&lt;int&gt; &amp;numbers)
{
    Divide(numbers, 0, numbers.size()-1);
    print(numbers);
}

void MergingSort::Divide(vector&lt;int&gt; &amp;numbers,
                         int beg,
                         int end)
{
    if(beg == end)
        return;
    int mid = beg + (end - beg) / 2;
    Divide(numbers, beg, mid);
    Divide(numbers, mid+1,end);
    Merge(numbers, beg, mid+1, end);
}

void MergingSort::Merge(vector&lt;int&gt; &amp;numbers,
                        int beg,
                        int mid,
                        int end)
{
    vector&lt;int&gt; temp;
    temp.reserve(end - beg + 1);
    int loc = 0;
    int left = beg;
    int right = mid;
    while(left &lt; mid &amp;&amp; right &lt;= end)
    {
        if(numbers[left] &lt;= numbers[right])
        {
            temp[loc] = numbers[left];
            ++left;
        }
        else
        {
            temp[loc] = numbers[right];
            ++right;
        }
        ++loc;
    }

    int remain = left &lt; mid ? left : right;
    while(loc &lt; end - beg + 1)
    {
        temp[loc] = numbers[remain];
        ++loc;
        ++remain;
    }

    loc = 0;
    while(loc &lt; end - beg + 1)
    {
        numbers[loc + beg] = temp[loc];
        ++loc;
    }
}
</code></pre>
<p>归并排序是第一个需要额外空间的排序方法，因为把两个数组合为一个数组时除非不断地往后挪， 不然最好使用额外的数组保存排序结果。<br>
（我实现过程中犯的一个错误就是直接在原数组swap，这样会破坏有序性）</p>
<h3 id="复杂度分析">复杂度分析</h3>
<p>我们来分析一下归并排序的时间复杂度，一趟归并需要将相邻的有序序列进行两两归并。这需要将待排序序列中的所有记录扫描一遍，因此耗费O(n)时间，而由完全二叉树的深度可知，整个归并排序需要进行ceil(logn)次，因此，总的时间复杂度为O(nlogn)，而且这是归并排序算法中最好、最坏、平均的时间性能。<br>
由于归并排序在归并过程中需要与原始记录序列同样数墩的存储空间存放归并结果以 及递归时深度为logn的栈空间，因此空间复杂度为0(n+bgn)。<br>
另外，Merge函数中需要两两比较，不存在跳跃，因此归并排序是一种稳定的排序算法。<br>
也就是说，归并排序是一种比较占用内存，但却效率高且稳定的算法</p>
<h3 id="非递归实现">非递归实现</h3>
<p>因为需要递归到长度为1的子数组，所以递归的归并排序会耗费很多栈空间<br>
所以来看一下迭代的实现</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[堆排序]]></title>
        <id>https://lixin-scut.github.io//post/dui-pai-xu</id>
        <link href="https://lixin-scut.github.io//post/dui-pai-xu">
        </link>
        <updated>2020-03-02T17:36:14.000Z</updated>
        <content type="html"><![CDATA[<p><a href="https://lixin-scut.github.io/post/pai-xu-suan-fa/">排序算法及其实现</a></p>
<p>  其实以前我已经写过一次堆排序了（<a href="https://lixin-scut.github.io/post/dui-pai-xu-shi-xian/">堆排序实现</a>），这次就当作是复习和优化了</p>
<p>  堆排序（Heap Sort)就是利用堆（假设利用大顶堆）进行排序的方法。它的基本思想是， 将待排序的序列构造成一个大顶堆。此时，整个序列的最大值就是堆顶的根结点。将它移走 （其实就是将其与堆数组的末尾元素交换，此时末尾元素就是最大值），然后将剩余的n-1个序列重新构造成一个堆，这样就会得到n个元素中的次小值。如此反复执行，便能得到一个有序序列了。</p>
<pre><code>class HeapSort
{
public:
    void HeapSort0(vector&lt;int&gt; &amp;numbers);

private:
    void HeapAdjust(int loc,vector&lt;int&gt; &amp;numbers, int end);
};

void HeapSort::HeapSort0(vector&lt;int&gt; &amp;numbers)
{
    int len = numbers.size();

    // build a heap first;
    for(int loc = len/2; loc &gt;= 0; --loc)
    {
        HeapAdjust(loc,numbers,len-1);
    }

    for(int loc = len-1; loc &gt; 0; --loc)
    {
        swap(numbers[loc],numbers[0]);
        HeapAdjust(0, numbers, loc-1);
    }
    print(numbers);
}


void HeapSort::HeapAdjust(int loc,
                          vector&lt;int&gt; &amp;numbers,
                          int end)
{
    int temp;
    int j;
    temp = numbers[loc];
    for(j = loc*2+1; j&lt;=end; j = j*2+1)
    {
        if(j&lt;end &amp;&amp; numbers[j] &lt; numbers[j+1])
        { ++j; }

        if(temp&gt;numbers[j])
        { break; }

        numbers[(j-1)/2] = numbers[j];
    }
    numbers[(j-1)/2] = temp;
}
</code></pre>
<p>  在实现的过程中有个问题就是下标问题，堆排序原来的性质是按下标1开始算的（例如当前节点的父节点下标为floor(loc/2)），但是C++的容器下标从0开始，所以就需要相应地+1或者-1。</p>
<p>  整个排序过程分为两个for循环。第一个循环要完成的就是将现在的待排序序列构建成一个大顶堆。第二个循环要完成的就是逐步将每个最大值的根结点与末尾元素交换，并且再调整其成为大顶堆。<br>
  所以注意！！！第一个循环后并非是有序顺序，大顶堆和二叉树不同，并非左子树的节点都小于右子树</p>
<p>  循环从(length-1)/2开始是因为从1到(length-1)/2都是有孩子的节点<br>
  我们所谓的将待排序的序列构建成为一个大顶堆，其实就是从下往上、从右到左，将每个非终端结点（非叶结点）当作根结点，将其和其子树调整成大顶堆</p>
<h3 id="堆排序复杂度分析">堆排序复杂度分析</h3>
<p>  运行时间主要是消耗在初始构建堆和在重建堆时的反复筛选上。<br>
  在构建堆的过程中，因为我们是完全二叉树从最下层最右边的非终端结点开始构 建，将它与其孩子进行比较和若有必要的互换，对于每个非终端结点来说，其实最多进行两次比较和互换操作，因此整个构建堆的时间复杂度为o(n)。<br>
  在正式排序时，第i次取堆顶记录重建堆需要用O(logi)的时间（完全二叉树的某个结点到根结点的距离为floor(logi)+1,并且需要取n-1次堆顶记录，因此，重建堆的时间复杂度为〇(nlogn)<br>
  所以总体来说，堆排序的时间复杂度为〇(nlogn)。由于堆排序对原始记录的排序状态并不敏感，因此它无论是最好、最坏和平均时间复杂度均为〇(nlogn)。<br>
  空间复杂度上，它只有一个用来交换的暂存单元，也非常的不错。<br>
  不过由于记录的比较与交换是跳跃式进行，因此堆排序也是一种<strong>不稳定的排序</strong>方法。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[多线程日志]]></title>
        <id>https://lixin-scut.github.io//post/duo-xian-cheng-ri-zhi</id>
        <link href="https://lixin-scut.github.io//post/duo-xian-cheng-ri-zhi">
        </link>
        <updated>2020-03-02T13:25:18.000Z</updated>
        <content type="html"><![CDATA[<p>故障诊断和追踪<br>
日志库是单例模式<br>
muduo日志库是C++ stream风格，但没用iostream，而是自己写了logstream class<br>
日志需要有设置级别的功能<br>
日志的目的地只有本地，不要往网络传日志<br>
日志应该有rolling功能，主要由文件大小和时间来区分<br>
日志文件名：进程名+时间+机器名+进程id+后缀.log<br>
防止程序崩溃1.定期flush 2.在内存中的日志消息都有cookie，值为某个函数地址<br>
日志消息格式是固定的，不需要通过运行时配置<br>
要点 1.每条日志只占1行 2.时间戳精确到微妙 gettimeofday 3.保证同一时区 4.打印线程id 5.打印日志级别 6.打印源文件名和行号<br>
每行日志的前四个字段的宽度是固定的 以空格分隔 便于分析，避免出现正则表达式的元字符<br>
优化：<br>
1.日期和时间都是缓存的<br>
2.前四个字段是定长的，避免运行时求长度<br>
3.线程id预先格式化为字符串 4.源文件名部分采用编译器计算<br>
多线程异步日志：使用一个背景线程来收集日志信息，其他业务线程往这个线程发送日志消息<br>
双缓冲技术 使用两个buffer 分为前段接收和后端写入<br>
实际上有四个缓冲区</p>
<p>日志通常用于故障诊断 和追踪(trace) ,也可用于性能分析。</p>
<p>日志通常要记录</p>
<ol>
<li>收到的每条内部消息的id (还可以包括关键字段、长度、hash等);</li>
<li>收到的每条外部消息的全文；</li>
<li>发出的每条消息的全文，每条消息都有全局唯一的id；</li>
<li>关键内部状态的变更。</li>
</ol>
<p>每条日志都有时间戳</p>
<p>一个日志库大体可分为前端(frontend)和后端(backend)两部分。前端是供应用程序使用的接口(API),并生成日志消息(log message)；后端则负责把日志 消息写到目的地(destination)。这两部分的接口有可能简单到只有一个回调函数：<br>
void output(const char* message, int len);<br>
其中的message字符串是一条完整的日志消息，包含日志级别、时间戳、源文件位 置、线程id等基本字段，以及程序输出的具体消息内容。<br>
在多线程程序中，前端和后端都与单线程程序无甚区别，无非是每个线程有自己 的前端，整个程序共用一个后端。但难点在于将日志数据从多个前端高效地传输到后 端尢这是一个典型的多生产者-单消费者问题，对生产者(前端)而言，要尽量做 到低延迟、低CPU开销、无阻塞；对消费者(后端)而言，要做到足够大的吞吐量, 并占用较少资源。</p>
<p>常规的通用日志库如log4j 13/logback 14通常会提供丰富的功能，但这些功能不 一定全都是必需的C</p>
<ol>
<li>日志消息有多种级别（level ）,如 TRACE. DEBUG、INFO、WARN、ERROR. FATAL 等。</li>
<li>日志消息可能有多个目的地（appender ）,如文件、socket、SMTP等。</li>
<li>日志消息的格式可配置（layout）,例如 org. apache. Iog4 j . PatternLayouto</li>
<li>可以设置运行时过滤器（filter）,控制不同组件的日志消息的级别和目的地。<br>
在上面这几项中，除了第一项之外，其余三项都是非必需的功能。<br>
日志的输出级别在运行时可调，这样同一个可执行文件可以分别在QA测试环境 的时候输出DEBUG级别的日志，在生产环境输出INFO级别的日志15。在必要的时候也 可以临时在线调整日志的输出级别。例如某台机器的消息量过大、日志文件太多、磁 盘空间紧张，那么可以临时调整为WARNING级别输出，减少日志数目。又比如某个新 上线的进程的行为略显古怪，则可以临时调整为DEBUG级别输出，打印更细节的日志 消息以便分析查错。调整日志的输出级别不需要重新编译，也不需要重启进程，只要 调用 muduo::Logger::setLogLevel（）就能即时生效。<br>
对于分布式系统中的服务进程而言，日志的目的地（destination ）只有一个：本 地文件。往网络写日志消息是不靠谱的，因为诊断日志的功能之一正是诊断网络故 障，往网络写日志消 息的另一个坏处是增加网络带宽消耗。同理应 该避免往网络文件系统（例如NFS）上写日志，<br>
以本地文件为日志的destination,那么日志文件的滚动（rolling ）是必需的，这 样可以简化日志归档（archive）的实现。rolling的条件通常有两个：文件大小（例 如每写满1GB就换下一个文件）和时间（例如每天零点新建一个日志文件，不论前 一个文件有没有写满）。muduo日志库的LogFile会自动根据文件大小和时间来主动 滚动日志文件。既然能主动rolling, fl然也就不必支持SIGUSR1 了，毕竟多线程程序 处理signal很麻烦<br>
一个典型的日志文件的文件名如下：<br>
logfile_test.2012060-144022.hostname.3605.log<br>
文件名由以下几部分组成：<br>
•第1部分logfile.test是进程的名字。通常是main（）函数参数中argv[0]的 basename（3）,这样容易区分究竟是哪个服务程序的日志。必要时还可以把程序 版本加进去。<br>
•第2部分是文件的创建时间（GMT时区）。这样很容易通过文件名来选择某一 时间范围内的日志，例如用通配符*.20120603-14<em>表示2012年6月3日下午2 点（GMT ）左右的日志文件（s）o<br>
•第3部分是机器名称。这样即便把日志文件拷贝到别的机器上也能追溯其来源。<br>
•第4部分是进程id。如果一个程序一秒之内反复重启，那么每次都会生成不同 的日志文件，参考§9.4。<br>
•第5部分是统一的后缀名.logo同样是为了便于周边配套脚本的编写。<br>
muduo的日志文件滚动没有采用文件改名的办法，即dmesg.log是最新日志, dmesg.log.l是前一个口志，dmesg.Log.2.gz是更早的口志等。这种做法的一个好处是 dmesglog始终是最新日志，便于编写某些及时解析日志的脚本。将来可以增加一个功 能，每次滚动日志文件之后立刻创建（更新）一个symlink, logMe.test.log始终指向当 前最新的日志文件，这样达到相同的效果。<br>
往文件写日志的一个常见问题是，万一程序崩溃，那么最后若干条日志往往就 丢失了，因为日志库不能每条消息都flush硬盘，更不能每条日志都open/close文 件，这样性能开销太大。muduo日志库用两个办法来应对这一点，其一是定期（默 认3秒）将缓冲区内的日志消息flush到硬盘；其二是每条内存中的日志消息都带有 cookie （或者叫哨兵值/sentry ）,其值为某个函数的地址，这样通过在core dump文 件中查找cookie 就能找到尚未来得及写入磁盘的消息。<br>
日志消息的格式是固定的，不需要运行时配置，这样可节省每条日志解析格式字 符串的开销。我认为日志的格式在项目的整个生命周期几乎不会改变，因为我们经常 会为不同目的编写parse H志的脚本，既要解析最近几天的日志文件，也要和几个月 之前，甚至一年之前的日志文件的同类数据做对比。如果在此期间日志格式变了，势 必会增加很多无谓的工作量。如果真的需要调整消息格式，直接修改代码并重新编译<br>
日志消息格式有几个要点:<br>
•尽量每条日志占一行。这样很容易用awk、sed、grep等命令行工具来快速联机 分析日志，比方说要查看&quot;2012-06-03 08:02:00° 至&quot;2012-06-03 08:02:59&quot;这 1 分钟内每秒打印日志的条数（直方图），可以运行 $ grep -o ，A20120603 08:02:..1 | sort | uniq -c<br>
•时间戳精确到微秒。每条消息都通过gettimeofday（2）获得当前时间，这么做 不会有什么性能损失。因为在x86-64 Linux ±, gettimeofday（2）不是系统调 用，不会陷入内核<br>
•始终使用GMT时区（Z）。对于跨洲的分布式系统而言，可省去本地时区转换 的麻烦（别忘了主要西方国家大多实行夏令时），更易于追杳事件的顺序。<br>
•打印线程id。便于分析多线程程序的时序，也可以检测死锁I</em>这里的线程id 是指调用LOG_INFO «的线程，线程id的获取见§4.3 o<br>
•打印日志级别。在线查错的时候先看看有无ERROR日志，通常可加速定位问题。<br>
•打印源文件名和行号。修复bug的时候不至于搞错对象。<br>
每行日志的前4个字段的宽度是固定的，以空格分隔，便于用脚本解析。另 外，应该避免在日志格式（特别是消息id 20）中出现正则表达式的元字符（meta character）,例如’［，和）等等，这样在用less（l）查看日志文件的时候查找字符 串更加便捷。</li>
</ol>
<p>性能需求<br>
编写Linux服务端程序的时候，我们需要一个高效的日志库。只有日志库足够高 效，程序员才敢在代码中输出足够多的诊断信息，减小运维难度，提升效率。高效性 体现在几方面：<br>
•每秒写儿千上万条日志的时候没有明显的性能损失。<br>
•能应对一个进程产生大量日志数据的场景，例如IGB/mino<br>
•不阻塞正常的执行流程。<br>
•在多线程程序中，不造成争用（contention ）</p>
<p>为了实现这样的性能指标，muduo日志库的实现有几点优化措施值得一提：<br>
•时间戳字符串中的日期和时间两部分是缓存的，一秒之内的多条日志只需重新 格式化微秒部分雹。例如p. Ill出现的3条日志消息中，“20120603 08:02:46” 是复用的，每条日志只需要格式化微秒部分(“.125770Z”)。<br>
•日志消息的前4个字段是定长的，因此可以避免在运行期求字符串长度(不会 反复调用strlen      )o因为编译器认识memcpy()函数，对于定长的内存复制, 会在编译期把它inline展开为高效的目标代码。<br>
•线程id是预先格式化为字符串，在输出日志消息时只需简单拷贝几个字节。见 CurrentThread::tidString()o<br>
•每行日志消息的源文件名部分采用了编译期计算来获得basename,避免运行 期strrchr(3)开销。见SourceFile class,这里利用了 gcc的内置函数。</p>
<p>多线程异步日志<br>
多线程程序对日志库提出了新的需求：线程安全，即多个线程可以并发写日志, 两个线程的日志消息不会出现交织。线程安全不难办到，简单的办法是用一个全局 mutex保护IO,或者每个线程单独写一个日志文件”，但这两种做法的高效性就堪 忧了。前者会造成全部线程抢一个锁，后者有可能让业务线程阻塞在写磁盘操作上。<br>
解决办法不难想到，用一个背景线程负责收集日志消息，并写入日志文件, 其他业务线程只管往这个“日志线程”发送日志消息，这称为“异步日志”。<br>
在多线程服务程序中，异步日志（叫“非阻塞日志”似乎更准确）是必需的，因 为如果在网络IO线程或业务线程中直接往磁盘写数据的话，写操作偶尔口J能阻塞长 达数秒之久</p>
<p>我们需要一个“队列”来将日志前端的数据传送到后端（日志线程），但这个 “队列”不必是现成的BlockingQueue<a href="std::string">std::string</a>,因为不用每次产生一条日志消 息都通知（notify（））接收方。<br>
muduo日志库采用的是双缓冲（double buffering ）技术吃 基本思路是准备两 块buffer： A和B,前端负责往buffer A填数据（日志消息）,后端负责将buffer B 的数据写入文件。当buffer A写满之后，交换A和B,让后端将buffer A的数据写 入文件，而前端则往buffer B填入新的日志消息，如此往复。用两个buffer的好处是 在新建日志消息的时候不必等待磁盘文件操作，也避免每条新日志消息都触发（唤 醒）后端日志线程。换言之，前端不是将一条条日志消息分别传送给后端，而是将多 条日志消息拼成一个大的buffer传送给后端，相当于批处理，减少了线程唤醒的频 度，降低开销。另外，为了及时将日志消息写入文件，即便buffer A未满，日志库也 会每3秒执行一次上述交换写入操作。</p>
<p>关键代码<br>
实际实现采用了四个缓冲区，这样可以进一步减少或避免日志前端的等待。数据 结构如下(muduo/base/AsyncLogging.h )：<br>
typedef boost::ptr_vector<LargeBuffer><br>
typedef BufferVector::auto^type</p>
<p>其中，LargeBuffer 类型是 FixedBuffer class template 的一份具体实现(instantiation ),其大小为4MB,可以存至少1000条日志消息o boost::ptr_vector<T>::auto_type 类型类似C++11中的std: :unique_ptr,具备移动语义(move semantics ),而且能自 动管理对象生命期。mutex.用于保护后面的四个数据成员。buffers.存放的是供后端 写入的buffero</p>
<p>前端在生成一条日志消息的时候会调用AsyncLogging::append()o在这个函数中, 如果当前缓冲(currentBuffer,)剩余的空间足够大(£31),则会直接把日志消息拷贝(追加)到当前缓冲中(C33),这是最常见的情况。这里拷贝一条日志消息并不会 带来多大开销(p.120)。前后端代码的其余部分都没有拷贝，而是简单的指针交换。</p>
<p>否则，说明当前缓冲已经写满，就把它送入(移入)buffers一(£37),并试图把 预备好的另一块缓冲(nextBuffer_ )移用(move )为当前缓冲(£39~£42 ),然后追加 日志消息并通知(唤醒)后端开始写入日志数据(£47〜£48 )。以上两种情况在临界区 之内都没有耗时的操作，运行时间为常数。<br>
如果前端写入速度太快，一下子把两块缓冲都用完了，那么只好分配一块新的 buffer,作为当前缓冲(£43~£46),这是极少发生的情况。</p>
<p>首先准备好两块空闲的buffer,以备在临界区内交换(C53、£54 )o在临界区内， 等待条件触发(£61〜£64),这里的条件有两个：其一是超时，其二是前端写满了一 个或多个buffero注意这里是非常规的condition variable用法，它没有使用while循 环，而且等待时间有上限。</p>
<pre><code>一开始先分配好四个缓冲区A、 B、C、D,前端和后端各持有其中两个。前端和后端各有一个缓冲区数组，初始时都 是空的。

万一前端陷入死循环，拼命发送日志消息，超过后端的处理（输出）能力，会导 致什么后果？对于同步日志来说，这不是问题，因为阻塞IO自然就限制了前端的写 入速度，起到了节流阀（throttling）的作用。但是对于异步日志来说，这就是典型的 生产速度高于消费速度问题，会造成数据在内存中堆积，严重时引发性能问题（可用 内存不足）或程序崩溃（分配内存失败）o
</code></pre>
<p>muduo H志库处理日志堆积的方法很简单：直接丢掉多余的日志buffer,以腾 出内存，见muduo/base/AsyncLogging.cc第87~96行代码。这样可以防止日志库本身引起 程序故障，是一种自我保护措施。将来或许可以加上网络报警功能，通知人工介入, 以尽快修复故障。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[线程池与内存池]]></title>
        <id>https://lixin-scut.github.io//post/xian-cheng-chi-yu-nei-cun-chi</id>
        <link href="https://lixin-scut.github.io//post/xian-cheng-chi-yu-nei-cun-chi">
        </link>
        <updated>2020-03-02T09:36:43.000Z</updated>
        <content type="html"><![CDATA[<ol>
<li>为什么需要线程池<br>
大多数的网络服务器，包括Web服务器都具有一个特点，就是单位时间内必须处理数目巨大的连接请求，但是处理时间却是比较短的。在传统的多线程服务器模型中是这样实现的：一旦有个请求到达，就创建一个新的线程，由该线程执行任务，任务执行完毕之后，线程就退出。这就是”即时创建，即时销毁”的策略。尽管与创建进程相比，创建线程的时间已经大大的缩短，但是如果提交给线程的任务是执行时间较短，而且执行次数非常频繁，那么服务器就将处于一个不停的创建线程和销毁线程的状态。这笔开销是不可忽略的，尤其是线程执行的时间非常非常短的情况。</li>
<li>线程池原理<br>
在应用程序启动之后，就马上创建一定数量的线程，放入空闲的队列中。这些线程都是处于阻塞状态，这些线程只占一点内存，不占用CPU。当任务到来后，线程池将选择一个空闲的线程，将任务传入此线程中运行。当所有的线程都处在处理任务的时候，线程池将自动创建一定的数量的新线程，用于处理更多的任务。执行任务完成之后线程并不退出，而是继续在线程池中等待下一次任务。当大部分线程处于阻塞状态时，线程池将自动销毁一部分的线程，回收系统资源。</li>
<li>线程池的作用<br>
需要大量的线程来完成任务，且完成任务的时间比较短；对性能要求苛刻的应用；对性能要求苛刻的应用</li>
<li>内存池的原理<br>
在软件开发中，有些对象使用非常频繁，那么我们可以预先在堆中实例化一些对象，我们把维护这些对象的结构叫“内存池”。在需要用的时候，直接从内存池中拿，而不用从新实例化，在要销毁的时候，不是直接free/delete，而是返还给内存池。把那些常用的对象存在内存池中，就不用频繁的分配/回收内存，可以相对减少内存碎片，更重要的是实例化这样的对象更快，回收也更快。当内存池中的对象不够用的时候就扩容。</li>
<li>内存池的优缺点<br>
内存池对象不是线程安全的，在多线程编程中，创建一个对象时必须加锁。</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[select、poll和epoll]]></title>
        <id>https://lixin-scut.github.io//post/selectpoll-he-epoll</id>
        <link href="https://lixin-scut.github.io//post/selectpoll-he-epoll">
        </link>
        <updated>2020-03-02T09:01:31.000Z</updated>
        <content type="html"><![CDATA[<h3 id="非阻塞io">非阻塞I/O</h3>
<p>阻塞和非阻塞最大的区别在于调用I/O系统调用后，是等整个I/O过程完成再把操作权限返回给用户还是会立即返回。</p>
<p>可以使用以下语句将句柄fd设置为非阻塞I/O：fcntl(fd, F_SETFL, O_NONBLOCK);</p>
<p>非阻塞I/O在调用后会立即返回，用户进程对返回的返回值判断以区分是否完成了I/O。如果返回大于0表示完成了数据读取，返回值即读取的字节数；返回0表示连接已经正常断开；返回-1表示错误，接下来用户进程会不停地询问kernel是否准备完毕。<br>
非阻塞I/O虽然不再会完全阻塞用户进程，但实际上由于用户进程需要不停地询问kernel是否准备完数据，所以整体效率依旧非常低，不适合做并发。</p>
<h3 id="io复用">I/O复用</h3>
<p>I/O复用模型会用到select、poll、epoll函数，这几个函数也会使进程阻塞，但是和阻塞I/O所不同的的，这三个函数可以同时阻塞多个I/O操作。而且可以同时对多个读操作，多个写操作的I/O函数进行检测，直到有数据可读或可写时，才真正调用I/O操作函数。</p>
<ol>
<li>IO复用是Linux中的IO模型之一，IO复用就是进程预先告诉内核需要监视的IO条件，使得内核一旦发现进程指定的一个或多个IO条件就绪，就通过进程进程处理，从而不会在单个IO上阻塞了。Linux中，提供了select、poll、epoll三种接口函数来实现IO复用。</li>
<li>Select<br>
select的缺点：<br>
①	单个进程能够监视的文件描述符的数量存在最大限制，通常是1024。由于select采用轮询的方式扫描文件描述符，文件描述符数量越多，性能越差；<br>
②	内核/用户空间内存拷贝问题，select需要大量句柄数据结构，产生巨大开销；<br>
③	Select返回的是含有整个句柄的数组，应用程序需要遍历整个数组才能发现哪些句柄发生事件；<br>
④	Select的触发方式是水平触发，应用程序如果没有完成对一个已经就绪的文件描述符进行IO操作，那么每次select调用还会将这些文件描述符通知进程。</li>
<li>Poll<br>
与select相比，poll使用链表保存文件描述符，没有了监视文件数量的限制，但其他三个缺点依然存在</li>
<li>Epoll<br>
上面所说的select缺点在epoll上不复存在，epoll使用一个文件描述符管理多个描述符，将用户关系的文件描述符的事件存放到内核的一个事件表中，这样在用户空间和内核空间的copy只需一次。Epoll是事件触发的，不是轮询查询的。没有最大的并发连接限制，内存拷贝，利用mmap()文件映射内存加速与内核空间的消息传递。</li>
</ol>
<h3 id="区别总结">区别总结</h3>
<ol>
<li>支持一个进程所能打开的最大连接数<br>
①	Select最大1024个连接，最大连接数有FD_SETSIZE宏定义，其大小是32位整数表示，可以改变宏定义进行修改，可以重新编译内核，性能可能会影响；<br>
②	Poll没有最大连接限制，原因是它是基于链表来存储的；<br>
③	连接数限数有上限，但是很大；</li>
<li>FD剧增后带来的IO效率问题<br>
①	因为每次进行线性遍历，所以随着FD的增加会造成遍历速度下降，效率降低；<br>
②	Poll同上；<br>
③	因为epoll内核中实现是根据每个fd上的callback函数来实现的，只有活跃的socket才会主动调用callback，所以在活跃socket较少的情况下，使用epoll没有前面两者的现象下降的性能问题。</li>
<li>消息传递方式<br>
①	Select内核需要将消息传递到用户空间，都需要内核拷贝；<br>
②	Poll同上；<br>
③	Epoll通过内核和用户空间共享来实现的。</li>
</ol>
<h3 id="epoll-的-lt-和-et-模式">epoll 的 LT 和 ET 模式</h3>
<p>epoll对文件描述符的操作有两种模式：LT(level trigger)和ET(edge trigger)，LT是默认模式。<br>
区别：<br>
LT模式：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序可以不立即处理该事件。下次调用epoll_wait时，会再次响应应用程序并通知此事件。<br>
ET模式：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序必须立即处理该事件。如果不处理，下次调用epoll_wait时，不会再次响应应用程序并通知此事件。</p>
<h3 id="补充资料">补充资料</h3>
<p>I/O多路复用（事件驱动模型）<br>
前面已经论述了多进程、多进程模型会因为开销巨大和调度困难而导致并不能承受高并发量。但不适用这种模型的话，无论是阻塞还是非阻塞方式都会导致整个服务器停滞。<br>
所以对于大并发量，我们需要一种代理模型可以帮助我们集中去管理所有的socket连接，一旦某个socket数据到达了就执行其对应的用户进程，I/O多路复用就是这么一种模型。Linux下I/O多路复用的系统调用有select，poll和epoll，但从本质上来讲他们都是同步I/O范畴。</p>
<p><strong>select</strong><br>
相关接口：</p>
<pre><code>int select (int maxfd, fd_set *readfds, fd_set *writefds, fd_set *errorfds, struct timeval *timeout);
FD_ZERO(int fd, fd_set* fds) //清空集合
FD_SET(int fd, fd_set* fds) //将给定的描述符加入集合
FD_ISSET(int fd, fd_set* fds) //将给定的描述符从文件中删除
FD_CLR(int fd, fd_set* fds) //判断指定描述符是否在集合中
</code></pre>
<p>参数：<br>
maxfd：当前最大文件描述符的值+1（≠ MAX_CONN）。<br>
readfds：指向读文件队列集合（fd_set）的指针。<br>
writefds：同上，指向读集合的指针。<br>
writefds：同上，指向错误集合的指针。<br>
timeout：指向timeval结构指针，用于设置超时。<br>
其他：<br>
判断和操作对象为set_fd集合，集合大小为单个进程可打开的最大文件数1024或2048（可重新编译内核修改但不建议）。</p>
<p><strong>poll</strong><br>
相关接口：<code>int poll(struct pollfd *fds, unsigned int nfds, int timeout);</code><br>
结构体定义： s</p>
<pre><code>truct pollfd{ int fd; // 文件描述符 
short events; // 等到的事件 
short revents; // 实际发生的事件 
</code></pre>
<p>参数：<br>
fds：指向pollfd结构体数组的指针。<br>
nfds：pollfd数组当前已被使用的最大下标。<br>
timeout：等待毫秒数。<br>
其他：<br>
判断和操作对象是元素为pollfd类型的数组，数组大小自己设定，即为最大连接数。</p>
<p><strong>epoll</strong><br>
相关接口：</p>
<pre><code>int epoll_create(int size); // 创建epoll句柄 
int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event); // 事件注册函数 
int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);
</code></pre>
<p>结构体定义：<br>
<code>struct epoll_event { __uint32_t events; epoll_data_t data; }; typedef union epoll_data { void *ptr; int fd; __uint32_t u32; __uint64_t u64; }epoll_data_t;</code><br>
参数：<br>
size：用来告诉内核要监听的数目。<br>
epfd：epoll函数的返回值。<br>
op：表示动作（EPOLL_CTL_ADD/EPOLL_CTL_FD/EPOLL_CTL_DEL）。<br>
fd：需要监听的fd。<br>
events：指向epoll_event的指针，该结构记录监听的事件。<br>
maxevents：告诉内核events的大小。<br>
timeout：超时时间（ms为单位，0表示立即返回，-1将不确定）。<br>
select、poll和epoll区别</p>
<p>操作方式及效率：<br>
select是遍历，需要遍历fd_set每一个比特位（= MAX_CONN），O(n)；<br>
poll是遍历，但只遍历到pollfd数组当前已使用的最大下标（≠ MAX_CONN），O(n)；<br>
epoll是回调，O(1)。</p>
<p>最大连接数：<br>
select为1024/2048（一个进程打开的文件数是有限制的）；poll无上限；epoll无上限。</p>
<p>fd拷贝：<br>
select每次都需要把fd集合从用户态拷贝到内核态；<br>
poll每次都需要把fd集合从用户态拷贝到内核态；<br>
epoll调用epoll_ctl时拷贝进内核并放到事件表中，但用户进程和内核通过mmap映射共享同一块存储，避免了fd从内核赋值到用户空间。</p>
<p>其他：<br>
select每次内核仅仅是通知有消息到了需要处理，具体是哪一个需要遍历所有的描述符才能找到。<br>
epoll不仅通知有I/O到来还可通过callback函数具体定位到活跃的socket，实现伪AIO。</p>
<p>异步I/O模型<br>
上面三种I/O方式均属于同步I/O。<br>
从阻塞式I/O到非阻塞I/O，我们已经做到了调用I/O请求后立即返回，但不停轮询的操作效率又很低，如果能够既像非阻塞I/O能够立即返回又能不一直轮询的话会更符合我们的预期。<br>
之所以用户进程会不停轮询就是因为在数据准备完毕后内核不会回调用户进程，只能通过用户进程一次又一次轮询来查询I/O结果。如果内核能够在完成I/O后通过消息告知用户进程来处理已经得到的数据自然是最好的，异步I/O就是这么回事。<br>
异步I/O就是当用户进程发起I/O请求后立即返回，直到内核发送一个信号，告知进程I/O已完成，在整个过程中，都没有进程被阻塞。看上去异步I/O和非阻塞I/O的区别在于：判断数据是否准备完毕的任务从用户进程本身被委托给内核来完成。这里所谓的异步只是操作系统提供的一直机制罢了。</p>
]]></content>
    </entry>
</feed>